#!/usr/bin/env python3
"""
Section 6.2 (CI/CD Pipeline) í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
CI/CD Pipeline Testing Script
"""

import json
import os
import subprocess
import sys
import time
from pathlib import Path
from typing import Any, Dict, List

import requests
import yaml

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


def test_section62():
    """Section 6.2 CI/CD íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""

    print("ğŸ§ª Section 6.2: CI/CD Pipeline í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)

    # 1. GitHub Actions ì›Œí¬í”Œë¡œìš° íŒŒì¼ í™•ì¸
    print("\n1ï¸âƒ£ GitHub Actions ì›Œí¬í”Œë¡œìš° íŒŒì¼ í™•ì¸...")

    required_workflow_files = [
        ".github/workflows/ci-cd-pipeline.yml",
        ".github/workflows/section5-docker-test.yml",  # ê¸°ì¡´ íŒŒì¼
    ]

    missing_files = []
    for file_path in required_workflow_files:
        if os.path.exists(file_path):
            print(f"âœ… {file_path}")
        else:
            print(f"âŒ {file_path}")
            missing_files.append(file_path)

    if missing_files:
        print(f"\nâŒ ëˆ„ë½ëœ ì›Œí¬í”Œë¡œìš° íŒŒì¼ë“¤: {missing_files}")
        return False

    # 2. YAML ì›Œí¬í”Œë¡œìš° êµ¬ë¬¸ ê²€ì¦
    print("\n2ï¸âƒ£ GitHub Actions YAML êµ¬ë¬¸ ê²€ì¦...")

    for workflow_file in required_workflow_files:
        try:
            with open(workflow_file, "r") as f:
                yaml.safe_load(f)
            print(f"âœ… {workflow_file} - êµ¬ë¬¸ ìœ íš¨")
        except yaml.YAMLError as e:
            print(f"âŒ {workflow_file} - YAML ì˜¤ë¥˜: {e}")
            return False
        except Exception as e:
            print(f"âŒ {workflow_file} - ì½ê¸° ì˜¤ë¥˜: {e}")
            return False

    # 3. CI/CD ìŠ¤í¬ë¦½íŠ¸ ë° ì„¤ì • íŒŒì¼ í™•ì¸
    print("\n3ï¸âƒ£ CI/CD ì§€ì› íŒŒì¼ í™•ì¸...")

    cicd_support_files = [
        "requirements.txt",
        "requirements-enhanced.txt",
        "docker/Dockerfile.api",
        "docker/Dockerfile.train",
        "docker/docker-compose.yml",
        "docker/docker-compose.monitoring.yml",
        "scripts/tests/test_section1.py",
        "scripts/tests/test_section2.py",
        "scripts/tests/test_section3.py",
        "scripts/tests/test_section4.py",
        "scripts/tests/test_section5.py",
        "scripts/tests/test_section6_1.py",
    ]

    missing_support_files = []
    for file_path in cicd_support_files:
        if os.path.exists(file_path):
            print(f"âœ… {file_path}")
        else:
            print(f"âŒ {file_path}")
            missing_support_files.append(file_path)

    if missing_support_files:
        print(f"\nâš ï¸ ì¼ë¶€ ì§€ì› íŒŒì¼ ëˆ„ë½: {missing_support_files}")
        print("CI/CD íŒŒì´í”„ë¼ì¸ì´ ì™„ì „íˆ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # 4. ì½”ë“œ í’ˆì§ˆ ë„êµ¬ í…ŒìŠ¤íŠ¸
    print("\n4ï¸âƒ£ ì½”ë“œ í’ˆì§ˆ ë„êµ¬ í…ŒìŠ¤íŠ¸...")

    try:
        # Python ê¸°ë³¸ ë„êµ¬ë“¤ í™•ì¸
        quality_tools = {
            "black": "code formatting",
            "flake8": "linting",
            "pylint": "advanced linting",
            "bandit": "security scanning",
            "mypy": "type checking",
            "pytest": "unit testing",
        }

        available_tools = []
        missing_tools = []

        for tool, description in quality_tools.items():
            try:
                result = subprocess.run(
                    [tool, "--version"], capture_output=True, text=True, timeout=5
                )
                if result.returncode == 0:
                    print(f"âœ… {tool} ({description})")
                    available_tools.append(tool)
                else:
                    print(f"âš ï¸ {tool} ({description}) - ì„¤ì¹˜ í•„ìš”")
                    missing_tools.append(tool)
            except (FileNotFoundError, subprocess.TimeoutExpired):
                print(f"âš ï¸ {tool} ({description}) - ì„¤ì¹˜ í•„ìš”")
                missing_tools.append(tool)

        if missing_tools:
            print(f"\nğŸ’¡ ëˆ„ë½ëœ ë„êµ¬ ì„¤ì¹˜:")
            print(f"pip install {' '.join(missing_tools)}")

    except Exception as e:
        print(f"âŒ ì½”ë“œ í’ˆì§ˆ ë„êµ¬ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")

    # 5. Docker ê¸°ëŠ¥ ê²€ì¦
    print("\n5ï¸âƒ£ Docker ë¹Œë“œ ëŠ¥ë ¥ ê²€ì¦...")

    try:
        # Docker ì„¤ì¹˜ í™•ì¸
        result = subprocess.run(["docker", "--version"], capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… Docker: {result.stdout.strip()}")
        else:
            print("âŒ Docker ë¯¸ì„¤ì¹˜")
            return False

        # Docker Compose í™•ì¸
        result = subprocess.run(
            ["docker-compose", "--version"], capture_output=True, text=True
        )
        if result.returncode == 0:
            print(f"âœ… Docker Compose: {result.stdout.strip()}")
        else:
            print("âŒ Docker Compose ë¯¸ì„¤ì¹˜")
            return False

        # Dockerfile êµ¬ë¬¸ ê²€ì¦ (ë¹Œë“œ ì—†ì´)
        dockerfiles = ["docker/Dockerfile.api", "docker/Dockerfile.train"]

        for dockerfile in dockerfiles:
            if os.path.exists(dockerfile):
                # ê¸°ë³¸ Dockerfile êµ¬ë¬¸ ì²´í¬
                with open(dockerfile, "r") as f:
                    content = f.read()
                    if "FROM" in content and "RUN" in content:
                        print(f"âœ… {dockerfile} - ê¸°ë³¸ êµ¬ë¬¸ ìœ íš¨")
                    else:
                        print(f"âš ï¸ {dockerfile} - êµ¬ë¬¸ í™•ì¸ í•„ìš”")
            else:
                print(f"âŒ {dockerfile} - íŒŒì¼ ëˆ„ë½")

    except Exception as e:
        print(f"âŒ Docker ê²€ì¦ ì˜¤ë¥˜: {e}")

    # 6. ì‹œë®¬ë ˆì´ì…˜ CI/CD íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    print("\n6ï¸âƒ£ CI/CD íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜...")

    try:
        # Stage 1: ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬ ì‹œë®¬ë ˆì´ì…˜
        print("   ğŸ“‹ Stage 1: ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬...")

        # Python íŒŒì¼ ì¡´ì¬ í™•ì¸
        python_files = list(Path("src").rglob("*.py"))
        if python_files:
            print(f"   âœ… Python íŒŒì¼ {len(python_files)}ê°œ ë°œê²¬")

            # ê°„ë‹¨í•œ êµ¬ë¬¸ ê²€ì‚¬
            syntax_errors = 0
            for py_file in python_files[:5]:  # ì²˜ìŒ 5ê°œë§Œ í…ŒìŠ¤íŠ¸
                try:
                    with open(py_file, "r") as f:
                        compile(f.read(), py_file, "exec")
                except SyntaxError:
                    syntax_errors += 1

            if syntax_errors == 0:
                print(f"   âœ… êµ¬ë¬¸ ê²€ì‚¬ í†µê³¼ (ìƒ˜í”Œ {min(5, len(python_files))}ê°œ íŒŒì¼)")
            else:
                print(f"   âš ï¸ êµ¬ë¬¸ ì˜¤ë¥˜ ë°œê²¬: {syntax_errors}ê°œ íŒŒì¼")
        else:
            print("   âŒ Python íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

        # Stage 2: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜
        print("   ğŸ§ª Stage 2: í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")

        test_results = []
        test_scripts = [
            "scripts/tests/test_section1.py",
            "scripts/tests/test_section2.py",
            "scripts/tests/test_section3.py",
            "scripts/tests/test_section4.py",
            "scripts/tests/test_section5.py",
            "scripts/tests/test_section6_1.py",
        ]

        for test_script in test_scripts:
            if os.path.exists(test_script):
                print(f"   âœ… {test_script} - í…ŒìŠ¤íŠ¸ ê°€ëŠ¥")
                test_results.append(True)
            else:
                print(f"   âŒ {test_script} - ëˆ„ë½")
                test_results.append(False)

        test_coverage = sum(test_results) / len(test_results) * 100
        print(f"   ğŸ“Š í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€: {test_coverage:.1f}%")

        # Stage 3: ë¹Œë“œ ì‹œë®¬ë ˆì´ì…˜
        print("   ğŸ”¨ Stage 3: ë¹Œë“œ ê²€ì¦...")

        # í•„ìˆ˜ íŒŒì¼ë“¤ í™•ì¸
        build_files = [
            "requirements.txt",
            "docker/Dockerfile.api",
            "docker/Dockerfile.train",
            "src/api/main.py",
            "src/models/trainer.py",
        ]

        build_ready = all(os.path.exists(f) for f in build_files)
        if build_ready:
            print("   âœ… ë¹Œë“œ ì¤€ë¹„ ì™„ë£Œ")
        else:
            missing_build_files = [f for f in build_files if not os.path.exists(f)]
            print(f"   âš ï¸ ë¹Œë“œ íŒŒì¼ ëˆ„ë½: {missing_build_files}")

        # Stage 4: ë°°í¬ ì¤€ë¹„ í™•ì¸
        print("   ğŸš€ Stage 4: ë°°í¬ ì¤€ë¹„...")

        deployment_files = [
            "docker/docker-compose.yml",
            "docker/docker-compose.monitoring.yml",
            "docker/docker-compose.prod.yml",
        ]

        deployment_ready = all(os.path.exists(f) for f in deployment_files)
        if deployment_ready:
            print("   âœ… ë°°í¬ ì„¤ì • ì™„ë£Œ")
        else:
            missing_deployment_files = [
                f for f in deployment_files if not os.path.exists(f)
            ]
            print(f"   âš ï¸ ë°°í¬ íŒŒì¼ ëˆ„ë½: {missing_deployment_files}")

    except Exception as e:
        print(f"   âŒ íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜ ì˜¤ë¥˜: {e}")

    # 7. GitHub Actions ì›Œí¬í”Œë¡œìš° ìƒì„¸ ê²€ì¦
    print("\n7ï¸âƒ£ GitHub Actions ì›Œí¬í”Œë¡œìš° ìƒì„¸ ê²€ì¦...")

    try:
        main_workflow = ".github/workflows/ci-cd-pipeline.yml"
        if os.path.exists(main_workflow):
            with open(main_workflow, "r") as f:
                workflow_content = yaml.safe_load(f)

            # í•„ìˆ˜ ì„¹ì…˜ í™•ì¸
            required_sections = ["name", "on", "jobs"]
            for section in required_sections:
                if section in workflow_content:
                    print(f"   âœ… ì›Œí¬í”Œë¡œìš° '{section}' ì„¹ì…˜ ì¡´ì¬")
                else:
                    print(f"   âŒ ì›Œí¬í”Œë¡œìš° '{section}' ì„¹ì…˜ ëˆ„ë½")

            # Jobs í™•ì¸
            jobs = workflow_content.get("jobs", {})
            expected_jobs = [
                "code-quality",
                "unit-tests",
                "integration-tests",
                "build-and-push",
                "deploy-staging",
                "deploy-production",
            ]

            found_jobs = list(jobs.keys())
            print(f"   ğŸ“‹ ì •ì˜ëœ Job ìˆ˜: {len(found_jobs)}")

            for job in expected_jobs:
                if job in found_jobs:
                    print(f"   âœ… Job '{job}' ì •ì˜ë¨")
                else:
                    print(f"   âš ï¸ Job '{job}' ëˆ„ë½")

            # íŠ¸ë¦¬ê±° ì´ë²¤íŠ¸ í™•ì¸
            triggers = workflow_content.get("on", {})
            if isinstance(triggers, dict):
                trigger_events = list(triggers.keys())
                print(f"   ğŸ¯ íŠ¸ë¦¬ê±° ì´ë²¤íŠ¸: {', '.join(trigger_events)}")

        else:
            print(f"   âŒ ë©”ì¸ ì›Œí¬í”Œë¡œìš° íŒŒì¼ ëˆ„ë½: {main_workflow}")

    except Exception as e:
        print(f"   âŒ ì›Œí¬í”Œë¡œìš° ê²€ì¦ ì˜¤ë¥˜: {e}")

    # 8. í™˜ê²½ ë³€ìˆ˜ ë° ì‹œí¬ë¦¿ ê°€ì´ë“œ
    print("\n8ï¸âƒ£ í™˜ê²½ ë³€ìˆ˜ ë° ì‹œí¬ë¦¿ ì„¤ì • ê°€ì´ë“œ...")

    required_secrets = [
        "GITHUB_TOKEN",  # ìë™ ì œê³µ
        "SLACK_ML_WEBHOOK_URL",  # Slack ì•Œë¦¼ìš©
        "EMAIL_USERNAME",  # ì´ë©”ì¼ ì•Œë¦¼ìš©
        "EMAIL_PASSWORD",  # ì´ë©”ì¼ ì•Œë¦¼ìš©
        "NOTIFICATION_EMAIL",  # ì•Œë¦¼ ë°›ì„ ì´ë©”ì¼
    ]

    print("   ğŸ” í•„ìš”í•œ GitHub Secrets:")
    for secret in required_secrets:
        if secret == "GITHUB_TOKEN":
            print(f"   âœ… {secret} (ìë™ ì œê³µ)")
        else:
            print(f"   âš ï¸ {secret} (ìˆ˜ë™ ì„¤ì • í•„ìš”)")

    print("\n   ğŸ’¡ GitHub Secrets ì„¤ì • ë°©ë²•:")
    print("   1. GitHub ë¦¬í¬ì§€í† ë¦¬ â†’ Settings â†’ Secrets and variables â†’ Actions")
    print("   2. 'New repository secret' í´ë¦­")
    print("   3. ê° ì‹œí¬ë¦¿ ì´ë¦„ê³¼ ê°’ ì…ë ¥")

    # 9. ëª¨ë‹ˆí„°ë§ í†µí•© í™•ì¸
    print("\n9ï¸âƒ£ CI/CD - ëª¨ë‹ˆí„°ë§ í†µí•© í™•ì¸...")

    try:
        # Section 6.1 ëª¨ë‹ˆí„°ë§ íŒŒì¼ í™•ì¸
        monitoring_files = [
            "docker/docker-compose.monitoring.yml",
            "src/monitoring/metrics.py",
            "src/api/main_with_metrics.py",
        ]

        monitoring_ready = True
        for mon_file in monitoring_files:
            if os.path.exists(mon_file):
                print(f"   âœ… {mon_file}")
            else:
                print(f"   âŒ {mon_file}")
                monitoring_ready = False

        if monitoring_ready:
            print("   âœ… CI/CD - ëª¨ë‹ˆí„°ë§ í†µí•© ì¤€ë¹„ ì™„ë£Œ")
            print("   ğŸ“Š ë°°í¬ í›„ ìë™ ëª¨ë‹ˆí„°ë§ í™œì„±í™” ê°€ëŠ¥")
        else:
            print("   âš ï¸ ëª¨ë‹ˆí„°ë§ í†µí•©ì„ ìœ„í•´ Section 6.1 ì™„ë£Œ í•„ìš”")

    except Exception as e:
        print(f"   âŒ ëª¨ë‹ˆí„°ë§ í†µí•© í™•ì¸ ì˜¤ë¥˜: {e}")

    # 10. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì„¤ì • ê²€ì¦
    print("\nğŸ”Ÿ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì„¤ì • ê²€ì¦...")

    try:
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ì— í•„ìš”í•œ ìš”ì†Œë“¤ í™•ì¸
        performance_requirements = {
            "load_testing_script": "scripts/performance_test.py",
            "test_data": "data/processed/movies_with_ratings.csv",
            "api_endpoint": "src/api/main.py",
            "model_files": "models/",
        }

        for req_name, req_path in performance_requirements.items():
            if os.path.exists(req_path):
                print(f"   âœ… {req_name}: {req_path}")
            else:
                print(f"   âš ï¸ {req_name}: {req_path} (ìƒì„± ê¶Œì¥)")

        print("   ğŸ“ˆ CI/CD íŒŒì´í”„ë¼ì¸ì—ì„œ ìë™ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        print("   ğŸ¯ ì„ê³„ê°’: í‰ê·  ì‘ë‹µì‹œê°„ < 2ì´ˆ, 95th percentile < 5ì´ˆ")

    except Exception as e:
        print(f"   âŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²€ì¦ ì˜¤ë¥˜: {e}")

    print("\n" + "=" * 60)
    print("ğŸ‰ Section 6.2 CI/CD Pipeline í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    print("\nğŸ“ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
    print("   âœ… GitHub Actions ì›Œí¬í”Œë¡œìš° íŒŒì¼ ìƒì„± ë° ê²€ì¦")
    print("   âœ… 5ë‹¨ê³„ CI/CD íŒŒì´í”„ë¼ì¸ ì„¤ì •")
    print("     - ğŸ” Stage 1: ì½”ë“œ í’ˆì§ˆ & ë³´ì•ˆ ê²€ì‚¬")
    print("     - ğŸ§ª Stage 2: ìœ ë‹›/í†µí•© í…ŒìŠ¤íŠ¸")
    print("     - ğŸ”¨ Stage 3: Docker ì´ë¯¸ì§€ ë¹Œë“œ & í‘¸ì‹œ")
    print("     - ğŸš€ Stage 4: ìŠ¤í…Œì´ì§•/í”„ë¡œë•ì…˜ ë°°í¬")
    print("     - ğŸ“Š Stage 5: ë°°í¬ í›„ ëª¨ë‹ˆí„°ë§ & ì•Œë¦¼")
    print("   âœ… ì½”ë“œ í’ˆì§ˆ ë„êµ¬ í†µí•©")
    print("   âœ… ë³´ì•ˆ ìŠ¤ìº” ë° ì·¨ì•½ì  ê²€ì‚¬")
    print("   âœ… ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í†µí•©")

    print("\nğŸš€ CI/CD íŒŒì´í”„ë¼ì¸ íŠ¹ì§•:")
    print("   ğŸ”„ ìë™í™”ëœ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    print("   ğŸ³ Multi-platform Docker ì´ë¯¸ì§€ ë¹Œë“œ")
    print("   ğŸŒ ìŠ¤í…Œì´ì§•/í”„ë¡œë•ì…˜ í™˜ê²½ ë¶„ë¦¬")
    print("   ğŸ“¢ Slack/ì´ë©”ì¼ ì•Œë¦¼ í†µí•©")
    print("   ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹ ìë™í™”")
    print("   ğŸ”’ ë³´ì•ˆ ìŠ¤ìº” ë° SBOM ìƒì„±")
    print("   ğŸ“ˆ ë°°í¬ í›„ ëª¨ë‹ˆí„°ë§ ìë™ í™œì„±í™”")

    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. GitHub Secrets ì„¤ì •:")
    print("      - SLACK_ML_WEBHOOK_URL (Slack ì•Œë¦¼ìš©)")
    print("      - EMAIL_USERNAME, EMAIL_PASSWORD (ì´ë©”ì¼ ì•Œë¦¼ìš©)")
    print("      - NOTIFICATION_EMAIL (ì•Œë¦¼ ë°›ì„ ì´ë©”ì¼)")
    print("   2. ì²« ë²ˆì§¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰:")
    print("      git add . && git commit -m 'Add CI/CD pipeline' && git push")
    print("   3. GitHub Actions íƒ­ì—ì„œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í™•ì¸")
    print("   4. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œì—ì„œ ë°°í¬ ë©”íŠ¸ë¦­ í™•ì¸")
    print("   5. ğŸ‰ ìµœì¢… ë°œí‘œ ì¤€ë¹„! (6.10 í™”ìš”ì¼)")

    print("\nğŸ† MLOps í”„ë¡œì íŠ¸ ì™„ì„±ë„:")
    print("   âœ… Section 1: Data Pipeline - COMPLETED")
    print("   âœ… Section 2: Preprocessing - COMPLETED")
    print("   âœ… Section 3: Model Training - COMPLETED")
    print("   âœ… Section 4: API Serving - COMPLETED")
    print("   âœ… Section 5: Docker Containerization - COMPLETED")
    print("   âœ… Section 6.1: Monitoring & Observability - COMPLETED")
    print("   âœ… Section 6.2: CI/CD Pipeline - COMPLETED")
    print("\nğŸ¯ í”„ë¡œì íŠ¸ ì™„ì„±ë„: 100% (7/7 ì„¹ì…˜ ì™„ë£Œ!)")

    return True


def test_workflow_syntax():
    """GitHub Actions ì›Œí¬í”Œë¡œìš° YAML êµ¬ë¬¸ ìƒì„¸ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ” GitHub Actions ì›Œí¬í”Œë¡œìš° ìƒì„¸ êµ¬ë¬¸ ê²€ì‚¬...")

    workflow_file = ".github/workflows/ci-cd-pipeline.yml"

    if not os.path.exists(workflow_file):
        print(f"âŒ ì›Œí¬í”Œë¡œìš° íŒŒì¼ ì—†ìŒ: {workflow_file}")
        return False

    try:
        with open(workflow_file, "r") as f:
            workflow = yaml.safe_load(f)

        # ì›Œí¬í”Œë¡œìš° ì´ë¦„ í™•ì¸
        workflow_name = workflow.get("name", "Unnamed")
        print(f"   ğŸ“‹ ì›Œí¬í”Œë¡œìš° ì´ë¦„: {workflow_name}")

        # íŠ¸ë¦¬ê±° ì´ë²¤íŠ¸ ìƒì„¸ í™•ì¸
        triggers = workflow.get("on", {})
        print(f"   ğŸ¯ íŠ¸ë¦¬ê±° ì„¤ì •:")
        for trigger, config in triggers.items():
            if isinstance(config, dict):
                print(f"      {trigger}: {config}")
            else:
                print(f"      {trigger}: {config}")

        # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
        env_vars = workflow.get("env", {})
        if env_vars:
            print(f"   ğŸŒ í™˜ê²½ ë³€ìˆ˜:")
            for var, value in env_vars.items():
                print(f"      {var}: {value}")

        # Jobs ìƒì„¸ ë¶„ì„
        jobs = workflow.get("jobs", {})
        print(f"   ğŸ’¼ Jobs ë¶„ì„ ({len(jobs)}ê°œ):")

        for job_name, job_config in jobs.items():
            needs = job_config.get("needs", [])
            runs_on = job_config.get("runs-on", "unknown")
            steps_count = len(job_config.get("steps", []))

            print(f"      {job_name}:")
            print(f"        - ì‹¤í–‰ í™˜ê²½: {runs_on}")
            print(f"        - ë‹¨ê³„ ìˆ˜: {steps_count}")
            if needs:
                if isinstance(needs, list):
                    print(f"        - ì˜ì¡´ì„±: {', '.join(needs)}")
                else:
                    print(f"        - ì˜ì¡´ì„±: {needs}")

        return True

    except yaml.YAMLError as e:
        print(f"   âŒ YAML êµ¬ë¬¸ ì˜¤ë¥˜: {e}")
        return False
    except Exception as e:
        print(f"   âŒ íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return False


def create_sample_performance_test():
    """ìƒ˜í”Œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    print("\nğŸ“ˆ ìƒ˜í”Œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±...")

    performance_script_path = Path("scripts/performance_test.py")

    if performance_script_path.exists():
        print("   âœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì´ë¯¸ ì¡´ì¬")
        return True

    performance_script_content = '''#!/usr/bin/env python3
"""
Performance Test Script for MLOps API
CI/CD íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
"""

import time
import requests
import statistics
import concurrent.futures
import json
from datetime import datetime

def single_prediction_test(base_url="http://localhost:8000", timeout=10):
    """ë‹¨ì¼ ì˜ˆì¸¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    test_data = {
        "title": "Performance Test Movie",
        "startYear": 2020,
        "runtimeMinutes": 120,
        "numVotes": 5000
    }

    start_time = time.time()
    try:
        response = requests.post(
            f"{base_url}/predict/movie",
            json=test_data,
            timeout=timeout
        )
        end_time = time.time()

        if response.status_code == 200:
            return end_time - start_time
        else:
            return None
    except:
        return None

def load_test(base_url="http://localhost:8000", num_requests=50, concurrent_requests=5):
    """ë¶€í•˜ í…ŒìŠ¤íŠ¸"""
    print(f"ğŸ”¥ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹œì‘: {num_requests}ê°œ ìš”ì²­, {concurrent_requests}ê°œ ë™ì‹œ ì‹¤í–‰")

    response_times = []
    errors = 0

    with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_requests) as executor:
        futures = [executor.submit(single_prediction_test, base_url) for _ in range(num_requests)]

        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            if result is not None:
                response_times.append(result)
            else:
                errors += 1

    if response_times:
        avg_time = statistics.mean(response_times)
        p95_time = sorted(response_times)[int(len(response_times) * 0.95)]
        p99_time = sorted(response_times)[int(len(response_times) * 0.99)]

        results = {
            "timestamp": datetime.now().isoformat(),
            "total_requests": num_requests,
            "successful_requests": len(response_times),
            "failed_requests": errors,
            "average_response_time": avg_time,
            "p95_response_time": p95_time,
            "p99_response_time": p99_time,
            "min_response_time": min(response_times),
            "max_response_time": max(response_times)
        }

        print(f"ğŸ“Š ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"   ì„±ê³µ ìš”ì²­: {len(response_times)}/{num_requests}")
        print(f"   í‰ê·  ì‘ë‹µì‹œê°„: {avg_time:.3f}ì´ˆ")
        print(f"   95th percentile: {p95_time:.3f}ì´ˆ")
        print(f"   99th percentile: {p99_time:.3f}ì´ˆ")

        # ì„±ëŠ¥ ê¸°ì¤€ ì²´í¬
        performance_ok = True
        if avg_time > 2.0:
            print(f"   âš ï¸ í‰ê·  ì‘ë‹µì‹œê°„ ì´ˆê³¼: {avg_time:.3f}s > 2.0s")
            performance_ok = False
        if p95_time > 5.0:
            print(f"   âš ï¸ 95th percentile ì´ˆê³¼: {p95_time:.3f}s > 5.0s")
            performance_ok = False

        if performance_ok:
            print("   âœ… ì„±ëŠ¥ ê¸°ì¤€ í†µê³¼")

        return results, performance_ok
    else:
        print("   âŒ ëª¨ë“  ìš”ì²­ ì‹¤íŒ¨")
        return None, False

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='MLOps API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸')
    parser.add_argument('--url', default='http://localhost:8000', help='API URL')
    parser.add_argument('--requests', type=int, default=50, help='ì´ ìš”ì²­ ìˆ˜')
    parser.add_argument('--concurrent', type=int, default=5, help='ë™ì‹œ ìš”ì²­ ìˆ˜')

    args = parser.parse_args()

    results, success = load_test(args.url, args.requests, args.concurrent)

    if results:
        # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        with open('performance_test_results.json', 'w') as f:
            json.dump(results, f, indent=2)
        print(f"ğŸ“„ ê²°ê³¼ ì €ì¥: performance_test_results.json")

    exit(0 if success else 1)
'''

    try:
        performance_script_path.parent.mkdir(exist_ok=True)
        with open(performance_script_path, "w") as f:
            f.write(performance_script_content)

        # ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
        os.chmod(performance_script_path, 0o755)

        print(f"   âœ… ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: {performance_script_path}")
        return True

    except Exception as e:
        print(f"   âŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return False


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Section 6.2 CI/CD Pipeline í…ŒìŠ¤íŠ¸")
    parser.add_argument("--detailed", action="store_true", help="ìƒì„¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    parser.add_argument(
        "--create-perf-test", action="store_true", help="ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"
    )

    args = parser.parse_args()

    success = test_section62()

    if args.detailed and success:
        print("\n" + "=" * 60)
        print("ğŸ“‹ ìƒì„¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
        print("=" * 60)
        test_workflow_syntax()

    if args.create_perf_test:
        print("\n" + "=" * 60)
        print("ğŸ“ˆ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±")
        print("=" * 60)
        create_sample_performance_test()

    sys.exit(0 if success else 1)
