import logging
import warnings
from pathlib import Path
from typing import Any, Dict, List, Tuple

import joblib
import numpy as np
import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

warnings.filterwarnings("ignore")

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class ModelEvaluator:
    """
    ëª¨ë¸ í‰ê°€ ë° ì˜ˆì¸¡ í´ë˜ìŠ¤
    trainer.pyì™€ ë™ì¼í•œ í”¼ì²˜ ì •ì˜ ì‚¬ìš©
    """

    def __init__(self):
        self.model = None
        self.scaler = None
        self.feature_names = []
        self.model_type = None
        self.model_info = None

    def load_model(self, model_path: str, model_type: str = "random_forest"):
        """ëª¨ë¸ê³¼ ê´€ë ¨ ì •ë³´ ë¡œë“œ"""
        try:
            # ëª¨ë¸ ì •ë³´ ë¡œë“œ (feature_names í¬í•¨)
            self.model_info = joblib.load(model_path)

            # ìƒˆë¡œìš´ í˜•ì‹ (ë”•ì…”ë„ˆë¦¬)ì¸ì§€ í™•ì¸
            if isinstance(self.model_info, dict):
                self.model = self.model_info["model"]
                self.feature_names = self.model_info["feature_names"]
                self.model_type = self.model_info.get("model_type", model_type)
            else:
                # ì´ì „ í˜•ì‹ (ëª¨ë¸ë§Œ ì €ì¥ëœ ê²½ìš°)
                self.model = self.model_info
                self.model_type = model_type
                # ê¸°ë³¸ í”¼ì²˜ ì‚¬ìš© (trainer.pyì™€ ë™ì¼)
                self.feature_names = ["startYear", "runtimeMinutes", "numVotes"]

            # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ (ë™ì¼í•œ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì €ì¥ëœ ê²ƒ ì°¾ê¸°)
            model_path_obj = Path(model_path)
            timestamp = (
                model_path_obj.stem.split("_")[-2]
                + "_"
                + model_path_obj.stem.split("_")[-1]
            )
            scaler_path = model_path_obj.parent / f"scaler_{timestamp}.joblib"

            if scaler_path.exists():
                self.scaler = joblib.load(scaler_path)
                logger.info(f"ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ: {scaler_path}")
            else:
                logger.warning(f"ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {scaler_path}")
                self.scaler = None

            logger.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
            logger.info(f"ëª¨ë¸ íƒ€ì…: {self.model_type}")
            logger.info(f"í”¼ì²˜ ëª©ë¡: {self.feature_names}")

        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def evaluate_model(
        self, X: np.ndarray, y: np.ndarray
    ) -> Tuple[Dict[str, float], np.ndarray]:
        """ëª¨ë¸ í‰ê°€"""
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ìŠ¤ì¼€ì¼ë§ ì ìš© (ìŠ¤ì¼€ì¼ëŸ¬ê°€ ìˆëŠ” ê²½ìš°)
        if self.scaler is not None:
            X_scaled = self.scaler.transform(X)
        else:
            X_scaled = X

        # ì˜ˆì¸¡
        y_pred = self.model.predict(X_scaled)

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = {
            "rmse": np.sqrt(mean_squared_error(y, y_pred)),
            "mae": mean_absolute_error(y, y_pred),
            "r2_score": r2_score(y, y_pred),
        }

        logger.info("ëª¨ë¸ í‰ê°€ ì™„ë£Œ:")
        logger.info(f"  RMSE: {metrics['rmse']:.4f}")
        logger.info(f"  MAE: {metrics['mae']:.4f}")
        logger.info(f"  RÂ²: {metrics['r2_score']:.4f}")
        logger.info(f"  ì˜ˆì¸¡ ë²”ìœ„: {y_pred.min():.2f} ~ {y_pred.max():.2f}")
        logger.info(f"  ì‹¤ì œ ë²”ìœ„: {y.min():.2f} ~ {y.max():.2f}")

        return metrics, y_pred

    def predict_single_movie(self, movie_data: Dict[str, Any]) -> float:
        """ë‹¨ì¼ ì˜í™” í‰ì  ì˜ˆì¸¡ - ğŸ¯ ìˆ˜ì •ëœ í”¼ì²˜ ì‚¬ìš©"""
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ğŸ¯ í•µì‹¬ ìˆ˜ì •: ì‹¤ì œ ëª¨ë¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” í”¼ì²˜ë§Œ ì‚¬ìš©
        try:
            # ëª¨ë¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” í”¼ì²˜ë§Œ ì¶”ì¶œ
            feature_values = []
            for feature_name in self.feature_names:
                if feature_name in movie_data:
                    feature_values.append(movie_data[feature_name])
                else:
                    # ê¸°ë³¸ê°’ ì„¤ì •
                    if feature_name == "startYear":
                        feature_values.append(2000)  # ê¸°ë³¸ ì—°ë„
                    elif feature_name == "runtimeMinutes":
                        feature_values.append(120)  # ê¸°ë³¸ ëŸ¬ë‹íƒ€ì„
                    elif feature_name == "numVotes":
                        feature_values.append(1000)  # ê¸°ë³¸ íˆ¬í‘œìˆ˜
                    else:
                        feature_values.append(0)  # ê¸°íƒ€ ê¸°ë³¸ê°’

                    logger.warning(f"í”¼ì²˜ '{feature_name}'ê°€ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©")

            # ì˜ˆì¸¡ì„ ìœ„í•œ ë°°ì—´ ìƒì„±
            X_single = np.array(feature_values).reshape(1, -1)

            # ìŠ¤ì¼€ì¼ë§ ì ìš©
            if self.scaler is not None:
                X_single_scaled = self.scaler.transform(X_single)
            else:
                X_single_scaled = X_single

            # ì˜ˆì¸¡
            prediction = self.model.predict(X_single_scaled)[0]

            # ì˜ˆì¸¡ê°’ ë²”ìœ„ ì œí•œ (1-10)
            prediction = np.clip(prediction, 1.0, 10.0)

            logger.info(f"ë‹¨ì¼ ì˜ˆì¸¡ ì™„ë£Œ: {prediction:.2f}")
            logger.info(f"ì‚¬ìš©ëœ í”¼ì²˜: {dict(zip(self.feature_names, feature_values))}")

            return float(prediction)

        except Exception as e:
            logger.error(f"ë‹¨ì¼ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            raise

    def batch_predict(self, movies_df: pd.DataFrame) -> np.ndarray:
        """ë°°ì¹˜ ì˜ˆì¸¡"""
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # í•„ìš”í•œ í”¼ì²˜ë§Œ ì¶”ì¶œ
        available_features = [
            col for col in self.feature_names if col in movies_df.columns
        ]

        if not available_features:
            raise ValueError(
                f"í•„ìš”í•œ í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤. í•„ìš”: {self.feature_names}, ì‚¬ìš©ê°€ëŠ¥: {list(movies_df.columns)}"
            )

        X = movies_df[available_features].fillna(movies_df[available_features].median())

        # ìŠ¤ì¼€ì¼ë§ ì ìš©
        if self.scaler is not None:
            X_scaled = self.scaler.transform(X.values)
        else:
            X_scaled = X.values

        # ì˜ˆì¸¡
        predictions = self.model.predict(X_scaled)

        # ì˜ˆì¸¡ê°’ ë²”ìœ„ ì œí•œ
        predictions = np.clip(predictions, 1.0, 10.0)

        logger.info(f"ë°°ì¹˜ ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)}ê°œ ìƒ˜í”Œ")

        return predictions

    def get_feature_names(self) -> List[str]:
        """í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ í”¼ì²˜ ì´ë¦„ ë°˜í™˜"""
        return self.feature_names.copy()

    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "model_type": self.model_type,
            "feature_names": self.feature_names,
            "n_features": len(self.feature_names),
            "model_loaded": self.model is not None,
            "scaler_loaded": self.scaler is not None,
        }


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # í‰ê°€ê¸° ì´ˆê¸°í™”
    evaluator = ModelEvaluator()

    # ëª¨ë¸ ë¡œë“œ (ê°€ì¥ ìµœê·¼ ëª¨ë¸ ì°¾ê¸°)
    models_dir = Path("models")
    model_files = list(models_dir.glob("*forest*.joblib"))

    if model_files:
        latest_model = max(model_files, key=lambda x: x.stat().st_mtime)
        print(f"ìµœì‹  ëª¨ë¸ ë¡œë“œ: {latest_model}")

        evaluator.load_model(str(latest_model))

        # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
        test_movie = {"startYear": 2020, "runtimeMinutes": 120, "numVotes": 10000}

        prediction = evaluator.predict_single_movie(test_movie)
        print(f"ì˜ˆì¸¡ í‰ì : {prediction:.2f}/10")

        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        info = evaluator.get_model_info()
        print(f"ëª¨ë¸ ì •ë³´: {info}")

    else:
        print("ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í›ˆë ¨ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
