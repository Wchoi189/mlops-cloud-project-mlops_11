import logging
import warnings
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Tuple, Union

import joblib
import mlflow
import mlflow.sklearn
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

warnings.filterwarnings("ignore")

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class MovieRatingTrainer:
    """
    ì˜í™” í‰ì  ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨ í´ë˜ìŠ¤
    MLOps íŒŒì´í”„ë¼ì¸ ì¤‘ì‹¬ ì„¤ê³„
    """

    # ğŸ¯ ì¤‘ì•™ì§‘ì¤‘í™”ëœ í”¼ì²˜ ì •ì˜ (í•µì‹¬ ìˆ˜ì •ì‚¬í•­)
    BASE_FEATURES = ["startYear", "runtimeMinutes", "numVotes"]
    TARGET_COLUMN = "averageRating"

    def __init__(self, experiment_name: str = "imdb_movie_rating"):
        self.experiment_name = experiment_name
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = []
        self.models_dir = Path("models")
        self.models_dir.mkdir(exist_ok=True)

        # MLflow ì„¤ì •
        try:
            mlflow.set_experiment(self.experiment_name)
            logger.info(f"MLflow ì‹¤í—˜ ì„¤ì •: {self.experiment_name}")
        except Exception as e:
            logger.warning(f"MLflow ì„¤ì • ì‹¤íŒ¨: {e}")

    def prepare_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """í”¼ì²˜ ì¤€ë¹„ - ì¤‘ì•™ì§‘ì¤‘í™”ëœ ì •ì˜ ì‚¬ìš©"""
        logger.info("í”¼ì²˜ ì¤€ë¹„ ì‹œì‘")

        # ê¸°ë³¸ í”¼ì²˜ë§Œ ì‚¬ìš© (ë‹¨ìˆœí™”)
        available_features = [col for col in self.BASE_FEATURES if col in df.columns]

        if not available_features:
            raise ValueError(
                f"í•„ìš”í•œ í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤. í•„ìš”: {self.BASE_FEATURES}, ì‚¬ìš©ê°€ëŠ¥: {list(df.columns)}"
            )

        logger.info(f"X contents####: {df[available_features].columns}")

        # í”¼ì²˜ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        X = df[available_features].copy()

        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        X = X.fillna(X.median())

        # íƒ€ê²Ÿ ë³€ìˆ˜
        if self.TARGET_COLUMN not in df.columns:
            raise ValueError(f"íƒ€ê²Ÿ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.TARGET_COLUMN}")

        y = df[self.TARGET_COLUMN].values

        # í”¼ì²˜ëª… ì €ì¥
        self.feature_names = available_features

        logger.info(
            f"í”¼ì²˜ ì¤€ë¹„ ì™„ë£Œ: {len(X)}ê°œ ìƒ˜í”Œ, {len(available_features)}ê°œ í”¼ì²˜"
        )
        logger.info(f"í”¼ì²˜ ëª©ë¡: {self.feature_names}")

        return X.values, y

    def train_model(
        self, X: np.ndarray, y: np.ndarray, model_type: str = "random_forest"
    ) -> Dict[str, float]:
        """ëª¨ë¸ í›ˆë ¨"""
        logger.info(f"ëª¨ë¸ í›ˆë ¨ ì‹œì‘: {model_type}")

        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # ëª¨ë¸ ì„ íƒ
        if model_type == "random_forest":
            self.model = RandomForestRegressor(n_estimators=100, random_state=42)
        elif model_type == "linear_regression":
            self.model = LinearRegression()
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: {model_type}")

        # MLflow ì‹¤í—˜ ì‹œì‘
        with mlflow.start_run():
            # ëª¨ë¸ í›ˆë ¨
            self.model.fit(X_train_scaled, y_train)

            # ì˜ˆì¸¡ ë° í‰ê°€
            y_pred = self.model.predict(X_test_scaled)

            # ë©”íŠ¸ë¦­ ê³„ì‚°
            metrics = {
                "rmse": np.sqrt(mean_squared_error(y_test, y_pred)),
                "mae": mean_absolute_error(y_test, y_pred),
                "r2_score": r2_score(y_test, y_pred),
            }

            # MLflow ë¡œê¹… (ìˆ˜ì •ëœ ë¶€ë¶„)
            try:
                # íŒŒë¼ë¯¸í„° ë¡œê¹…
                mlflow.log_param("model_type", model_type)
                mlflow.log_param("features", self.feature_names)
                mlflow.log_param("n_features", len(self.feature_names))

                # ë©”íŠ¸ë¦­ ë¡œê¹…
                for metric_name, metric_value in metrics.items():
                    mlflow.log_metric(metric_name, metric_value)

                # ğŸ¯ ëª¨ë¸ ë¡œê¹… ê°œì„  (ì„œëª…ê³¼ ì˜ˆì œ ì¶”ê°€)
                input_example = pd.DataFrame(
                    X_train_scaled[:5], columns=self.feature_names
                )

                mlflow.sklearn.log_model(
                    self.model,
                    "model",
                    input_example=input_example,
                    registered_model_name=f"{model_type}_movie_rating",
                )

                logger.info("MLflow ë¡œê¹… ì™„ë£Œ")

            except Exception as e:
                logger.warning(f"MLflow ë¡œê¹… ì‹¤íŒ¨: {e}")

            logger.info("ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ:")
            logger.info(f"  - RMSE: {metrics['rmse']:.4f}")
            logger.info(f"  - MAE: {metrics['mae']:.4f}")
            logger.info(f"  - RÂ²: {metrics['r2_score']:.4f}")

        return metrics

    def save_model(self) -> Dict[str, Union[str, List[str]]]:
        """ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥"""
        if self.model is None:
            raise ValueError("í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_filename = f"{type(self.model).__name__.lower()}_{timestamp}.joblib"
        scaler_filename = f"scaler_{timestamp}.joblib"

        model_path = self.models_dir / model_filename
        scaler_path = self.models_dir / scaler_filename

        # ëª¨ë¸ ì •ë³´ì™€ í•¨ê»˜ ì €ì¥
        model_info = {
            "model": self.model,
            "feature_names": self.feature_names,
            "model_type": type(self.model).__name__,
            "timestamp": timestamp,
        }

        joblib.dump(model_info, model_path)
        joblib.dump(self.scaler, scaler_path)

        logger.info(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
        logger.info(f"ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ ì™„ë£Œ: {scaler_path}")

        return {
            "model_path": str(model_path),
            "scaler_path": str(scaler_path),
            "feature_names": self.feature_names,
        }

    def get_feature_names(self) -> List[str]:
        """í”¼ì²˜ ì´ë¦„ ë°˜í™˜ (ì™¸ë¶€ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡)"""
        return self.feature_names.copy()


def run_training_pipeline():
    """í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    try:
        # ë°ì´í„° ë¡œë“œ
        data_path = "data/processed/movies_with_ratings.csv"
        df = pd.read_csv(data_path)

        logger.info(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê°œ ìƒ˜í”Œ")

        # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
        trainer = MovieRatingTrainer()

        # í”¼ì²˜ ì¤€ë¹„
        X, y = trainer.prepare_features(df)

        # ëª¨ë¸ í›ˆë ¨ (Random Forest)
        metrics = trainer.train_model(X, y, model_type="random_forest")

        # ëª¨ë¸ ì €ì¥
        model_info = trainer.save_model()

        print("\nğŸ‰ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print(f"ğŸ“Š ì„±ëŠ¥: RMSE={metrics['rmse']:.4f}, RÂ²={metrics['r2_score']:.4f}")
        print(f"ğŸ’¾ ì €ì¥ëœ ëª¨ë¸: {model_info['model_path']}")
        print(f"ğŸ”§ í”¼ì²˜: {model_info['feature_names']}")

        return model_info

    except Exception as e:
        logger.error(f"í›ˆë ¨ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
        raise


if __name__ == "__main__":
    run_training_pipeline()
