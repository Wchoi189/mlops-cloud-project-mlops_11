import logging
from datetime import datetime
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd
from fastapi import APIRouter, Depends, HTTPException

from ..models.evaluator import ModelEvaluator
from .schemas import (
    BatchPredictionRequest,
    BatchPredictionResponse,
    HealthResponse,
    ModelInfo,
    PredictionRequest,
    PredictionResponse,
)

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ë¼ìš°í„° ìƒì„±
router = APIRouter()

# ì „ì—­ ëª¨ë¸ í‰ê°€ê¸° (ì•± ì‹œì‘ì‹œ ë¡œë“œë¨)
model_evaluator: Optional[ModelEvaluator] = None


def get_model_evaluator() -> Optional[ModelEvaluator]:
    """
    ëª¨ë¸ í‰ê°€ê¸° ì˜ì¡´ì„± ì£¼ì… (Graceful handling)
    CI/CD í™˜ê²½ì—ì„œ ëª¨ë¸ì´ ì—†ì„ ë•Œë„ ë™ì‘í•˜ë„ë¡ ê°œì„ 
    """
    global model_evaluator
    
    if model_evaluator is None:
        logger.warning("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CI/CD í™˜ê²½ì´ê±°ë‚˜ ëª¨ë¸ íŒŒì¼ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return None
    
    return model_evaluator

def require_model_evaluator() -> ModelEvaluator:
    """
    ëª¨ë¸ì´ í•„ìˆ˜ì¸ ì—”ë“œí¬ì¸íŠ¸ìš© ì˜ì¡´ì„± ì£¼ì…
    ëª¨ë¸ì´ ì—†ìœ¼ë©´ 503 ì—ëŸ¬ ë°˜í™˜
    """
    evaluator = get_model_evaluator()
    if evaluator is None:
        raise HTTPException(
            status_code=503,
            detail={
                "error": "Service Temporarily Unavailable",
                "message": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                "details": "ì„œë²„ë¥¼ ë‹¤ì‹œ ì‹œì‘í•˜ê±°ë‚˜ ëª¨ë¸ì„ í›ˆë ¨í•´ì£¼ì„¸ìš”",
                "suggestions": [
                    "python scripts/train_model.py ì‹¤í–‰",
                    "models/ ë””ë ‰í† ë¦¬ì— ëª¨ë¸ íŒŒì¼ í™•ì¸",
                    "ì„œë²„ ì¬ì‹œì‘ ì‹œë„"
                ],
                "model_required": True,
                "status": "no_model_loaded"
            }
        )
    return evaluator

@router.post("/predict", response_model=PredictionResponse)
async def predict_movie_rating(request: PredictionRequest):
    """
    ë‹¨ì¼ ì˜í™” í‰ì  ì˜ˆì¸¡ (Enhanced with graceful degradation)

    ìš”ì²­ ì˜ˆì‹œ:
    {
        "text": "ì˜í™” ì œëª©",
        "startYear": 2020,
        "runtimeMinutes": 120,
        "numVotes": 10000
    }
    """
    try:
        logger.info(f"í‰ì  ì˜ˆì¸¡ ìš”ì²­: {(request.text[:50] + '...') if request.text else 'No text provided'}")

        # ìš”ì²­ì—ì„œ ì˜í™” ì •ë³´ ì¶”ì¶œ
        movie_data = {
            "startYear": getattr(request, "startYear", 2020),
            "runtimeMinutes": getattr(request, "runtimeMinutes", 120),
            "numVotes": getattr(request, "numVotes", 5000),
        }

        # ëª¨ë¸ í‰ê°€ê¸° í™•ì¸ (graceful handling)
        evaluator = get_model_evaluator()
        
        if evaluator is None:
            # ëª¨ë¸ì´ ì—†ì„ ë•Œ fallback ì˜ˆì¸¡
            logger.warning("ëª¨ë¸ ì—†ìŒ - fallback ì˜ˆì¸¡ ì œê³µ")
            
            # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ì˜ˆì¸¡
            base_rating = 6.0  # ê¸°ë³¸ í‰ì 
            
            # ì—°ë„ ë³´ì •
            year = movie_data.get("startYear", 2020)
            if year > 2010:
                base_rating += 0.3
            if year > 2020:
                base_rating += 0.1
                
            # ëŸ°íƒ€ì„ ë³´ì •
            runtime = movie_data.get("runtimeMinutes", 120)
            if 90 <= runtime <= 150:
                base_rating += 0.2
            elif runtime > 200:
                base_rating -= 0.1
                
            # íˆ¬í‘œìˆ˜ ë³´ì •
            votes = movie_data.get("numVotes", 5000)
            if votes > 10000:
                base_rating += 0.2
            if votes > 50000:
                base_rating += 0.1
                
            # ë²”ìœ„ ì œí•œ
            predicted_rating = min(max(base_rating, 1.0), 10.0)
            
            # ê°ì • ë¶„ë¥˜ (í‰ì  ê¸°ë°˜)
            sentiment = "positive" if predicted_rating >= 6.0 else "negative"
            confidence = 0.5  # ë‚®ì€ ì‹ ë¢°ë„ (fallbackì´ë¯€ë¡œ)

            logger.info(f"Fallback ì˜ˆì¸¡ ì™„ë£Œ: {predicted_rating:.2f}/10")

            return PredictionResponse(
                text=request.text,
                sentiment=sentiment,
                confidence=confidence,
                timestamp=datetime.now().isoformat(),
                # Enhanced fields for graceful degradation
                predicted_rating=round(predicted_rating, 2),
                model_version="fallback-v1.0",
                features_used=["heuristic_fallback"],
                processing_time=0.001,
                metadata={
                    "model_status": "not_loaded",
                    "prediction_method": "heuristic_fallback",
                    "warning": "ì‹¤ì œ ML ëª¨ë¸ì„ ì‚¬ìš©í•˜ì§€ ì•Šì€ ì˜ˆì¸¡ì…ë‹ˆë‹¤",
                    "note": "ëª¨ë¸ í›ˆë ¨ í›„ ë” ì •í™•í•œ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤"
                }
            )
        
        # ëª¨ë¸ì´ ìˆì„ ë•Œ ì •ìƒ ì˜ˆì¸¡ (ê¸°ì¡´ ë¡œì§)
        predicted_rating = evaluator.predict_single_movie(movie_data)

        # ê°ì • ë¶„ë¥˜ (í‰ì  ê¸°ë°˜)
        sentiment = "positive" if predicted_rating >= 6.0 else "negative"
        confidence = min(0.95, max(0.55, predicted_rating / 10.0))

        logger.info(f"ì˜ˆì¸¡ ì™„ë£Œ: {predicted_rating:.2f}/10")

        return PredictionResponse(
            text=request.text,
            sentiment=sentiment,
            confidence=confidence,
            timestamp=datetime.now().isoformat(),
            # Enhanced fields for normal prediction
            predicted_rating=round(predicted_rating, 2),
            model_version="1.0.0",
            features_used=evaluator.get_feature_names(),
            processing_time=0.05,
            metadata={
                "model_status": "loaded",
                "prediction_method": "ml_model",
                "model_type": evaluator.model_type
            }
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")   
@router.post("/predict/movie", response_model=Dict[str, Any])
async def predict_movie_with_features(movie_data: Dict[str, Any]):
    """
    ì˜í™” í”¼ì²˜ ê¸°ë°˜ í‰ì  ì˜ˆì¸¡ (Graceful degradation)
    ëª¨ë¸ì´ ì—†ì„ ë•Œ ì ì ˆí•œ ì‘ë‹µ ì œê³µ
    """
    try:
        evaluator = get_model_evaluator()
        
        # ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš° graceful degradation
        if evaluator is None:
            logger.warning("ëª¨ë¸ ì—†ìŒ - ê¸°ë³¸ ì‘ë‹µ ì œê³µ")
            
            # ë‹¨ìˆœí•œ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ì˜ˆì¸¡ (CI/CD í…ŒìŠ¤íŠ¸ìš©)
            base_rating = 6.5  # í‰ê·  ì˜í™” í‰ì 
            
            # ì—°ë„ ë³´ì •
            year = movie_data.get("startYear", 2000)
            if year > 2010:
                base_rating += 0.2
            if year > 2020:
                base_rating += 0.1
                
            # ëŸ°íƒ€ì„ ë³´ì •
            runtime = movie_data.get("runtimeMinutes", 120)
            if 90 <= runtime <= 150:
                base_rating += 0.1
                
            # íˆ¬í‘œìˆ˜ ë³´ì •
            votes = movie_data.get("numVotes", 1000)
            if votes > 10000:
                base_rating += 0.2
            if votes > 100000:
                base_rating += 0.1
                
            predicted_rating = min(max(base_rating, 1.0), 10.0)
            
            return {
                "title": movie_data.get("title", "Unknown Movie"),
                "predicted_rating": round(predicted_rating, 2),
                "rating_out_of_10": f"{predicted_rating:.1f}/10",
                "features_used": ["heuristic_fallback"],
                "model_features": ["startYear", "runtimeMinutes", "numVotes"],
                "timestamp": datetime.now().isoformat(),
                "confidence": 0.5,  # ë‚®ì€ ì‹ ë¢°ë„
                "model_version": "fallback-v1.0",
                "metadata": {
                    "model_status": "not_loaded",
                    "prediction_method": "heuristic_fallback",
                    "warning": "ì‹¤ì œ ML ëª¨ë¸ì„ ì‚¬ìš©í•˜ì§€ ì•Šì€ ì˜ˆì¸¡ì…ë‹ˆë‹¤",
                    "accuracy_note": "ëª¨ë¸ í›ˆë ¨ í›„ ì •í™•í•œ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤"
                }
            }
        
        # ëª¨ë¸ì´ ìˆëŠ” ê²½ìš° ì •ìƒ ì˜ˆì¸¡ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        logger.info(f"ì˜í™” í‰ì  ì˜ˆì¸¡: {movie_data}")
        
        required_features = evaluator.get_feature_names()
        predicted_rating = evaluator.predict_single_movie(movie_data)
        
        response = {
            "title": movie_data.get("title", "Unknown Movie"),
            "predicted_rating": round(predicted_rating, 2),
            "rating_out_of_10": f"{predicted_rating:.1f}/10",
            "features_used": {
                k: v for k, v in movie_data.items() if k in required_features
            },
            "model_features": required_features,
            "timestamp": datetime.now().isoformat(),
            "confidence": 0.85,
            "model_version": "1.0.0",
            "metadata": {
                "model_status": "loaded",
                "model_type": evaluator.model_type,
                "prediction_method": "ml_model"
            }
        }
        
        logger.info(f"ì˜ˆì¸¡ ê²°ê³¼: {predicted_rating:.2f}/10")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì˜í™” ì˜ˆì¸¡ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=500, 
            detail=f"ì˜ˆì¸¡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )
@router.post("/predict/batch", response_model=BatchPredictionResponse)
async def predict_batch_movies(request: BatchPredictionRequest):
    """
    ì—¬ëŸ¬ ì˜í™” ë°°ì¹˜ ì˜ˆì¸¡ (Enhanced with graceful degradation)
    """
    try:
        logger.info(f"ë°°ì¹˜ ì˜ˆì¸¡ ìš”ì²­: {len(request.texts)}ê°œ ì˜í™”")

        if len(request.texts) > 100:
            raise HTTPException(
                status_code=400, detail="í•œ ë²ˆì— ìµœëŒ€ 100ê°œê¹Œì§€ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤."
            )

        # ëª¨ë¸ í‰ê°€ê¸° í™•ì¸ (graceful handling)
        evaluator = get_model_evaluator()
        predictions = []

        for i, text in enumerate(request.texts):
            try:
                # ê°„ë‹¨í•œ ë”ë¯¸ ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” í…ìŠ¤íŠ¸ íŒŒì‹± í•„ìš”)
                movie_data = {
                    "startYear": 2020 - (i % 20),  # 2000-2020 ë²”ìœ„
                    "runtimeMinutes": 90 + (i % 60),  # 90-150ë¶„ ë²”ìœ„
                    "numVotes": 1000 + (i * 100),  # ë‹¤ì–‘í•œ ì¸ê¸°ë„
                }

                if evaluator is None:
                    # ëª¨ë¸ì´ ì—†ì„ ë•Œ fallback ì˜ˆì¸¡
                    base_rating = 6.0  # ê¸°ë³¸ í‰ì 
                    
                    # ì—°ë„ ë³´ì •
                    year = movie_data.get("startYear", 2020)
                    if year > 2010:
                        base_rating += 0.2
                    if year > 2015:
                        base_rating += 0.1
                        
                    # ëŸ°íƒ€ì„ ë³´ì •
                    runtime = movie_data.get("runtimeMinutes", 120)
                    if 90 <= runtime <= 150:
                        base_rating += 0.1
                        
                    # íˆ¬í‘œìˆ˜ ë³´ì •
                    votes = movie_data.get("numVotes", 1000)
                    if votes > 5000:
                        base_rating += 0.1
                        
                    # ê°œë³„ ì˜í™”ë§ˆë‹¤ ì•½ê°„ì˜ ë³€í™” ì¶”ê°€
                    import random
                    base_rating += random.uniform(-0.3, 0.3)
                    
                    # ë²”ìœ„ ì œí•œ
                    predicted_rating = min(max(base_rating, 1.0), 10.0)
                    
                    sentiment = "positive" if predicted_rating >= 6.0 else "negative"
                    confidence = 0.5  # ë‚®ì€ ì‹ ë¢°ë„

                    predictions.append(
                        PredictionResponse(
                            text=text,
                            sentiment=sentiment,
                            confidence=confidence,
                            timestamp=datetime.now().isoformat(),
                            # Enhanced fields for fallback
                            predicted_rating=round(predicted_rating, 2),
                            model_version="fallback-v1.0",
                            features_used=["heuristic_fallback"],
                            processing_time=0.001,
                            metadata={
                                "model_status": "not_loaded",
                                "prediction_method": "heuristic_fallback",
                                "batch_index": i,
                                "warning": "ì‹¤ì œ ML ëª¨ë¸ì„ ì‚¬ìš©í•˜ì§€ ì•Šì€ ì˜ˆì¸¡ì…ë‹ˆë‹¤"
                            }
                        )
                    )
                else:
                    # ëª¨ë¸ì´ ìˆì„ ë•Œ ì •ìƒ ì˜ˆì¸¡
                    predicted_rating = evaluator.predict_single_movie(movie_data)
                    sentiment = "positive" if predicted_rating >= 6.0 else "negative"
                    confidence = min(0.95, max(0.55, predicted_rating / 10.0))

                    predictions.append(
                        PredictionResponse(
                            text=text,
                            sentiment=sentiment,
                            confidence=confidence,
                            timestamp=datetime.now().isoformat(),
                            # Enhanced fields for normal prediction
                            predicted_rating=round(predicted_rating, 2),
                            model_version="1.0.0",
                            features_used=evaluator.get_feature_names(),
                            processing_time=0.05,
                            metadata={
                                "model_status": "loaded",
                                "prediction_method": "ml_model",
                                "batch_index": i,
                                "model_type": evaluator.model_type
                            }
                        )
                    )

            except Exception as e:
                logger.warning(f"ê°œë³„ ì˜ˆì¸¡ ì‹¤íŒ¨ ({text[:30]}...): {e}")
                # ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ê°’ (fallback)
                predictions.append(
                    PredictionResponse(
                        text=text,
                        sentiment="neutral",
                        confidence=0.3,
                        timestamp=datetime.now().isoformat(),
                        # Enhanced fields for error case
                        predicted_rating=5.0,  # ì¤‘ê°„ê°’
                        model_version="error-fallback",
                        features_used=["error_fallback"],
                        processing_time=0.001,
                        metadata={
                            "model_status": "error",
                            "prediction_method": "error_fallback",
                            "batch_index": i,
                            "error": str(e),
                            "warning": "ê°œë³„ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
                        }
                    )
                )

        logger.info(f"ë°°ì¹˜ ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)}ê°œ ê²°ê³¼")

        return BatchPredictionResponse(
            predictions=predictions, 
            total_count=len(predictions)
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë°°ì¹˜ ì˜ˆì¸¡ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë°°ì¹˜ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")

@router.get("/model/info")
async def get_model_info():
    """
    ëª¨ë¸ ì •ë³´ ì¡°íšŒ (Graceful handling)
    ëª¨ë¸ì´ ì—†ì–´ë„ ìœ ìš©í•œ ì •ë³´ ì œê³µ
    """
    try:
        evaluator = get_model_evaluator()
        
        if evaluator is None:
            return {
                "name": "IMDB Rating Predictor",
                "version": "not_loaded",
                "status": "model_not_available",
                "description": "IMDB ì˜í™” í‰ì  ì˜ˆì¸¡ ëª¨ë¸ (í˜„ì¬ ë¡œë“œë˜ì§€ ì•ŠìŒ)",
                "model_loaded": False,
                "created_at": datetime.now().isoformat(),
                "metrics": {
                    "features": 0,
                    "model_loaded": False,
                    "scaler_loaded": False,
                },
                "expected_features": ["startYear", "runtimeMinutes", "numVotes"],
                "fallback_available": True,
                "suggestions": [
                    "ëª¨ë¸ í›ˆë ¨: python scripts/train_model.py",
                    "ëª¨ë¸ íŒŒì¼ í™•ì¸: ls models/",
                    "ì„œë²„ ì¬ì‹œì‘ ê³ ë ¤"
                ],
                "warning": "í˜„ì¬ heuristic fallback ëª¨ë“œì—ì„œ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤"
            }
        
        # ëª¨ë¸ì´ ë¡œë“œëœ ê²½ìš° (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        model_info = evaluator.get_model_info()
        
        return {
            "name": model_info.get("model_type", "Unknown"),
            "version": "1.0.0",
            "status": "loaded",
            "description": f"IMDB ì˜í™” í‰ì  ì˜ˆì¸¡ ëª¨ë¸ ({model_info.get('model_type', 'Unknown')})",
            "created_at": datetime.now().isoformat(),
            "model_loaded": True,
            "metrics": {
                "features": model_info.get("n_features", 0),
                "model_loaded": model_info.get("model_loaded", False),
                "scaler_loaded": model_info.get("scaler_loaded", False),
            },
            "feature_names": model_info.get("feature_names", []),
            "fallback_available": False
        }
        
    except Exception as e:
        logger.error(f"ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return {
            "name": "IMDB Rating Predictor",
            "version": "error",
            "status": "error",
            "description": "ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            "created_at": datetime.now().isoformat(),
            "model_loaded": False,
            "error": str(e),
            "fallback_available": True
        }
    
@router.get("/health", response_model=HealthResponse)
async def health_check():
    """
    API ìƒíƒœ í™•ì¸ (Enhanced with graceful degradation info)
    """
    try:
        evaluator = get_model_evaluator()
        model_loaded = evaluator is not None
        
        # ìƒíƒœ ê²°ì •
        if model_loaded:
            status = "healthy"
            details = "ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ì •ìƒ ë™ì‘ ì¤‘"
        else:
            status = "degraded"
            details = "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ì§€ë§Œ APIëŠ” ë™ì‘ ê°€ëŠ¥ (fallback ëª¨ë“œ)"
        
        return HealthResponse(
            status=status,
            timestamp=datetime.now(),
            version="1.0.0",
            model_loaded=model_loaded,
            details=details,
            capabilities={
                "prediction": True,  # fallback ê°€ëŠ¥í•˜ë¯€ë¡œ í•­ìƒ true
                "model_info": True,
                "health_check": True,
                "fallback_prediction": not model_loaded
            }
        )
        
    except Exception as e:
        logger.error(f"í—¬ìŠ¤ì²´í¬ ì˜¤ë¥˜: {str(e)}")
        return HealthResponse(
            status="unhealthy",
            timestamp=datetime.now(),
            version="1.0.0",
            model_loaded=False,
            details=f"í—¬ìŠ¤ì²´í¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
            capabilities={
                "prediction": False,
                "model_info": False,
                "health_check": True,
                "fallback_prediction": False
            }
        )
def load_model_at_startup():
    """
    Enhanced model loading with Docker packaging support
    Priority: 1) Packaged model 2) Latest trained model 3) Fallback
    """
    global model_evaluator

    try:
        from pathlib import Path
        import os

        # CI/CD environment detection
        is_ci_environment = any([
            os.getenv('CI') == 'true',
            os.getenv('GITHUB_ACTIONS') == 'true',
            os.getenv('DOCKER_ENV') == 'ci',
            os.getenv('ENVIRONMENT') == 'ci'
        ])
        
        is_docker_environment = any([
            os.path.exists('/.dockerenv'),
            os.getenv('DOCKER_CONTAINER') == 'true'
        ])

        models_dir = Path("models")
        if not models_dir.exists():
            logger.warning("âš ï¸ models ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False

        # ğŸ¯ PRIORITY 1: Look for packaged CI/CD model (Docker containers)
        packaged_models = [
            "cicd_default_model.joblib",
            # "docker_model.joblib", 
            "cicd_linear_model.joblib",
            # "scaler_default_model.joblib",
            # "latest_model.joblib"

        ]
        
        for packaged_model in packaged_models:
            packaged_path = models_dir / packaged_model
            if packaged_path.exists():
                try:
                    logger.info(f"ğŸ³ Found packaged model: {packaged_model}")
                    model_evaluator = ModelEvaluator()
                    model_evaluator.load_model(str(packaged_path))
                    
                    logger.info("âœ… Packaged model loaded successfully!")
                    logger.info(f"   Model type: {model_evaluator.model_type}")
                    logger.info(f"   Features: {model_evaluator.get_feature_names()}")
                    logger.info(f"   Source: Packaged for containers")
                    
                    return True
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to load packaged model {packaged_model}: {e}")
                    continue

        # ğŸ¯ PRIORITY 2: Look for latest trained model (development/production)
        model_files = list(models_dir.glob("*forest*.joblib"))
        model_files.extend(list(models_dir.glob("*regressor*.joblib")))
        model_files.extend(list(models_dir.glob("*model*.joblib")))
        
        # Filter out packaged models from search
        model_files = [f for f in model_files if f.name not in packaged_models]
        
        if model_files:
            # Get the most recent model
            latest_model = max(model_files, key=lambda x: x.stat().st_mtime)
            
            try:
                logger.info(f"ğŸ“¦ Found trained model: {latest_model.name}")
                model_evaluator = ModelEvaluator()
                model_evaluator.load_model(str(latest_model))
                
                logger.info("âœ… Trained model loaded successfully!")
                logger.info(f"   Model type: {model_evaluator.model_type}")
                logger.info(f"   Features: {model_evaluator.get_feature_names()}")
                logger.info(f"   Source: Training pipeline")
                
                return True
                
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to load trained model: {e}")

        # ğŸ¯ PRIORITY 3: No model found - log appropriate message
        if is_docker_environment and is_ci_environment:
            logger.info("â„¹ï¸ CI/CD ì»¨í…Œì´ë„ˆì—ì„œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            logger.info("ğŸ’¡ ì»¨í…Œì´ë„ˆì— ëª¨ë¸ì´ íŒ¨í‚¤ì§•ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        elif is_ci_environment:
            logger.info("â„¹ï¸ CI/CD í™˜ê²½ - ëª¨ë¸ ì—†ì´ fallback ëª¨ë“œë¡œ ì‹¤í–‰")
        else:
            logger.error("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            logger.info("ğŸ’¡ ëª¨ë¸ í›ˆë ¨ ë°©ë²•: python scripts/train_model.py")

        model_evaluator = None
        return False

    except Exception as e:
        if is_ci_environment:
            logger.info(f"â„¹ï¸ CI/CD í™˜ê²½ì—ì„œ ëª¨ë¸ ë¡œë“œ ê±´ë„ˆëœ€: {e}")
        else:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        model_evaluator = None
        return False


def get_model_status():
    """Get detailed model status for debugging"""
    try:
        from pathlib import Path
        import os
        
        models_dir = Path("models")
        status = {
            "models_directory_exists": models_dir.exists(),
            "is_docker": os.path.exists('/.dockerenv'),
            "is_ci": os.getenv('CI') == 'true',
            "model_evaluator_loaded": model_evaluator is not None,
            "available_models": [],
            "packaged_models": [],
            "environment": {
                "DOCKER_CONTAINER": os.getenv('DOCKER_CONTAINER'),
                "CI": os.getenv('CI'),
                "GITHUB_ACTIONS": os.getenv('GITHUB_ACTIONS'),
                "MODEL_PATH": os.getenv('MODEL_PATH')
            }
        }
        
        if models_dir.exists():
            # List all model files
            all_models = list(models_dir.glob("*.joblib")) + list(models_dir.glob("*.pkl"))
            status["available_models"] = [f.name for f in all_models]
            
            # Identify packaged models
            packaged_names = ["cicd_default_model.joblib", "docker_model.joblib", "cicd_linear_model.joblib"]
            status["packaged_models"] = [name for name in packaged_names if (models_dir / name).exists()]
        
        if model_evaluator is not None:
            try:
                status["current_model"] = {
                    "type": model_evaluator.model_type if hasattr(model_evaluator, 'model_type') else "unknown",
                    "features": model_evaluator.get_feature_names() if hasattr(model_evaluator, 'get_feature_names') else []
                }
            except:
                status["current_model"] = "loaded_but_details_unavailable"
        
        return status
        
    except Exception as e:
        return {"error": str(e)}