from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import logging
from typing import Dict, Any
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ì•± ìƒëª…ì£¼ê¸° ê´€ë¦¬
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì‹œì‘ ì‹œ ì‹¤í–‰
    logger.info("ğŸš€ MLOps IMDB API ì‹œì‘ ì¤‘...")
    
    # ëª¨ë¸ ë¡œë“œ
    from .endpoints import load_model_at_startup
    model_loaded = load_model_at_startup()
    
    if model_loaded:
        logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - API ì¤€ë¹„ë¨")
    else:
        logger.warning("âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤")
    
    yield
    
    # ì¢…ë£Œ ì‹œ ì‹¤í–‰
    logger.info("ğŸ›‘ MLOps IMDB API ì¢…ë£Œ ì¤‘...")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="MLOps IMDB Movie Rating Prediction API",
    description="""
    ğŸ¬ IMDB ì˜í™” í‰ì  ì˜ˆì¸¡ MLOps API
    
    ## ê¸°ëŠ¥
    - ì˜í™” í‰ì  ì˜ˆì¸¡ (Random Forest ëª¨ë¸)
    - ë°°ì¹˜ ì˜ˆì¸¡ ì§€ì›
    - ëª¨ë¸ ì •ë³´ ì¡°íšŒ
    - í—¬ìŠ¤ ì²´í¬
    
    ## ì‚¬ìš©ë˜ëŠ” í”¼ì²˜
    - startYear: ê°œë´‰ ì—°ë„
    - runtimeMinutes: ìƒì˜ ì‹œê°„
    - numVotes: íˆ¬í‘œ ìˆ˜
    
    ## ëª¨ë¸ ì„±ëŠ¥
    - RMSE: ~0.69
    - RÂ²: ~0.31
    """,
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì • (ê°œë°œ í™˜ê²½ìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” êµ¬ì²´ì ì¸ ë„ë©”ì¸ ì§€ì •
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¼ìš°í„° ë“±ë¡
from .endpoints import router as prediction_router
app.include_router(prediction_router, tags=["predictions"])

@app.get("/", response_model=Dict[str, Any])
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ - API ì •ë³´ ì œê³µ"""
    return {
        "message": "MLOps IMDB Movie Rating Prediction API",
        "status": "running",
        "version": "1.0.0",
        "description": "ì˜í™” í‰ì  ì˜ˆì¸¡ì„ ìœ„í•œ MLOps API",
        "endpoints": {
            "predict_text": "POST /predict - í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ (ë ˆê±°ì‹œ)",
            "predict_movie": "POST /predict/movie - ì˜í™” í”¼ì²˜ ê¸°ë°˜ ì˜ˆì¸¡",
            "predict_batch": "POST /predict/batch - ë°°ì¹˜ ì˜ˆì¸¡",
            "model_info": "GET /model/info - ëª¨ë¸ ì •ë³´",
            "health": "GET /health - ìƒíƒœ í™•ì¸",
            "docs": "GET /docs - API ë¬¸ì„œ"
        },
        "features_used": ["startYear", "runtimeMinutes", "numVotes"],
        "model_info": {
            "type": "Random Forest Regressor", 
            "performance": "RMSE ~0.69, RÂ² ~0.31",
            "target": "IMDB Rating (1-10)"
        },
        "timestamp": datetime.now().isoformat(),
        "github": "https://github.com/AIBootcamp13/mlops-cloud-project-mlops_11"
    }

@app.get("/status")
async def get_api_status():
    """ìƒì„¸í•œ API ìƒíƒœ ì •ë³´"""
    try:
        from .endpoints import model_evaluator
        
        model_loaded = model_evaluator is not None
        
        if model_loaded:
            model_info = model_evaluator.get_model_info()
        else:
            model_info = {"status": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ"}
        
        return {
            "api_status": "running",
            "model_status": "loaded" if model_loaded else "not_loaded",
            "model_info": model_info,
            "timestamp": datetime.now().isoformat(),
            "uptime": "ê³„ì‚° ì¤‘...",
            "endpoints_count": len(app.routes),
            "version": "1.0.0"
        }
        
    except Exception as e:
        logger.error(f"ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {
            "api_status": "running", 
            "model_status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# ì˜¤ë¥˜ í•¸ë“¤ëŸ¬
@app.exception_handler(404)
async def not_found_handler(request, exc):
    return {
        "error": "Not Found",
        "message": "ìš”ì²­í•œ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "available_endpoints": [
            "/",
            "/predict/movie", 
            "/predict/batch",
            "/model/info",
            "/health",
            "/docs"
        ]
    }

@app.exception_handler(500)
async def internal_error_handler(request, exc):
    logger.error(f"ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜: {exc}")
    return {
        "error": "Internal Server Error",
        "message": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "timestamp": datetime.now().isoformat()
    }

# ê°œë°œ ì„œë²„ ì‹¤í–‰ (python src/api/main.pyë¡œ ì‹¤í–‰ ê°€ëŠ¥)
if __name__ == "__main__":
    import uvicorn
    logger.info("ê°œë°œ ì„œë²„ ì‹œì‘...")
    uvicorn.run(
        "src.api.main:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        log_level="info"
    )