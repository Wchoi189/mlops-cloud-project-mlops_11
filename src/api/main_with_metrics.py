"""
Enhanced FastAPI application with Prometheus metrics integration
Monitoring-ready MLOps API with comprehensive observability
"""

from fastapi import FastAPI, HTTPException, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import PlainTextResponse
from contextlib import asynccontextmanager
import logging
import asyncio
from typing import Dict, Any, Union
from datetime import datetime

# Monitoring imports
try:
    from prometheus_client import CONTENT_TYPE_LATEST, generate_latest, multiprocess, CollectorRegistry
    from ..monitoring.metrics import metrics, PrometheusMiddleware, metrics_collector, update_health_metrics
    HAS_MONITORING = True
except ImportError:
    HAS_MONITORING = False
    logging.warning("Monitoring dependencies not available")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ì•± ìƒëª…ì£¼ê¸° ê´€ë¦¬ with monitoring
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì‹œì‘ ì‹œ ì‹¤í–‰
    logger.info("ğŸš€ MLOps IMDB API with Monitoring ì‹œì‘ ì¤‘...")
    
    # Start metrics collection
    if HAS_MONITORING:
        metrics_collector.start()
        logger.info("ğŸ“Š Metrics collection started")
    
    # ëª¨ë¸ ë¡œë“œ
    from .endpoints import load_model_at_startup
    model_loaded = load_model_at_startup()
    
    if model_loaded:
        logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - API ì¤€ë¹„ë¨")
        if HAS_MONITORING:
            metrics.record_model_accuracy(0.69, "imdb_model", "1.0")  # Initial accuracy
    else:
        logger.warning("âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤")
    
    # Start background health metrics update
    if HAS_MONITORING:
        asyncio.create_task(periodic_health_update())
    
    yield
    
    # ì¢…ë£Œ ì‹œ ì‹¤í–‰
    logger.info("ğŸ›‘ MLOps IMDB API ì¢…ë£Œ ì¤‘...")
    if HAS_MONITORING:
        metrics_collector.stop()

async def periodic_health_update():
    """Periodic health metrics update"""
    while True:
        try:
            update_health_metrics()
            await asyncio.sleep(30)  # Update every 30 seconds
        except Exception as e:
            logger.error(f"Health metrics update error: {e}")
            await asyncio.sleep(30)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="MLOps IMDB Movie Rating Prediction API (Monitoring Edition)",
    description="""
    ğŸ¬ IMDB ì˜í™” í‰ì  ì˜ˆì¸¡ MLOps API with Comprehensive Monitoring
    
    ## ê¸°ëŠ¥
    - ì˜í™” í‰ì  ì˜ˆì¸¡ (Random Forest ëª¨ë¸)
    - ë°°ì¹˜ ì˜ˆì¸¡ ì§€ì›
    - ëª¨ë¸ ì •ë³´ ì¡°íšŒ
    - í—¬ìŠ¤ ì²´í¬
    - **ğŸ“Š Prometheus ë©”íŠ¸ë¦­ìŠ¤ ìˆ˜ì§‘**
    - **ğŸš¨ ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ**
    - **ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**
    
    ## ëª¨ë‹ˆí„°ë§ ì—”ë“œí¬ì¸íŠ¸
    - `/metrics` - Prometheus ë©”íŠ¸ë¦­ìŠ¤
    - `/health` - ìƒì„¸ í—¬ìŠ¤ ì²´í¬
    - `/monitoring/status` - ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ìƒíƒœ
    
    ## ì‚¬ìš©ë˜ëŠ” í”¼ì²˜
    - startYear: ê°œë´‰ ì—°ë„
    - runtimeMinutes: ìƒì˜ ì‹œê°„
    - numVotes: íˆ¬í‘œ ìˆ˜
    
    ## ëª¨ë¸ ì„±ëŠ¥
    - RMSE: ~0.69
    - RÂ²: ~0.31
    """,
    version="1.1.0",
    lifespan=lifespan
)

# Add Prometheus middleware
if HAS_MONITORING:
    app.add_middleware(PrometheusMiddleware, metrics_instance=metrics)

# CORS ì„¤ì • (ê°œë°œ í™˜ê²½ìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” êµ¬ì²´ì ì¸ ë„ë©”ì¸ ì§€ì •
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¼ìš°í„° ë“±ë¡
from .endpoints import router as prediction_router
app.include_router(prediction_router, tags=["predictions"])

# ëª¨ë‹ˆí„°ë§ ì „ìš© ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.get("/metrics", response_class=PlainTextResponse, include_in_schema=False)
async def get_metrics():
    """Prometheus metrics endpoint"""
    if not HAS_MONITORING:
        return "# Monitoring not available\n"
    
    try:
        # Update health metrics before serving
        update_health_metrics()
        return metrics.get_metrics()
    except Exception as e:
        logger.error(f"Error generating metrics: {e}")
        return f"# Error generating metrics: {e}\n"

@app.get("/monitoring/status")
async def monitoring_status():
    """Monitoring system status"""
    return {
        "monitoring_enabled": HAS_MONITORING,
        "metrics_collector_running": metrics_collector.running if HAS_MONITORING else False,
        "prometheus_endpoint": "/metrics",
        "grafana_dashboard": "http://localhost:3000",
        "alertmanager": "http://localhost:9093",
        "services": {
            "prometheus": "http://localhost:9090",
            "grafana": "http://localhost:3000", 
            "alertmanager": "http://localhost:9093"
        },
        "timestamp": datetime.now().isoformat()
    }

@app.get("/", response_model=Dict[str, Any])
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ - API ì •ë³´ ì œê³µ"""
    
    # Record API call if monitoring enabled
    if HAS_MONITORING:
        metrics.http_requests_total.labels(
            method="GET",
            endpoint="/",
            status_code="200"
        ).inc()
    
    return {
        "message": "MLOps IMDB Movie Rating Prediction API (Monitoring Edition)",
        "status": "running",
        "version": "1.1.0",
        "description": "ì˜í™” í‰ì  ì˜ˆì¸¡ì„ ìœ„í•œ ëª¨ë‹ˆí„°ë§ ì§€ì› MLOps API",
        "monitoring": {
            "enabled": HAS_MONITORING,
            "prometheus_metrics": "/metrics",
            "health_check": "/health",
            "monitoring_status": "/monitoring/status"
        },
        "endpoints": {
            "predict_text": "POST /predict - í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ (ë ˆê±°ì‹œ)",
            "predict_movie": "POST /predict/movie - ì˜í™” í”¼ì²˜ ê¸°ë°˜ ì˜ˆì¸¡",
            "predict_batch": "POST /predict/batch - ë°°ì¹˜ ì˜ˆì¸¡",
            "model_info": "GET /model/info - ëª¨ë¸ ì •ë³´",
            "health": "GET /health - ìƒíƒœ í™•ì¸",
            "docs": "GET /docs - API ë¬¸ì„œ"
        },
        "features_used": ["startYear", "runtimeMinutes", "numVotes"],
        "model_info": {
            "type": "Random Forest Regressor", 
            "performance": "RMSE ~0.69, RÂ² ~0.31",
            "target": "IMDB Rating (1-10)"
        },
        "monitoring_dashboards": {
            "grafana": "http://localhost:3000",
            "prometheus": "http://localhost:9090",
            "alertmanager": "http://localhost:9093"
        },
        "timestamp": datetime.now().isoformat(),
        "github": "https://github.com/AIBootcamp13/mlops-cloud-project-mlops_11"
    }

@app.get("/health")
async def enhanced_health_check():
    """Enhanced health check with monitoring metrics"""
    try:
        from .endpoints import model_evaluator
        
        model_loaded = model_evaluator is not None
        
        # Get system health if monitoring available
        health_data = {
            "status": "healthy" if model_loaded else "degraded",
            "timestamp": datetime.now().isoformat(),
            "version": "1.1.0",
            "model_loaded": model_loaded,
            "monitoring_enabled": HAS_MONITORING
        }
        
        if HAS_MONITORING:
            try:
                import psutil
                import os
                
                process = psutil.Process(os.getpid())
                memory_info = process.memory_info()
                
                health_data["system_metrics"] = {
                    "memory_usage_mb": round(memory_info.rss / 1024 / 1024, 2),
                    "cpu_percent": process.cpu_percent(),
                    "num_threads": process.num_threads()
                }
                
                # Update health metrics
                update_health_metrics()
                
            except ImportError:
                health_data["system_metrics"] = "psutil not available"
        
        if model_loaded and HAS_MONITORING:
            model_info = model_evaluator.get_model_info()
            health_data["model_info"] = model_info
            
            # Record model status
            metrics.set_active_users(1)  # Simple active user tracking
        
        return health_data
        
    except Exception as e:
        logger.error(f"í—¬ìŠ¤ì²´í¬ ì˜¤ë¥˜: {e}")
        error_response = {
            "status": "unhealthy",
            "timestamp": datetime.now().isoformat(),
            "version": "1.1.0",
            "model_loaded": False,
            "error": str(e)
        }
        
        if HAS_MONITORING:
            metrics.http_requests_total.labels(
                method="GET",
                endpoint="/health",
                status_code="500"
            ).inc()
        
        return error_response

@app.get("/metrics/custom")
async def custom_metrics():
    """Custom business metrics endpoint"""
    if not HAS_MONITORING:
        return {"error": "Monitoring not available"}
    
    try:
        # Example custom metrics calculation
        from .endpoints import model_evaluator
        
        custom_data: Dict[str, Union[str, int, float]] = {
            "timestamp": datetime.now().isoformat(), # str
            "model_status": "loaded" if model_evaluator else "not_loaded", # str
            "api_version": "1.1.0" # str
        }
        
        # Record some example business metrics
        if model_evaluator:
            # Simulate some business metrics
            metrics.record_prediction_rating(7.5)  # Example rating
            metrics.set_active_users(5)  # Example active users
            
            custom_data["predictions_today"] = 42  # Example data
            custom_data["average_rating"] = 7.2   # Example data
            custom_data["active_users"] = 5
        
        return custom_data
        
    except Exception as e:
        logger.error(f"Custom metrics error: {e}")
        return {"error": str(e)}

# ëª¨ë‹ˆí„°ë§ ê´€ë ¨ ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def add_monitoring_headers(request: Request, call_next):
    """Add monitoring headers to responses"""
    response = await call_next(request)
    
    # Add monitoring-related headers
    response.headers["X-MLOps-Version"] = "1.1.0"
    response.headers["X-Monitoring-Enabled"] = str(HAS_MONITORING)
    
    if HAS_MONITORING:
        response.headers["X-Prometheus-Metrics"] = "/metrics"
        response.headers["X-Health-Check"] = "/health"
    
    return response

# ì˜¤ë¥˜ í•¸ë“¤ëŸ¬ with monitoring
@app.exception_handler(404)
async def not_found_handler(request, exc):
    if HAS_MONITORING:
        metrics.http_requests_total.labels(
            method=request.method,
            endpoint=request.url.path,
            status_code="404"
        ).inc()
    
    return {
        "error": "Not Found",
        "message": "ìš”ì²­í•œ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "available_endpoints": [
            "/",
            "/predict/movie", 
            "/predict/batch",
            "/model/info",
            "/health",
            "/metrics",
            "/monitoring/status",
            "/docs"
        ]
    }

@app.exception_handler(500)
async def internal_error_handler(request, exc):
    logger.error(f"ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜: {exc}")
    
    if HAS_MONITORING:
        metrics.http_requests_total.labels(
            method=request.method,
            endpoint=request.url.path,
            status_code="500"
        ).inc()
    
    return {
        "error": "Internal Server Error",
        "message": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
        "monitoring": "Check /metrics for system health" if HAS_MONITORING else "Monitoring disabled",
        "timestamp": datetime.now().isoformat()
    }

# ê°œë°œ ì„œë²„ ì‹¤í–‰ (python src/api/main_with_metrics.pyë¡œ ì‹¤í–‰ ê°€ëŠ¥)
if __name__ == "__main__":
    import uvicorn
    logger.info("ëª¨ë‹ˆí„°ë§ ì§€ì› ê°œë°œ ì„œë²„ ì‹œì‘...")
    uvicorn.run(
        "src.api.main_with_metrics:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        log_level="info"
    )