"""
Enhanced FastAPI application with Prometheus metrics integration
Monitoring-ready MLOps API with comprehensive observability
"""

import asyncio
import logging
from contextlib import asynccontextmanager
from datetime import datetime
from typing import Any, Dict, Union

from fastapi import FastAPI, HTTPException, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, PlainTextResponse
from prometheus_fastapi_instrumentator import Instrumentator
from starlette.exceptions import HTTPException as StarletteHTTPException

# Monitoring imports
try:
    from prometheus_client import (
        CONTENT_TYPE_LATEST,
        CollectorRegistry,
        generate_latest,
        multiprocess,
    )

    from ..monitoring.metrics import (
        PrometheusMiddleware,
        metrics,
        metrics_collector,
        update_health_metrics,
    )

    HAS_MONITORING = True
except ImportError:
    HAS_MONITORING = False
    logging.warning("Monitoring dependencies not available")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# ì•± ìƒëª…ì£¼ê¸° ê´€ë¦¬ with monitoring
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì‹œì‘ ì‹œ ì‹¤í–‰
    logger.info("ğŸš€ MLOps IMDB API with Monitoring ì‹œì‘ ì¤‘...")

    # Start metrics collection
    if HAS_MONITORING and "metrics_collector" in globals():
        metrics_collector.start()
        logger.info("ğŸ“Š Metrics collection started")

    # ëª¨ë¸ ë¡œë“œ
    from .endpoints import load_model_at_startup

    model_loaded = load_model_at_startup()

    if model_loaded:
        logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - API ì¤€ë¹„ë¨")
        if HAS_MONITORING:
            metrics.record_model_accuracy(0.69, "imdb_model", "1.0")  # Initial accuracy
    else:
        logger.warning("âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤")

    # Start background health metrics update
    if HAS_MONITORING and "update_health_metrics" in globals():
        asyncio.create_task(periodic_health_update())

    yield

    # ì¢…ë£Œ ì‹œ ì‹¤í–‰
    logger.info("ğŸ›‘ MLOps IMDB API ì¢…ë£Œ ì¤‘...")
    if HAS_MONITORING and "metrics_collector" in globals():
        metrics_collector.stop()


async def periodic_health_update():
    """Periodic health metrics update"""
    while True:
        try:
            update_health_metrics()
            await asyncio.sleep(30)  # Update every 30 seconds
        except Exception as e:
            logger.error(f"Health metrics update error: {e}")
            await asyncio.sleep(30)


# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="MLOps IMDB Movie Rating Prediction API (Monitoring Edition)",
    description="""
    ğŸ¬ IMDB ì˜í™” í‰ì  ì˜ˆì¸¡ MLOps API with Comprehensive Monitoring

    ## ê¸°ëŠ¥
    - ì˜í™” í‰ì  ì˜ˆì¸¡ (Random Forest ëª¨ë¸)
    - ë°°ì¹˜ ì˜ˆì¸¡ ì§€ì›
    - ëª¨ë¸ ì •ë³´ ì¡°íšŒ
    - í—¬ìŠ¤ ì²´í¬
    - **ğŸ“Š Prometheus ë©”íŠ¸ë¦­ìŠ¤ ìˆ˜ì§‘**
    - **ğŸš¨ ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ**
    - **ğŸ“ˆ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**

    ## ëª¨ë‹ˆí„°ë§ ì—”ë“œí¬ì¸íŠ¸
    - `/metrics` - Prometheus ë©”íŠ¸ë¦­ìŠ¤
    - `/health` - ìƒì„¸ í—¬ìŠ¤ ì²´í¬
    - `/monitoring/status` - ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ìƒíƒœ

    ## ì‚¬ìš©ë˜ëŠ” í”¼ì²˜
    - startYear: ê°œë´‰ ì—°ë„
    - runtimeMinutes: ìƒì˜ ì‹œê°„
    - numVotes: íˆ¬í‘œ ìˆ˜

    ## ëª¨ë¸ ì„±ëŠ¥
    - RMSE: ~0.69
    - RÂ²: ~0.31
    """,
    version="1.1.0",
    lifespan=lifespan,
)


# Enable Prometheus metrics
@app.on_event("startup")
async def startup():
    Instrumentator().instrument(app).expose(app)


# Add Prometheus middleware safely
if HAS_MONITORING and PrometheusMiddleware is not None:
    try:
        app.add_middleware(PrometheusMiddleware, metrics_instance=metrics)
        logger.info("ğŸ“Š Prometheus middleware added successfully")
    except Exception as e:
        logger.warning(f"Failed to add Prometheus middleware: {e}")
        HAS_MONITORING = False

# CORS ì„¤ì • (ê°œë°œ í™˜ê²½ìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” êµ¬ì²´ì ì¸ ë„ë©”ì¸ ì§€ì •
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¼ìš°í„° ë“±ë¡
from .endpoints import router as prediction_router

app.include_router(prediction_router, tags=["predictions"])


@app.get("/metrics")
async def metrics_endpoint():
    """Prometheus metrics endpoint"""
    if not HAS_MONITORING:
        return Response(
            content='# Monitoring not enabled\n# TYPE info gauge\ninfo{version="1.1.0",status="monitoring_disabled"} 1\n',
            media_type="text/plain",
            status_code=200,  # Changed from 503 to 200
        )

    try:
        # Try multiprocess metrics collection first
        try:
            registry = CollectorRegistry()
            multiprocess.MultiProcessCollector(registry)
            metrics_data = generate_latest(registry)
        except (ValueError, OSError, Exception) as e:
            logger.warning(f"Multiprocess metrics failed, using default: {e}")
            # Fallback to default registry
            metrics_data = generate_latest()

        # Return as Response with correct content type
        return Response(content=metrics_data, media_type=CONTENT_TYPE_LATEST)

    except Exception as e:
        logger.error(f"Error generating metrics: {e}")
        # Return basic error metrics instead of failing
        error_metrics = f"""# Error generating metrics: {e}
        # TYPE mlops_api_error_total counter
        mlops_api_error_total{{error_type="metrics_generation"}} 1
        # TYPE mlops_api_info gauge
        mlops_api_info{{version="1.1.0",status="metrics_error"}} 1
        """
        return Response(
            content=error_metrics,
            media_type="text/plain",
            status_code=200,  # Return 200 with error info instead of 500
        )


@app.get("/monitoring/status")
async def monitoring_status():
    """Monitoring system status"""
    return {
        "monitoring_enabled": HAS_MONITORING,
        "metrics_collector_running": (
            metrics_collector.running
            if HAS_MONITORING and "metrics_collector" in globals()
            else False
        ),
        "prometheus_endpoint": "/metrics",
        "grafana_dashboard": "http://localhost:3000",
        "alertmanager": "http://localhost:9093",
        "services": {
            "prometheus": "http://localhost:9090",
            "grafana": "http://localhost:3000",
            "alertmanager": "http://localhost:9093",
        },
        "timestamp": datetime.now().isoformat(),
    }


@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ - API ì •ë³´ ì œê³µ"""

    # Record API call if monitoring enabled
    if HAS_MONITORING:
        metrics.http_requests_total.labels(
            method="GET", endpoint="/", status_code="200"
        ).inc()

    return JSONResponse(
        status_code=200,
        content={
            "message": "Welcome to the MLOps IMDB Movie Rating Prediction API (Monitoring Edition)",
            "version": "1.1.0",
            "description": "ì˜í™” í‰ì  ì˜ˆì¸¡ì„ ìœ„í•œ ëª¨ë‹ˆí„°ë§ ì§€ì› MLOps API",
            "endpoints": {
                "/predict/movie": "POST - ì˜í™” í”¼ì²˜ ê¸°ë°˜ ì˜ˆì¸¡",
                "/predict/batch": "POST - ë°°ì¹˜ ì˜ˆì¸¡",
                "/model/info": "GET - ëª¨ë¸ ì •ë³´ ì¡°íšŒ",
                "/health": "GET - í—¬ìŠ¤ ì²´í¬",
                "/metrics": "GET - Prometheus ë©”íŠ¸ë¦­ìŠ¤",
                "/monitoring/status": "GET - ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ìƒíƒœ",
            },
            "features_used": ["startYear", "runtimeMinutes", "numVotes"],
            "model_info": {
                "type": "Random Forest Regressor",
                "performance": "RMSE ~0.69, RÂ² ~0.31",
                "target": "IMDB Rating (1-10)",
            },
            "monitoring_enabled": HAS_MONITORING,
            "timestamp": datetime.now().isoformat(),
            "github": "https://github.com/AIBootcamp13/mlops-cloud-project-mlops_11",
        },
    )


@app.get("/health")
async def enhanced_health_check():
    """Enhanced health check with monitoring metrics"""
    try:
        from .endpoints import model_evaluator

        model_loaded = model_evaluator is not None

        # Get system health if monitoring available
        health_data = {
            "status": "healthy" if model_loaded else "degraded",
            "timestamp": datetime.now().isoformat(),
            "version": "1.1.0",
            "model_loaded": model_loaded,
            "monitoring_enabled": HAS_MONITORING,
        }

        if HAS_MONITORING:
            try:
                import os

                import psutil

                process = psutil.Process(os.getpid())
                memory_info = process.memory_info()

                health_data["system_metrics"] = {
                    "memory_usage_mb": round(memory_info.rss / 1024 / 1024, 2),
                    "cpu_percent": process.cpu_percent(),
                    "num_threads": process.num_threads(),
                }

                # Update health metrics safely
                if "update_health_metrics" in globals() and callable(
                    update_health_metrics
                ):
                    update_health_metrics()

            except ImportError:
                health_data["system_metrics"] = "psutil not available"
            except Exception as e:
                health_data["system_metrics"] = f"Error: {str(e)}"

        if model_loaded and HAS_MONITORING:
            if model_evaluator is not None:
                model_info = model_evaluator.get_model_info()
                health_data["model_info"] = model_info
            else:
                health_data["model_info"] = "Model evaluator not available"

            # Record model status safely
            if "metrics" in globals() and hasattr(metrics, "set_active_users"):
                try:
                    metrics.set_active_users(1)  # Simple active user tracking
                except Exception as e:
                    logger.warning(f"Failed to set active users metric: {e}")

        return JSONResponse(status_code=200, content=health_data)

    except Exception as e:
        logger.error(f"í—¬ìŠ¤ì²´í¬ ì˜¤ë¥˜: {e}")
        error_response = {
            "status": "unhealthy",
            "timestamp": datetime.now().isoformat(),
            "version": "1.1.0",
            "model_loaded": False,
            "error": str(e),
        }

        if HAS_MONITORING and "metrics" in globals():
            try:
                metrics.http_requests_total.labels(
                    method="GET", endpoint="/health", status_code="500"
                ).inc()
            except Exception as metrics_error:
                logger.warning(f"Metrics recording failed: {metrics_error}")

        return JSONResponse(status_code=500, content=error_response)


@app.get("/metrics/custom")
async def custom_metrics():
    """Custom business metrics endpoint"""
    if not HAS_MONITORING:
        return {"error": "Monitoring not available"}

    try:
        # Example custom metrics calculation
        from .endpoints import model_evaluator

        custom_data: Dict[str, Union[str, int, float]] = {
            "timestamp": datetime.now().isoformat(),  # str
            "model_status": "loaded" if model_evaluator else "not_loaded",  # str
            "api_version": "1.1.0",  # str
        }

        # Record some example business metrics
        if model_evaluator:
            # Simulate some business metrics
            metrics.record_prediction_rating(7.5)  # Example rating
            metrics.set_active_users(5)  # Example active users

            custom_data["predictions_today"] = 42  # Example data
            custom_data["average_rating"] = 7.2  # Example data
            custom_data["active_users"] = 5

            custom_data["predictions_today"] = 42  # Example data
            custom_data["average_rating"] = 7.2  # Example data
            custom_data["active_users"] = 5

        return custom_data

    except Exception as e:
        logger.error(f"Custom metrics error: {e}")
        return {"error": str(e)}


# ëª¨ë‹ˆí„°ë§ ê´€ë ¨ ë¯¸ë“¤ì›¨ì–´
@app.middleware("http")
async def add_monitoring_headers(request: Request, call_next):
    """Add monitoring headers to responses"""
    response = await call_next(request)

    # Add monitoring-related headers
    response.headers["X-MLOps-Version"] = "1.1.0"
    response.headers["X-Monitoring-Enabled"] = str(HAS_MONITORING)

    if HAS_MONITORING:
        response.headers["X-Prometheus-Metrics"] = "/metrics"
        response.headers["X-Health-Check"] = "/health"

    return response


@app.exception_handler(StarletteHTTPException)
async def http_exception_handler(request: Request, exc: StarletteHTTPException):
    if exc.status_code == 404:
        if HAS_MONITORING:
            metrics.http_requests_total.labels(
                method=request.method, endpoint=request.url.path, status_code="404"
            ).inc()
        return JSONResponse(
            status_code=404,
            content={
                "error": "Not Found",
                "message": "ìš”ì²­í•œ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "available_endpoints": [
                    "/",
                    "/predict/movie",
                    "/predict/batch",
                    "/model/info",
                    "/health",
                    "/metrics",
                    "/monitoring/status",
                    "/docs",
                ],
            },
        )
    else:
        if HAS_MONITORING and "metrics" in globals():
            metrics.http_requests_total.labels(
                method=request.method, endpoint=request.url.path, status_code="500"
            ).inc()
        return JSONResponse(
            status_code=exc.status_code,
            content={
                "error": (
                    exc.detail if exc.status_code != 500 else "Internal Server Error"
                ),
                "message": (
                    "An error occurred."
                    if exc.status_code != 500
                    else "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                ),
                "monitoring": (
                    "Check /metrics for system health"
                    if HAS_MONITORING and exc.status_code == 500
                    else None
                ),
                "timestamp": datetime.now().isoformat(),
            },
        )


# ê°œë°œ ì„œë²„ ì‹¤í–‰ (python src/api/main_with_metrics.pyë¡œ ì‹¤í–‰ ê°€ëŠ¥)
if __name__ == "__main__":
    import uvicorn

    logger.info("ëª¨ë‹ˆí„°ë§ ì§€ì› ê°œë°œ ì„œë²„ ì‹œì‘...")
    uvicorn.run(
        "src.api.main_with_metrics:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info",
    )
