import logging
import pickle
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class IMDbPreprocessor:
    """
    IMDb ì˜í™” ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    MLOps ì¹œí™”ì  ì„¤ê³„: ì¬ì‚¬ìš© ê°€ëŠ¥, ìŠ¤ì¼€ì¼ëŸ¬ë¸”, ê²€ì¦ ë‚´ì¥
    """

    def __init__(self, processed_data_path: str = "data/processed"):
        self.processed_data_path = Path(processed_data_path)
        self.processed_data_path.mkdir(exist_ok=True)

        # ì „ì²˜ë¦¬ ì„¤ì •
        self.top_genres = None  # ìƒìœ„ ì¥ë¥´ ëª©ë¡
        self.scaler = StandardScaler()
        self.feature_names = []
        self.is_fitted = False

        # í•˜ì´í¼íŒŒë¼ë¯¸í„°
        self.top_n_genres = 8  # ìƒìœ„ 8ê°œ ì¥ë¥´ë§Œ ì‚¬ìš©
        self.min_year = 1900  # ìµœì†Œ ì—°ë„
        self.max_year = 2025  # ìµœëŒ€ ì—°ë„

    def load_data(self) -> pd.DataFrame:
        """ì²˜ë¦¬ëœ ì˜í™” ë°ì´í„° ë¡œë“œ"""
        data_path = self.processed_data_path / "movies_with_ratings.csv"

        if not data_path.exists():
            raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_path}")

        logger.info(f"ë°ì´í„° ë¡œë“œ: {data_path}")
        df = pd.read_csv(data_path)
        logger.info(f"ë¡œë“œëœ ë°ì´í„°: {len(df):,} í–‰")

        return df

    def extract_top_genres(self, df: pd.DataFrame) -> List[str]:
        """ìƒìœ„ ì¥ë¥´ ì¶”ì¶œ"""
        logger.info("ìƒìœ„ ì¥ë¥´ ë¶„ì„ ì¤‘...")

        # ëª¨ë“  ì¥ë¥´ ìˆ˜ì§‘
        all_genres = []
        for genres_str in df["genres"].dropna():
            if genres_str and genres_str != "\\N":
                genres = [g.strip() for g in genres_str.split(",")]
                all_genres.extend(genres)

        # ì¥ë¥´ ë¹ˆë„ ê³„ì‚°
        genre_counts = pd.Series(all_genres).value_counts()
        top_genres = genre_counts.head(self.top_n_genres).index.tolist()

        logger.info(f"ìƒìœ„ {self.top_n_genres}ê°œ ì¥ë¥´: {top_genres}")

        return top_genres

    def create_genre_features(
        self, df: pd.DataFrame, genres_list: List[str]
    ) -> pd.DataFrame:
        """ì¥ë¥´ ì›-í•« ì¸ì½”ë”© í”¼ì²˜ ìƒì„±"""
        logger.info("ì¥ë¥´ í”¼ì²˜ ìƒì„± ì¤‘...")

        genre_df = df.copy()

        # ê° ì¥ë¥´ë³„ ì›-í•« ì¸ì½”ë”©
        for genre in genres_list:
            column_name = f"genre_{genre.lower().replace('-', '_')}"
            genre_df[column_name] = genre_df["genres"].apply(
                lambda x: 1 if isinstance(x, str) and genre in x else 0
            )

        logger.info(f"ìƒì„±ëœ ì¥ë¥´ í”¼ì²˜: {len(genres_list)}ê°œ")
        return genre_df

    def create_numerical_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ìˆ«ìí˜• í”¼ì²˜ ìƒì„± ë° ì •ì œ"""
        logger.info("ìˆ«ìí˜• í”¼ì²˜ ìƒì„± ì¤‘...")

        feature_df = df.copy()

        # 1. ì—°ë„ í”¼ì²˜ (ì •ê·œí™”)
        feature_df["year_normalized"] = pd.to_numeric(
            feature_df["startYear"], errors="coerce"
        )
        feature_df["year_normalized"] = feature_df["year_normalized"].fillna(
            feature_df["year_normalized"].median()
        )

        # ì—°ë„ ë²”ìœ„ ì œí•œ
        feature_df["year_normalized"] = feature_df["year_normalized"].clip(
            self.min_year, self.max_year
        )

        # 2. ëŸ°íƒ€ì„ í”¼ì²˜ (ê²°ì¸¡ê°’ ì²˜ë¦¬)
        feature_df["runtime_minutes"] = pd.to_numeric(
            feature_df["runtimeMinutes"], errors="coerce"
        )
        runtime_median = feature_df["runtime_minutes"].median()
        feature_df["runtime_minutes"] = feature_df["runtime_minutes"].fillna(
            runtime_median
        )

        # 3. íˆ¬í‘œìˆ˜ í”¼ì²˜ (ë¡œê·¸ ë³€í™˜)
        feature_df["votes_log"] = np.log1p(
            feature_df["numVotes"]
        )  # log(1+x) for stability

        # 4. ì œëª© ê¸¸ì´ í”¼ì²˜
        feature_df["title_length"] = feature_df["primaryTitle"].str.len()

        # 5. íƒ€ê²Ÿ ë³€ìˆ˜ (í‰ì )
        feature_df["target_rating"] = feature_df["averageRating"]

        logger.info("ìˆ«ìí˜• í”¼ì²˜ ìƒì„± ì™„ë£Œ")
        return feature_df

    def prepare_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
        """ìµœì¢… í”¼ì²˜ ë°ì´í„°í”„ë ˆì„ ì¤€ë¹„"""
        logger.info("ìµœì¢… í”¼ì²˜ ì¤€ë¹„ ì¤‘...")

        # ìƒìœ„ ì¥ë¥´ ì¶”ì¶œ (í›ˆë ¨ ì‹œì—ë§Œ)
        if self.top_genres is None:
            self.top_genres = self.extract_top_genres(df)

        # ì¥ë¥´ í”¼ì²˜ ìƒì„±
        df_with_genres = self.create_genre_features(df, self.top_genres)

        # ìˆ«ìí˜• í”¼ì²˜ ìƒì„±
        df_with_features = self.create_numerical_features(df_with_genres)

        # ìµœì¢… í”¼ì²˜ ì»¬ëŸ¼ ì„ íƒ
        feature_columns = []

        # ì¥ë¥´ í”¼ì²˜ ì¶”ê°€
        for genre in self.top_genres:
            column_name = f"genre_{genre.lower().replace('-', '_')}"
            feature_columns.append(column_name)

        # ìˆ«ìí˜• í”¼ì²˜ ì¶”ê°€
        numerical_features = [
            "year_normalized",
            "runtime_minutes",
            "votes_log",
            "title_length",
        ]
        feature_columns.extend(numerical_features)

        # í”¼ì²˜ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        X = df_with_features[feature_columns].copy()

        # ê²°ì¸¡ê°’ ìµœì¢… ì²´í¬
        X = X.fillna(0)

        logger.info(f"ìµœì¢… í”¼ì²˜: {len(feature_columns)}ê°œ")
        logger.info(f"í”¼ì²˜ ëª©ë¡: {feature_columns}")

        return X, feature_columns

    def fit_transform(
        self, df: pd.DataFrame
    ) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        """í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•œ ì „ì²˜ë¦¬ (fit + transform)"""
        logger.info("ğŸ”§ í›ˆë ¨ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")

        # í”¼ì²˜ ì¤€ë¹„
        X, feature_names = self.prepare_features(df)
        self.feature_names = feature_names

        # íƒ€ê²Ÿ ì¤€ë¹„
        y = df["averageRating"].values

        # ìŠ¤ì¼€ì¼ë§ (StandardScaler)
        X_scaled = self.scaler.fit_transform(X)

        self.is_fitted = True
        logger.info("âœ… í›ˆë ¨ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")

        return X_scaled, y, feature_names

    def transform(self, df: pd.DataFrame) -> np.ndarray:
        """ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ì „ì²˜ë¦¬ (transform only)"""
        if not self.is_fitted:
            raise ValueError(
                "ì „ì²˜ë¦¬ê¸°ê°€ ì•„ì§ fitë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. fit_transformì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."
            )

        logger.info("ğŸ”„ ìƒˆë¡œìš´ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")

        # í”¼ì²˜ ì¤€ë¹„ (ë™ì¼í•œ ì¥ë¥´ ëª©ë¡ ì‚¬ìš©)
        X, _ = self.prepare_features(df)

        # ìŠ¤ì¼€ì¼ë§ (ì´ë¯¸ fitëœ scaler ì‚¬ìš©)
        X_scaled = self.scaler.transform(X)

        logger.info("âœ… ìƒˆë¡œìš´ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")

        return X_scaled

    def create_train_test_split(
        self,
        X: np.ndarray,
        y: np.ndarray,
        test_size: float = 0.2,
        random_state: int = 42,
    ) -> Tuple:
        """í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• """
        logger.info(f"ë°ì´í„° ë¶„í•  ì¤‘... (test_size={test_size})")

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=None
        )

        logger.info(f"í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]:,} ìƒ˜í”Œ")
        logger.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]:,} ìƒ˜í”Œ")

        return X_train, X_test, y_train, y_test

    def save_preprocessor(self, filepath: str = None):
        """ì „ì²˜ë¦¬ê¸° ì €ì¥ (ì¬ì‚¬ìš©ì„ ìœ„í•´)"""
        if filepath is None:
            filepath = self.processed_data_path / "preprocessor.pkl"

        preprocessor_data = {
            "top_genres": self.top_genres,
            "scaler": self.scaler,
            "feature_names": self.feature_names,
            "is_fitted": self.is_fitted,
            "top_n_genres": self.top_n_genres,
            "min_year": self.min_year,
            "max_year": self.max_year,
        }

        with open(filepath, "wb") as f:
            pickle.dump(preprocessor_data, f)

        logger.info(f"ì „ì²˜ë¦¬ê¸° ì €ì¥: {filepath}")

    def load_preprocessor(self, filepath: str = None):
        """ì €ì¥ëœ ì „ì²˜ë¦¬ê¸° ë¡œë“œ"""
        if filepath is None:
            filepath = self.processed_data_path / "preprocessor.pkl"

        with open(filepath, "rb") as f:
            preprocessor_data = pickle.load(f)

        self.top_genres = preprocessor_data["top_genres"]
        self.scaler = preprocessor_data["scaler"]
        self.feature_names = preprocessor_data["feature_names"]
        self.is_fitted = preprocessor_data["is_fitted"]
        self.top_n_genres = preprocessor_data["top_n_genres"]
        self.min_year = preprocessor_data["min_year"]
        self.max_year = preprocessor_data["max_year"]

        logger.info(f"ì „ì²˜ë¦¬ê¸° ë¡œë“œ: {filepath}")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì „ì²˜ë¦¬ê¸° ìƒì„±
    preprocessor = IMDbPreprocessor()

    # ë°ì´í„° ë¡œë“œ
    df = preprocessor.load_data()

    # í›ˆë ¨ ë°ì´í„° ì „ì²˜ë¦¬
    X, y, feature_names = preprocessor.fit_transform(df)

    # ë°ì´í„° ë¶„í• 
    X_train, X_test, y_train, y_test = preprocessor.create_train_test_split(X, y)

    # ì „ì²˜ë¦¬ê¸° ì €ì¥
    preprocessor.save_preprocessor()

    print(f"ğŸ¯ ì „ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"  í”¼ì²˜ ìˆ˜: {len(feature_names)}")
    print(f"  í›ˆë ¨ ë°ì´í„°: {X_train.shape}")
    print(f"  í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")
    print(f"  í”¼ì²˜ ëª©ë¡: {feature_names}")
