# 3.6 ë°ì´í„° ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•

## ğŸ“‹ ê°œìš”

**ëª©í‘œ**: ì½”ë“œë¿ë§Œ ì•„ë‹ˆë¼ ë°ì´í„°ì™€ ëª¨ë¸ì˜ ì²´ê³„ì  ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•
**ì†Œìš” ì‹œê°„**: 3-4ì‹œê°„
**ë‚œì´ë„**: ì¤‘ê¸‰

WSL Ubuntu í™˜ê²½ì—ì„œ Docker ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„° ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

---

## ğŸ¯ 1. DVC (Data Version Control) í™˜ê²½ ì¤€ë¹„

### 1.1 í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# WSL Ubuntu í™˜ê²½ì—ì„œ ì‹¤í–‰
cd /mnt/c/dev/movie-mlops

# ê°œë°œ í™˜ê²½ ì˜ì¡´ì„± ì„¤ì¹˜ (DVC í¬í•¨)
pip install -r docs/03-version-control/requirements-dev.txt

# DVC ì„¤ì¹˜ í™•ì¸
dvc version
```

### 1.2 DVC ì´ˆê¸° ì„¤ì •

```bash
# DVC ì´ˆê¸°í™”
dvc init

# Gitì— DVC ì„¤ì • íŒŒì¼ ì¶”ê°€
git add .dvc .dvcignore
git commit -m "chore: initialize DVC for data version control"
```

### 1.3 ì›ê²© ìŠ¤í† ë¦¬ì§€ ì„¤ì • (ë¡œì»¬ ì‹œë®¬ë ˆì´ì…˜)

```bash
# ë¡œì»¬ ì›ê²© ìŠ¤í† ë¦¬ì§€ ë””ë ‰í„°ë¦¬ ìƒì„±
mkdir -p data/dvc-storage

# DVC ì›ê²© ìŠ¤í† ë¦¬ì§€ ì„¤ì •
dvc remote add -d local_storage data/dvc-storage
dvc remote modify local_storage url data/dvc-storage

# ì„¤ì • ì»¤ë°‹
git add .dvc/config
git commit -m "config: add local DVC remote storage"
```

---

## ğŸ¯ 2. ë°ì´í„° íŒŒì¼ ë²„ì „ ê´€ë¦¬ êµ¬í˜„

### 2.1 í˜„ì¬ ë°ì´í„° íŒŒì¼ DVC ì¶”ì  ì„¤ì •

```bash
# í˜„ì¬ ì¡´ì¬í•˜ëŠ” ì›ì‹œ ë°ì´í„°ë¥¼ DVCë¡œ ì¶”ì 
if [ -f "data/raw/movies/bulk_collection_20250605_024954.json" ]; then
    dvc add data/raw/movies/bulk_collection_20250605_024954.json
    git add data/raw/movies/bulk_collection_20250605_024954.json.dvc
    git add .gitignore
    git commit -m "data: add TMDB bulk collection data to DVC tracking"
fi

# ì²˜ë¦¬ëœ ë°ì´í„°ë„ DVC ì¶”ì 
if [ -d "data/processed" ] && [ "$(ls -A data/processed)" ]; then
    dvc add data/processed
    git add data/processed.dvc
    git add .gitignore
    git commit -m "data: add processed data to DVC tracking"
fi
```

### 2.2 ë°ì´í„° íŒŒì´í”„ë¼ì¸ DVC ì •ì˜

```bash
# DVC íŒŒì´í”„ë¼ì¸ ì„¤ì • íŒŒì¼ ìƒì„±
cat > dvc.yaml << 'EOF'
stages:
  data_collection:
    cmd: python scripts/daily_collection.py
    deps:
    - scripts/daily_collection.py
    - src/data/crawlers/tmdb_crawler.py
    - config/development.yaml
    outs:
    - data/raw/movies/daily
    metrics:
    - data/raw/movies/collection_stats.json:
        cache: false
    
  data_validation:
    cmd: python src/data/validation/data_quality_checker.py
    deps:
    - src/data/validation/data_quality_checker.py
    - data/raw/movies/daily
    outs:
    - data/staging/validated
    metrics:
    - logs/data/validation_results.json:
        cache: false
    
  feature_engineering:
    cmd: python src/features/engineering/tmdb_processor.py
    deps:
    - src/features/engineering/tmdb_processor.py
    - data/staging/validated
    outs:
    - data/processed/features
    metrics:
    - data/processed/feature_stats.json:
        cache: false
    
  feature_store_update:
    cmd: python src/features/store/simple_feature_store.py
    deps:
    - src/features/store/simple_feature_store.py
    - data/processed/features
    outs:
    - data/feature_store/features
    metrics:
    - data/feature_store/metadata/feature_metrics.json:
        cache: false
EOF

git add dvc.yaml
git commit -m "config: add DVC pipeline definition"
```

### 2.3 ë°ì´í„° ë©”íŠ¸ë¦­ ì¶”ì  ì„¤ì •

```bash
# ë©”íŠ¸ë¦­ ì •ì˜ íŒŒì¼ ìƒì„±
cat > dvclive/metrics.json << 'EOF'
{
    "data_quality": {
        "completeness": 0.95,
        "accuracy": 0.92,
        "consistency": 0.98,
        "validity": 0.94
    },
    "data_volume": {
        "raw_files_count": 100,
        "raw_size_mb": 250.5,
        "processed_files_count": 85,
        "processed_size_mb": 180.3
    },
    "feature_engineering": {
        "features_count": 45,
        "feature_coverage": 0.96,
        "null_ratio": 0.02
    }
}
EOF

mkdir -p dvclive
git add dvclive/metrics.json
git commit -m "config: add data metrics tracking"
```

---

## ğŸ¯ 3. Docker ì»¨í…Œì´ë„ˆì—ì„œ DVC í™œìš©

### 3.1 DVCìš© Docker ì„¤ì • ì—…ë°ì´íŠ¸

```dockerfile
# Dockerfile.devì— DVC ê´€ë ¨ ì„¤ì • ì¶”ê°€
cat >> Dockerfile.dev << 'EOF'

# DVC ì„¤ì¹˜ ë° ì„¤ì •
RUN pip install dvc[all]==3.55.2

# DVC ìºì‹œ ë””ë ‰í„°ë¦¬ ì„¤ì •
ENV DVC_CACHE_DIR=/app/.dvc/cache
RUN mkdir -p /app/.dvc/cache

# DVC ê¶Œí•œ ì„¤ì •
RUN chown -R mlops:mlops /app/.dvc
EOF
```

### 3.2 Docker Composeì— DVC ë³¼ë¥¨ ì¶”ê°€

```yaml
# docker-compose.ymlì— DVC ê´€ë ¨ ë³¼ë¥¨ ì¶”ê°€
cat >> docker-compose.yml << 'EOF'

  # DVC ì „ìš© ì„œë¹„ìŠ¤ (ì„ íƒì‚¬í•­)
  dvc-service:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: movie-mlops-dvc
    volumes:
      - .:/app
      - dvc_cache:/app/.dvc/cache
      - ./data:/app/data
    environment:
      - DVC_CACHE_DIR=/app/.dvc/cache
    command: tail -f /dev/null
    networks:
      - mlops-network

volumes:
  dvc_cache:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/dvc-cache
EOF
```

### 3.3 DVC ì»¨í…Œì´ë„ˆ í…ŒìŠ¤íŠ¸

```bash
# DVC ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d dvc-service

# DVC ì»¨í…Œì´ë„ˆì—ì„œ ìƒíƒœ í™•ì¸
docker-compose exec dvc-service dvc status

# DVC íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
docker-compose exec dvc-service dvc repro --dry

# ì¢…ë£Œ
docker-compose down
```

---

## ğŸ¯ 4. ê°„ë‹¨í•œ íŒŒì¼ ê¸°ë°˜ ë°ì´í„° ë²„ì „ ê´€ë¦¬

### 4.1 ë°ì´í„° ë²„ì „ ê´€ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

```bash
# ë°ì´í„° ë²„ì „ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹° ì‘ì„±
cat > src/data/utils/data_versioning.py << 'EOF'
"""
ë°ì´í„° ë²„ì „ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°
DVC ëŒ€ì•ˆìœ¼ë¡œ íŒŒì¼ëª… ê¸°ë°˜ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ
"""
import os
import json
import hashlib
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

class SimpleDataVersioning:
    """ê°„ë‹¨í•œ íŒŒì¼ ê¸°ë°˜ ë°ì´í„° ë²„ì „ ê´€ë¦¬"""
    
    def __init__(self, base_path: str = "data"):
        self.base_path = Path(base_path)
        self.registry_file = self.base_path / "data_registry.json"
        self.registry = self._load_registry()
    
    def _load_registry(self) -> Dict[str, Any]:
        """ë°ì´í„° ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë¡œë“œ"""
        if self.registry_file.exists():
            with open(self.registry_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _save_registry(self):
        """ë°ì´í„° ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì €ì¥"""
        self.registry_file.parent.mkdir(parents=True, exist_ok=True)
        with open(self.registry_file, 'w', encoding='utf-8') as f:
            json.dump(self.registry, f, indent=2, ensure_ascii=False)
    
    def _calculate_checksum(self, file_path: Path) -> str:
        """íŒŒì¼ ì²´í¬ì„¬ ê³„ì‚°"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def version_data(self, 
                    file_path: str,
                    data_name: str,
                    version: str = None,
                    description: str = None) -> str:
        """ë°ì´í„° íŒŒì¼ ë²„ì „ ë“±ë¡"""
        source_path = Path(file_path)
        if not source_path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")
        
        # ë²„ì „ ìë™ ìƒì„±
        if version is None:
            version = datetime.now().strftime("v%Y%m%d_%H%M%S")
        
        # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
        file_stats = source_path.stat()
        checksum = self._calculate_checksum(source_path)
        
        # ë²„ì „ íŒŒì¼ëª… ìƒì„±
        suffix = source_path.suffix
        versioned_name = f"{data_name}_{version}{suffix}"
        versioned_path = source_path.parent / versioned_name
        
        # íŒŒì¼ ë³µì‚¬
        import shutil
        shutil.copy2(source_path, versioned_path)
        
        # ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
        if data_name not in self.registry:
            self.registry[data_name] = {}
        
        self.registry[data_name][version] = {
            "file": versioned_name,
            "original_file": source_path.name,
            "created": datetime.now().isoformat(),
            "size_bytes": file_stats.st_size,
            "size_mb": round(file_stats.st_size / (1024*1024), 2),
            "checksum": checksum,
            "description": description or f"Version {version} of {data_name}"
        }
        
        # latest ì‹¬ë³¼ë¦­ ë§í¬ ìƒì„±
        latest_link = source_path.parent / f"{data_name}_latest{suffix}"
        if latest_link.exists() or latest_link.is_symlink():
            latest_link.unlink()
        latest_link.symlink_to(versioned_name)
        
        self._save_registry()
        return versioned_path.as_posix()
    
    def list_versions(self, data_name: str) -> Dict[str, Any]:
        """íŠ¹ì • ë°ì´í„°ì˜ ëª¨ë“  ë²„ì „ ì¡°íšŒ"""
        return self.registry.get(data_name, {})
    
    def get_latest_version(self, data_name: str) -> Optional[str]:
        """ìµœì‹  ë²„ì „ ì¡°íšŒ"""
        versions = self.list_versions(data_name)
        if not versions:
            return None
        return max(versions.keys())
    
    def get_version_info(self, data_name: str, version: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ë²„ì „ ì •ë³´ ì¡°íšŒ"""
        return self.registry.get(data_name, {}).get(version)

# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    versioning = SimpleDataVersioning()
    
    # í˜„ì¬ ë°ì´í„° íŒŒì¼ë“¤ ë²„ì „ ë“±ë¡ ì˜ˆì œ
    # versioning.version_data(
    #     "data/raw/movies/bulk_collection_20250605_024954.json",
    #     "tmdb_bulk_movies",
    #     description="Initial TMDB movie data collection"
    # )
EOF

# ì‹¤í–‰ ê¶Œí•œ ì„¤ì •
chmod +x src/data/utils/data_versioning.py
```

### 4.2 ë°ì´í„° ë²„ì „ ê´€ë¦¬ ëª…ë ¹ì–´ ìŠ¤í¬ë¦½íŠ¸

```bash
# ë°ì´í„° ë²„ì „ ê´€ë¦¬ CLI ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
cat > scripts/data_version_manager.py << 'EOF'
#!/usr/bin/env python3
"""
ë°ì´í„° ë²„ì „ ê´€ë¦¬ CLI ë„êµ¬
"""
import argparse
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ íŒ¨ìŠ¤ì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.data.utils.data_versioning import SimpleDataVersioning

def main():
    parser = argparse.ArgumentParser(description="ë°ì´í„° ë²„ì „ ê´€ë¦¬ CLI")
    subparsers = parser.add_subparsers(dest='command', help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´')
    
    # version ëª…ë ¹ì–´
    version_parser = subparsers.add_parser('version', help='ë°ì´í„° íŒŒì¼ ë²„ì „ ë“±ë¡')
    version_parser.add_argument('file_path', help='ë²„ì „ ë“±ë¡í•  íŒŒì¼ ê²½ë¡œ')
    version_parser.add_argument('data_name', help='ë°ì´í„° ì´ë¦„')
    version_parser.add_argument('--version', help='ë²„ì „ ëª… (ê¸°ë³¸ê°’: ìë™ ìƒì„±)')
    version_parser.add_argument('--description', help='ë²„ì „ ì„¤ëª…')
    
    # list ëª…ë ¹ì–´
    list_parser = subparsers.add_parser('list', help='ë°ì´í„° ë²„ì „ ëª©ë¡ ì¡°íšŒ')
    list_parser.add_argument('data_name', help='ë°ì´í„° ì´ë¦„')
    
    # info ëª…ë ¹ì–´
    info_parser = subparsers.add_parser('info', help='íŠ¹ì • ë²„ì „ ì •ë³´ ì¡°íšŒ')
    info_parser.add_argument('data_name', help='ë°ì´í„° ì´ë¦„')
    info_parser.add_argument('version', help='ë²„ì „ëª…')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    versioning = SimpleDataVersioning()
    
    if args.command == 'version':
        try:
            versioned_path = versioning.version_data(
                args.file_path,
                args.data_name,
                args.version,
                args.description
            )
            print(f"âœ… ë°ì´í„° ë²„ì „ ë“±ë¡ ì™„ë£Œ: {versioned_path}")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
            sys.exit(1)
    
    elif args.command == 'list':
        versions = versioning.list_versions(args.data_name)
        if not versions:
            print(f"âŒ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.data_name}")
            return
        
        print(f"ğŸ“‹ {args.data_name} ë²„ì „ ëª©ë¡:")
        for version, info in versions.items():
            print(f"  - {version}: {info['file']} ({info['size_mb']}MB) - {info['created']}")
    
    elif args.command == 'info':
        info = versioning.get_version_info(args.data_name, args.version)
        if not info:
            print(f"âŒ ë²„ì „ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.data_name} {args.version}")
            return
        
        print(f"ğŸ“Š {args.data_name} {args.version} ì •ë³´:")
        for key, value in info.items():
            print(f"  - {key}: {value}")

if __name__ == "__main__":
    main()
EOF

chmod +x scripts/data_version_manager.py
```

---

## ğŸ¯ 5. Git í†µí•© ë° ìë™í™”

### 5.1 ë°ì´í„° ë²„ì „ ê´€ë¦¬ Git í›… ì„¤ì •

```bash
# ë°ì´í„° ë³€ê²½ ê°ì§€ pre-commit í›… ìƒì„±
cat > .git/hooks/pre-commit-data-check << 'EOF'
#!/bin/bash
# ë°ì´í„° íŒŒì¼ ë³€ê²½ ê°ì§€ ë° ìë™ ë²„ì „ ê´€ë¦¬

# ë°ì´í„° íŒŒì¼ ë³€ê²½ ê°ì§€
changed_data_files=$(git diff --cached --name-only | grep -E '\.(json|csv|parquet|pkl)$' | grep -E '^data/')

if [ -n "$changed_data_files" ]; then
    echo "ğŸ” ë°ì´í„° íŒŒì¼ ë³€ê²½ ê°ì§€:"
    echo "$changed_data_files"
    
    # ì‚¬ìš©ìì—ê²Œ ë°ì´í„° ë²„ì „ ê´€ë¦¬ í™•ì¸
    echo "ğŸ“ ë°ì´í„° ë²„ì „ ê´€ë¦¬ë¥¼ ìœ„í•´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:"
    echo "   python scripts/data_version_manager.py version <file_path> <data_name>"
    echo ""
    echo "DVCë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°:"
    echo "   dvc add <file_path>"
    echo "   git add <file_path>.dvc"
    echo ""
    echo "ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N)"
    read -r response
    if [[ ! $response =~ ^[Yy]$ ]]; then
        echo "âŒ ì»¤ë°‹ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤."
        exit 1
    fi
fi
EOF

chmod +x .git/hooks/pre-commit-data-check
```

### 5.2 .gitignore ì—…ë°ì´íŠ¸

```bash
# .gitignoreì— ë°ì´í„° ë²„ì „ ê´€ë¦¬ ê´€ë ¨ í•­ëª© ì¶”ê°€
cat >> .gitignore << 'EOF'

# ë°ì´í„° ë²„ì „ ê´€ë¦¬
/data/dvc-storage/
/data/dvc-cache/
*.dvc
.dvc/cache/

# ì„ì‹œ ë°ì´í„° íŒŒì¼
*_latest.*
*_temp.*
*_staging.*
EOF

git add .gitignore
git commit -m "config: update gitignore for data versioning"
```

---

## ğŸ¯ 6. ë°ì´í„° íŒŒì´í”„ë¼ì¸ ë²„ì „ ê´€ë¦¬ í…ŒìŠ¤íŠ¸

### 6.1 í˜„ì¬ ë°ì´í„°ë¡œ ë²„ì „ ê´€ë¦¬ í…ŒìŠ¤íŠ¸

```bash
# í˜„ì¬ ì¡´ì¬í•˜ëŠ” ë°ì´í„° íŒŒì¼ í™•ì¸
echo "ğŸ“ í˜„ì¬ ë°ì´í„° íŒŒì¼ë“¤:"
find data/ -type f -name "*.json" -o -name "*.parquet" -o -name "*.csv" | head -10

# ë°ì´í„° ë²„ì „ ê´€ë¦¬ í…ŒìŠ¤íŠ¸
if [ -f "data/raw/movies/bulk_collection_20250605_024954.json" ]; then
    echo "ğŸ§ª ë°ì´í„° ë²„ì „ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘..."
    
    # ê°„ë‹¨í•œ ë²„ì „ ê´€ë¦¬ í…ŒìŠ¤íŠ¸
    python scripts/data_version_manager.py version \
        "data/raw/movies/bulk_collection_20250605_024954.json" \
        "tmdb_bulk_movies" \
        --description "Initial TMDB bulk collection data"
    
    # ë²„ì „ ëª©ë¡ í™•ì¸
    python scripts/data_version_manager.py list tmdb_bulk_movies
    
    echo "âœ… ë°ì´í„° ë²„ì „ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ"
fi
```

### 6.2 DVC íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (ìˆëŠ” ê²½ìš°)

```bash
# DVC ìƒíƒœ í™•ì¸
if command -v dvc &> /dev/null; then
    echo "ğŸ§ª DVC íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸..."
    
    # DVC ìƒíƒœ í™•ì¸
    dvc status
    
    # íŒŒì´í”„ë¼ì¸ DAG ì‹œê°í™”
    dvc dag
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (dry run)
    dvc repro --dry
    
    echo "âœ… DVC í…ŒìŠ¤íŠ¸ ì™„ë£Œ"
else
    echo "â„¹ï¸  DVCê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ ë²„ì „ ê´€ë¦¬ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
fi
```

---

## ğŸ¯ 7. ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì„¤ì •

### 7.1 ë°ì´í„° ë³€ê²½ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸

```bash
# ë°ì´í„° ë³€ê²½ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
cat > scripts/data_change_monitor.py << 'EOF'
#!/usr/bin/env python3
"""
ë°ì´í„° ë³€ê²½ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸
"""
import os
import json
import time
import hashlib
from pathlib import Path
from datetime import datetime
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class DataChangeHandler(FileSystemEventHandler):
    """ë°ì´í„° íŒŒì¼ ë³€ê²½ ê°ì§€ í•¸ë“¤ëŸ¬"""
    
    def __init__(self, data_dirs):
        self.data_dirs = data_dirs
        self.change_log = Path("logs/data/data_changes.log")
        self.change_log.parent.mkdir(parents=True, exist_ok=True)
    
    def on_modified(self, event):
        if event.is_directory:
            return
        
        file_path = Path(event.src_path)
        if file_path.suffix in ['.json', '.csv', '.parquet', '.pkl']:
            self._log_change(file_path, "modified")
    
    def on_created(self, event):
        if event.is_directory:
            return
        
        file_path = Path(event.src_path)
        if file_path.suffix in ['.json', '.csv', '.parquet', '.pkl']:
            self._log_change(file_path, "created")
    
    def _log_change(self, file_path, change_type):
        """ë°ì´í„° ë³€ê²½ ë¡œê·¸ ê¸°ë¡"""
        timestamp = datetime.now().isoformat()
        
        log_entry = {
            "timestamp": timestamp,
            "file_path": str(file_path),
            "change_type": change_type,
            "size_bytes": file_path.stat().st_size if file_path.exists() else 0
        }
        
        with open(self.change_log, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
        
        print(f"ğŸ“Š ë°ì´í„° ë³€ê²½ ê°ì§€: {change_type} - {file_path}")

def main():
    data_dirs = ["data/raw", "data/processed", "data/staging"]
    
    event_handler = DataChangeHandler(data_dirs)
    observer = Observer()
    
    for data_dir in data_dirs:
        if os.path.exists(data_dir):
            observer.schedule(event_handler, data_dir, recursive=True)
            print(f"ğŸ” ëª¨ë‹ˆí„°ë§ ì‹œì‘: {data_dir}")
    
    observer.start()
    
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()
        print("\nâ¹ï¸  ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    observer.join()

if __name__ == "__main__":
    main()
EOF

chmod +x scripts/data_change_monitor.py
```

---

## âœ… ì™„ë£Œ í™•ì¸

### 7.1 ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

```bash
echo "ğŸ§ª ë°ì´í„° ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸..."

# 1. ë°ì´í„° ë²„ì „ ê´€ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê°€ëŠ¥ í™•ì¸
python scripts/data_version_manager.py --help

# 2. ê°„ë‹¨í•œ ë²„ì „ ê´€ë¦¬ í…ŒìŠ¤íŠ¸
if [ -f "data/raw/movies/bulk_collection_20250605_024954.json" ]; then
    python scripts/data_version_manager.py version \
        "data/raw/movies/bulk_collection_20250605_024954.json" \
        "test_data" \
        --description "Test version"
    
    python scripts/data_version_manager.py list test_data
fi

# 3. DVC ìƒíƒœ í™•ì¸ (ì„¤ì¹˜ëœ ê²½ìš°)
if command -v dvc &> /dev/null; then
    dvc status
fi

# 4. Git ìƒíƒœ í™•ì¸
git status

echo "âœ… ë°ì´í„° ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ!"
```

### 7.2 ë¬¸ì„œ ì—…ë°ì´íŠ¸

```bash
# êµ¬í˜„ ì™„ë£Œ ìƒíƒœë¥¼ Gitì— ì»¤ë°‹
git add .
git commit -m "feat: implement data version management system

- Add DVC configuration and pipeline definition
- Implement simple file-based data versioning
- Add data change monitoring script
- Configure Docker environment for DVC
- Set up data versioning CLI tool
- Add Git hooks for data change detection"

echo "ğŸ“ 3.6 ë°ì´í„° ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ!"
echo "ğŸ”„ ë‹¤ìŒ ë‹¨ê³„: 3.7 GitHub ì €ì¥ì†Œ ì„¤ì • ë° ê¶Œí•œ ê´€ë¦¬"
```

---

## ğŸ“Š êµ¬í˜„ ê²°ê³¼

### ì£¼ìš” êµ¬í˜„ ì‚¬í•­:
1. âœ… DVC (Data Version Control) í™˜ê²½ ì„¤ì •
2. âœ… ê°„ë‹¨í•œ íŒŒì¼ ê¸°ë°˜ ë°ì´í„° ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ
3. âœ… Docker í™˜ê²½ì—ì„œ DVC ì§€ì›
4. âœ… ë°ì´í„° íŒŒì´í”„ë¼ì¸ ë²„ì „ ê´€ë¦¬
5. âœ… Git í†µí•© ë° ìë™í™” í›…
6. âœ… ë°ì´í„° ë³€ê²½ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

### ìƒì„±ëœ íŒŒì¼ë“¤:
- `src/data/utils/data_versioning.py` - ë°ì´í„° ë²„ì „ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°
- `scripts/data_version_manager.py` - ë°ì´í„° ë²„ì „ ê´€ë¦¬ CLI
- `scripts/data_change_monitor.py` - ë°ì´í„° ë³€ê²½ ëª¨ë‹ˆí„°ë§
- `dvc.yaml` - DVC íŒŒì´í”„ë¼ì¸ ì •ì˜
- `.git/hooks/pre-commit-data-check` - ë°ì´í„° ë³€ê²½ ê°ì§€ í›…

ì´ì œ ë‹¤ìŒ ë‹¨ê³„ì¸ 3.7ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
