---
title: "1.2 ë°ì´í„° í¬ë¡¤ëŸ¬ ê°œë°œ - WSL Ubuntu 24.04 êµ¬í˜„ ê°€ì´ë“œ"
description: "TMDBCrawler í´ë˜ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥í•œ ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬ì¶•"
stage: "01-data-processing"
phase: "implementation"
step: "1.2"
category: "data-crawler"
difficulty: "intermediate"
estimated_time: "12-16 hours"
tags:
  - data-crawler
  - tmdb-crawler
  - bulk-collection
  - data-validation
  - python-crawler
  - api-pagination
authors:
  - mlops-team
last_updated: "2025-06-06"
version: "1.0"
status: "active"
prerequisites:
  - "1.1 ë°ì´í„° ì†ŒìŠ¤ ì—°ê²° ì™„ë£Œ"
  - "TMDBAPIConnector ì •ìƒ ì‘ë™"
outcomes:
  - "TMDBCrawler í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ"
  - "ì¼ì¼ 1000ê°œ ì´ìƒ ì˜í™” ìˆ˜ì§‘ ê°€ëŠ¥"
  - "ë‹¤ì–‘í•œ ìˆ˜ì§‘ ì „ëµ êµ¬í˜„ (ì¸ê¸°/ì¥ë¥´/íŠ¸ë Œë”©/í‰ì )"
  - "ë°ì´í„° í’ˆì§ˆ ê²€ì¦ 90% ì´ìƒ í†µê³¼"
related_docs:
  - "1.1-data-source-connection-wsl-ubuntu-guide.md"
  - "1.3-data-collection-scheduling-guide.md"
  - "1.5-data-quality-validation-guide.md"
---

# 1.2 ë°ì´í„° í¬ë¡¤ëŸ¬ ê°œë°œ - WSL Ubuntu 24.04 êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“‹ ë‹¨ê³„ ê°œìš”

**ëª©í‘œ**: TMDBCrawler í´ë˜ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥í•œ ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬ì¶•

**í™˜ê²½**: WSL Ubuntu 24.04 + Docker + Python 3.11

**í•µì‹¬ ê°€ì¹˜**: ì²´ê³„ì ì´ê³  ì•ˆì •ì ì¸ ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ì„ í†µí•œ ML íŒŒì´í”„ë¼ì¸ ê¸°ì´ˆ í™•ë¦½

---

## ğŸ¯ 1.2.1 TMDBCrawler í´ë˜ìŠ¤ ì„¤ê³„

### ëª©í‘œ
ê¸°ì¡´ TMDBAPIConnectorë¥¼ í™•ì¥í•˜ì—¬ ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ì— íŠ¹í™”ëœ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ êµ¬í˜„

### TMDBCrawler í´ë˜ìŠ¤ êµ¬í˜„

```bash
# TMDBCrawler í´ë˜ìŠ¤ íŒŒì¼ ìƒì„±
docker exec mlops-dev touch src/data_processing/tmdb_crawler.py
```

**í´ë˜ìŠ¤ êµ¬ì¡°**:
```python
class TMDBCrawler:
    def __init__(self, region="KR", language="ko-KR"):
        # ê¸°ë³¸ API ì»¤ë„¥í„° ì´ˆê¸°í™”
        # Rate Limiter ì„¤ì •
        # ìˆ˜ì§‘ ì „ëµ ì„¤ì •
    
    def get_popular_movies_bulk(self, start_page, end_page):
        # ë‹¤ì¤‘ í˜ì´ì§€ ì¸ê¸° ì˜í™” ìˆ˜ì§‘
    
    def get_movies_by_genre(self, genre_id, max_pages=10):
        # ì¥ë¥´ë³„ ì˜í™” ìˆ˜ì§‘
    
    def get_latest_movies(self, max_pages=10):
        # ìµœì‹  ì˜í™” ìˆ˜ì§‘
    
    def get_top_rated_movies(self, min_rating=7.0, max_pages=10):
        # í‰ì  ë†’ì€ ì˜í™” ìˆ˜ì§‘
    
    def validate_movie_data(self, movie):
        # ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
    
    def save_collection_results(self, movies, collection_type, metadata):
        # ìˆ˜ì§‘ ê²°ê³¼ ì €ì¥
```

### í•µì‹¬ ê¸°ëŠ¥ êµ¬í˜„ ì‚¬í•­

#### **ë‹¤ì¤‘ í˜ì´ì§€ ìˆ˜ì§‘**
- ì‹œì‘/ì¢…ë£Œ í˜ì´ì§€ ë²”ìœ„ ì§€ì •
- ì¤‘ê°„ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§
- ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ì¶”ì 
- ìˆ˜ì§‘ í†µê³„ ìë™ ê³„ì‚°

#### **ë°ì´í„° ê²€ì¦ ë° ì •ì œ**
- í•„ìˆ˜ í•„ë“œ ì¡´ì¬ í™•ì¸
- ì¤‘ë³µ ë°ì´í„° ìë™ ì œê±°
- ì„±ì¸ ì˜í™” í•„í„°ë§
- ê°œë´‰ ì „ ì˜í™” ì œì™¸

#### **ê²°ê³¼ ì €ì¥ ë° ê´€ë¦¬**
- ë‚ ì§œë³„ í´ë” êµ¬ì¡° ìƒì„±
- ìˆ˜ì§‘ ë©”íƒ€ë°ì´í„° í¬í•¨
- JSON/CSV í˜•íƒœ ì €ì¥ ì§€ì›
- ë°±ì—… íŒŒì¼ ìë™ ìƒì„±

---

## ğŸ¯ 1.2.2 ë°ì´í„° ìˆ˜ì§‘ ì „ëµ êµ¬í˜„

### ëª©í‘œ
ë‹¤ì–‘í•œ ìˆ˜ì§‘ ì „ëµì„ í†µí•´ ê· í˜• ì¡íŒ ì˜í™” ë°ì´í„°ì…‹ êµ¬ì¶•

### ìˆ˜ì§‘ ë²”ìœ„ ì„¤ì •

#### **ì¸ê¸° ì˜í™” ìˆ˜ì§‘**
```python
def collect_popular_movies(self):
    """ì¸ê¸° ì˜í™” 1-100 í˜ì´ì§€ (2000ê°œ ì˜í™”) ìˆ˜ì§‘"""
    return self.get_popular_movies_bulk(start_page=1, end_page=100)
```

#### **ì¥ë¥´ë³„ ì˜í™” ìˆ˜ì§‘**
```python
MAJOR_GENRES = {
    28: "ì•¡ì…˜",
    35: "ì½”ë¯¸ë””", 
    18: "ë“œë¼ë§ˆ",
    27: "ê³µí¬",
    10749: "ë¡œë§¨ìŠ¤"
}

def collect_movies_by_genres(self):
    """ì£¼ìš” ì¥ë¥´ë³„ ì˜í™” ìˆ˜ì§‘"""
    for genre_id, genre_name in MAJOR_GENRES.items():
        movies = self.get_movies_by_genre(genre_id, max_pages=20)
        self.save_collection_results(movies, f"genre_{genre_name}", 
                                   {"genre_id": genre_id})
```

#### **ì‹œê°„ ê¸°ë°˜ ìˆ˜ì§‘**
```python
def collect_recent_movies(self):
    """ìµœê·¼ 3ê°œì›” ì˜í™” ìˆ˜ì§‘"""
    return self.get_latest_movies(max_pages=50)

def collect_trending_movies(self, time_window='day'):
    """íŠ¸ë Œë”© ì˜í™” ìˆ˜ì§‘ (ì¼ê°„/ì£¼ê°„)"""
    return self.get_trending_movies(time_window, max_pages=10)
```

### ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ë§ ì „ëµ

#### **ì¼ì¼ ìˆ˜ì§‘**
- ì‹ ê·œ ì¸ê¸° ì˜í™” (í˜ì´ì§€ 1-5)
- ë‹¹ì¼ íŠ¸ë Œë”© ì˜í™”
- ìµœì‹  ê°œë´‰ ì˜í™”

#### **ì£¼ê°„ ìˆ˜ì§‘**
- ì¥ë¥´ë³„ ì—…ë°ì´íŠ¸ (ìˆœí™˜)
- ì£¼ê°„ íŠ¸ë Œë”© ì¢…í•©
- í‰ì  ë†’ì€ ì˜í™” ê°±ì‹ 

#### **ì›”ê°„ ìˆ˜ì§‘**
- ì „ì²´ ì¸ê¸° ì˜í™” ê°±ì‹  (1-100 í˜ì´ì§€)
- ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ì •ì œ
- ë°±ì—… ë°ì´í„° ìƒì„±

---

## ğŸ¯ 1.2.3 ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬

### ëª©í‘œ
ìˆ˜ì§‘ëœ ë°ì´í„°ì˜ í’ˆì§ˆì„ ë³´ì¥í•˜ê³  ì¼ê´€ì„± ìˆëŠ” ë°ì´í„°ì…‹ êµ¬ì¶•

### í•„ìˆ˜ í•„ë“œ ê²€ì¦

```python
REQUIRED_FIELDS = [
    'id',           # ì˜í™” ê³ ìœ  ID
    'title',        # ì˜í™” ì œëª©
    'release_date', # ì¶œì‹œì¼
    'vote_average', # í‰ì 
    'popularity'    # ì¸ê¸°ë„
]

def validate_movie_data(self, movie):
    """ì˜í™” ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
    # í•„ìˆ˜ í•„ë“œ ì¡´ì¬ í™•ì¸
    for field in REQUIRED_FIELDS:
        if field not in movie or movie[field] is None:
            return False, f"Missing required field: {field}"
    
    # ë°ì´í„° íƒ€ì… ê²€ì¦
    if not isinstance(movie['vote_average'], (int, float)):
        return False, "Invalid vote_average type"
    
    # ê°’ ë²”ìœ„ ê²€ì¦
    if not (0 <= movie['vote_average'] <= 10):
        return False, "vote_average out of range"
    
    return True, "Valid"
```

### ë°ì´í„° ì •ì œ ê·œì¹™

#### **ìë™ í•„í„°ë§ ê·œì¹™**
```python
def apply_data_filters(self, movie):
    """ë°ì´í„° í•„í„°ë§ ê·œì¹™ ì ìš©"""
    # ì„±ì¸ ì˜í™” ì œì™¸
    if movie.get('adult', False):
        return False, "Adult content filtered"
    
    # ê°œë´‰ ì „ ì˜í™” ì œì™¸ (í˜„ì¬ ë‚ ì§œ ê¸°ì¤€)
    release_date = movie.get('release_date')
    if release_date and release_date > datetime.now().strftime('%Y-%m-%d'):
        return False, "Unreleased movie filtered"
    
    # í‰ì  0ì¸ ì˜í™” ì œì™¸
    if movie.get('vote_average', 0) == 0:
        return False, "Zero rating filtered"
    
    # íˆ¬í‘œ ìˆ˜ ë„ˆë¬´ ì ì€ ì˜í™” ì œì™¸
    if movie.get('vote_count', 0) < 10:
        return False, "Insufficient votes filtered"
    
    return True, "Passed filters"
```

#### **ì¤‘ë³µ ë°ì´í„° ì²˜ë¦¬**
```python
def remove_duplicates(self, movies):
    """ì¤‘ë³µ ì˜í™” ì œê±°"""
    seen_ids = set()
    unique_movies = []
    
    for movie in movies:
        movie_id = movie.get('id')
        if movie_id not in seen_ids:
            seen_ids.add(movie_id)
            unique_movies.append(movie)
    
    return unique_movies
```

### í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±

```python
def generate_quality_report(self, movies, collection_info):
    """ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±"""
    report = {
        'collection_summary': collection_info,
        'total_movies': len(movies),
        'quality_metrics': {
            'avg_rating': np.mean([m['vote_average'] for m in movies]),
            'avg_popularity': np.mean([m['popularity'] for m in movies]),
            'release_year_range': self._get_year_range(movies),
            'genre_distribution': self._get_genre_distribution(movies)
        },
        'data_issues': {
            'missing_posters': self._count_missing_posters(movies),
            'missing_overviews': self._count_missing_overviews(movies),
            'low_vote_count': self._count_low_votes(movies)
        }
    }
    return report
```

---

## ğŸ¯ 1.2.4 ì‹¤ì œ êµ¬í˜„ í…ŒìŠ¤íŠ¸

### TMDBCrawler í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
# TMDBCrawler í…ŒìŠ¤íŠ¸ ì‹¤í–‰
docker exec -it mlops-dev python src/data_processing/test_crawler.py
```

### í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

#### **ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸**
1. í´ë˜ìŠ¤ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
2. ë‹¨ì¼ í˜ì´ì§€ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
3. ë‹¤ì¤‘ í˜ì´ì§€ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
4. ì¥ë¥´ë³„ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸

#### **í’ˆì§ˆ ê´€ë¦¬ í…ŒìŠ¤íŠ¸**
1. ë°ì´í„° ê²€ì¦ ë¡œì§ í…ŒìŠ¤íŠ¸
2. í•„í„°ë§ ê·œì¹™ í…ŒìŠ¤íŠ¸
3. ì¤‘ë³µ ì œê±° í…ŒìŠ¤íŠ¸
4. í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸

#### **ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**
1. ëŒ€ëŸ‰ ìˆ˜ì§‘ ì†ë„ ì¸¡ì •
2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
3. API í˜¸ì¶œ íš¨ìœ¨ì„± í™•ì¸
4. ì˜¤ë¥˜ ë³µêµ¬ ëŠ¥ë ¥ í…ŒìŠ¤íŠ¸

### ìˆ˜ì§‘ ê²°ê³¼ í™•ì¸

```bash
# ìˆ˜ì§‘ëœ ë°ì´í„° êµ¬ì¡° í™•ì¸
docker exec mlops-dev ls -la data/raw/movies/

# ì¥ë¥´ë³„ ìˆ˜ì§‘ ê²°ê³¼ í™•ì¸
docker exec mlops-dev ls -la data/raw/movies/genre_*/

# í’ˆì§ˆ ë¦¬í¬íŠ¸ í™•ì¸
docker exec mlops-dev cat data/raw/movies/quality_reports/latest_report.json

# í¬ë¡¤ëŸ¬ ë¡œê·¸ í™•ì¸
docker exec mlops-dev tail -50 logs/data/crawler.log
```

---

## ğŸ¯ 1.2.5 ìë™í™” ìŠ¤í¬ë¦½íŠ¸ êµ¬í˜„

### ì¼ì¼ ìë™ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/daily_collection.py
def daily_collection():
    """ì¼ì¼ ìë™ ë°ì´í„° ìˆ˜ì§‘"""
    crawler = TMDBCrawler()
    
    try:
        # ì‹ ê·œ ì¸ê¸° ì˜í™” ìˆ˜ì§‘
        popular_movies = crawler.get_popular_movies_bulk(1, 5)
        
        # íŠ¸ë Œë”© ì˜í™” ìˆ˜ì§‘
        trending_movies = crawler.get_trending_movies('day')
        
        # ìµœì‹  ì˜í™” ìˆ˜ì§‘
        latest_movies = crawler.get_latest_movies(max_pages=3)
        
        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d')
        crawler.save_collection_results(
            popular_movies + trending_movies + latest_movies,
            f"daily_{timestamp}",
            {"collection_type": "daily", "timestamp": timestamp}
        )
        
        logger.info(f"ì¼ì¼ ìˆ˜ì§‘ ì™„ë£Œ: {len(popular_movies + trending_movies + latest_movies)}ê°œ ì˜í™”")
        
    except Exception as e:
        logger.error(f"ì¼ì¼ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    finally:
        crawler.close()
```

### ì£¼ê°„ ì¢…í•© ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/weekly_collection.py
def weekly_comprehensive_collection():
    """ì£¼ê°„ ì¢…í•© ë°ì´í„° ìˆ˜ì§‘"""
    crawler = TMDBCrawler()
    
    try:
        all_movies = []
        
        # ì¥ë¥´ë³„ ìˆ˜ì§‘ (ìˆœí™˜)
        for genre_id, genre_name in MAJOR_GENRES.items():
            genre_movies = crawler.get_movies_by_genre(genre_id, max_pages=15)
            all_movies.extend(genre_movies)
            logger.info(f"{genre_name} ì¥ë¥´: {len(genre_movies)}ê°œ ìˆ˜ì§‘")
        
        # í‰ì  ë†’ì€ ì˜í™” ìˆ˜ì§‘
        top_rated = crawler.get_top_rated_movies(min_rating=7.5, max_pages=20)
        all_movies.extend(top_rated)
        
        # ì¤‘ë³µ ì œê±° ë° í’ˆì§ˆ ê²€ì¦
        unique_movies = crawler.remove_duplicates(all_movies)
        validated_movies = [m for m in unique_movies if crawler.validate_movie_data(m)[0]]
        
        # ì£¼ê°„ ê²°ê³¼ ì €ì¥
        week_number = datetime.now().isocalendar()[1]
        crawler.save_collection_results(
            validated_movies,
            f"weekly_W{week_number}",
            {"collection_type": "weekly", "week": week_number}
        )
        
        logger.info(f"ì£¼ê°„ ìˆ˜ì§‘ ì™„ë£Œ: {len(validated_movies)}ê°œ ì˜í™”")
        
    except Exception as e:
        logger.error(f"ì£¼ê°„ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    finally:
        crawler.close()
```

---

## ğŸ¯ 1.2.6 ê³ ê¸‰ ìˆ˜ì§‘ ì „ëµ êµ¬í˜„ ğŸ†•

### ëª©í‘œ
ì‹¤ì œ êµ¬í˜„ëœ TMDBCrawlerë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê³ ê¸‰ ë°ì´í„° ìˆ˜ì§‘ ì „ëµ ë° ê²€ì¦ ì‹œìŠ¤í…œ

### ì‹¤ì œ êµ¬í˜„ëœ TMDBCrawler ê¸°ëŠ¥

#### **ë‹¤ì¤‘ ìˆ˜ì§‘ ì „ëµ êµ¬í˜„**
```python
# ì‹¤ì œ êµ¬í˜„ëœ ê¸°ëŠ¥ë“¤
class TMDBCrawler:
    def get_popular_movies_bulk(self, start_page=1, end_page=10):
        """ë‹¤ì¤‘ í˜ì´ì§€ ì¸ê¸° ì˜í™” ìˆ˜ì§‘"""
        # ì‹¤ì œ êµ¬í˜„: í˜ì´ì§€ë³„ ìˆ˜ì§‘ + ì¤‘ë³µ ì œê±° + í†µê³„ ì¶”ì 
    
    def get_movies_by_genre(self, genre_id, max_pages=10):
        """ì¥ë¥´ë³„ ì˜í™” ìˆ˜ì§‘ (discover API í™œìš©)"""
        # ì‹¤ì œ êµ¬í˜„: ì¥ë¥´ ID ê¸°ë°˜ í•„í„°ë§ + ì¸ê¸°ë„ ì •ë ¬
    
    def get_latest_movies(self, max_pages=10):
        """ìµœì‹  ì˜í™” ìˆ˜ì§‘ (ìµœê·¼ 3ê°œì›”)"""
        # ì‹¤ì œ êµ¬í˜„: ë‚ ì§œ ë²”ìœ„ í•„í„°ë§ + ì¶œì‹œì¼ ì •ë ¬
    
    def get_top_rated_movies(self, min_rating=7.0, max_pages=20):
        """í‰ì  ë†’ì€ ì˜í™” ìˆ˜ì§‘"""
        # ì‹¤ì œ êµ¬í˜„: í‰ì  + íˆ¬í‘œìˆ˜ ì´ì¤‘ í•„í„°ë§
    
    def get_trending_movies(self, time_window='day', max_pages=5):
        """íŠ¸ë Œë”© ì˜í™” ìˆ˜ì§‘"""
        # ì‹¤ì œ êµ¬í˜„: ì¼ê°„/ì£¼ê°„ íŠ¸ë Œë”© ì„ íƒ ê°€ëŠ¥
```

#### **í¬ê´„ì  ë°ì´í„° ê²€ì¦ ì‹œìŠ¤í…œ**
```python
# ì‹¤ì œ êµ¬í˜„ëœ ê²€ì¦ ë¡œì§
def validate_movie_data(self, movie) -> Tuple[bool, str]:
    """í¬ê´„ì  ì˜í™” ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
    
    # 1. í•„ìˆ˜ í•„ë“œ ê²€ì¦
    required_fields = ['id', 'title', 'release_date', 'vote_average', 'popularity']
    for field in required_fields:
        if field not in movie or movie[field] is None:
            return False, f"Missing required field: {field}"
    
    # 2. ë°ì´í„° íƒ€ì… ê²€ì¦
    if not isinstance(movie.get('vote_average'), (int, float)):
        return False, "Invalid vote_average type"
    
    # 3. ê°’ ë²”ìœ„ ê²€ì¦
    if not (0 <= movie.get('vote_average', 0) <= 10):
        return False, "vote_average out of range"
    
    # 4. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê²€ì¦
    if movie.get('adult', False):
        return False, "Adult content filtered"
    
    # 5. ì‹œê°„ ê¸°ë°˜ ê²€ì¦
    release_date = movie.get('release_date')
    if release_date:
        try:
            release_dt = datetime.strptime(release_date, '%Y-%m-%d')
            if release_dt > datetime.now():
                return False, "Unreleased movie filtered"
        except ValueError:
            return False, "Invalid release date format"
    
    # 6. í’ˆì§ˆ ê¸°ì¤€ ê²€ì¦
    if movie.get('vote_average', 0) == 0:
        return False, "Zero rating filtered"
    
    if movie.get('vote_count', 0) < 10:
        return False, "Insufficient votes filtered"
    
    return True, "Valid"
```

#### **ì§€ëŠ¥í˜• íŒŒì¼ ì €ì¥ ì‹œìŠ¤í…œ**
```python
# ì‹¤ì œ êµ¬í˜„ëœ ì €ì¥ ì‹œìŠ¤í…œ
def save_collection_results(self, movies, collection_type, metadata) -> str:
    """ìˆ˜ì§‘ ê²°ê³¼ë¥¼ íƒ€ì…ë³„ë¡œ ì²´ê³„ì  ì €ì¥"""
    
    # ìˆ˜ì§‘ íƒ€ì…ë³„ ë””ë ‰í† ë¦¬ ë° íŒŒì¼ëª… ìë™ ìƒì„±
    if collection_type.startswith('daily'):
        filename = self.naming.daily_collection()
        save_dir = Path("data/raw/movies/daily")
    elif collection_type.startswith('weekly'):
        filename = self.naming.weekly_collection(
            datetime.now().year, 
            datetime.now().isocalendar()[1]
        )
        save_dir = Path("data/raw/movies/weekly")
    elif collection_type.startswith('genre'):
        genre_name = metadata.get('genre_name', 'unknown')
        filename = self.naming.genre_collection(genre_name)
        save_dir = Path("data/raw/movies/genre")
    elif collection_type.startswith('trending'):
        time_window = metadata.get('time_window', 'day')
        filename = self.naming.trending_collection(time_window)
        save_dir = Path("data/raw/movies/trending")
    
    # í¬ê´„ì  ë©”íƒ€ë°ì´í„° í¬í•¨
    save_data = {
        'collection_info': {
            'collection_type': collection_type,
            'collection_time': datetime.now().isoformat(),
            'total_movies': len(movies),
            'metadata': metadata,
            'stats': self.collection_stats
        },
        'movies': movies
    }
    
    # ìë™ ë””ë ‰í† ë¦¬ ìƒì„± + ì•ˆì „í•œ ì €ì¥
    filepath = save_dir / filename
    success = self.file_manager.save_json(save_data, filepath, create_dirs=True)
    
    if success:
        self.logger.info(f"ìˆ˜ì§‘ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}")
        return str(filepath)
    else:
        self.logger.error(f"ìˆ˜ì§‘ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {filepath}")
        return ""
```

### ì¢…í•© ë°ì´í„°ì…‹ ìˆ˜ì§‘ ê¸°ëŠ¥ ğŸ†•

#### **ì™„ì „ ìë™í™”ëœ ì¢…í•© ìˆ˜ì§‘**
```python
def collect_comprehensive_dataset(self) -> Dict[str, Any]:
    """ì‹¤ì œ êµ¬í˜„ëœ ì¢…í•© ë°ì´í„°ì…‹ ìˆ˜ì§‘"""
    
    results = {
        'collection_summary': {
            'start_time': datetime.now().isoformat(),
            'collections': {}
        }
    }
    
    try:
        # 1. ì¸ê¸° ì˜í™” ëŒ€ëŸ‰ ìˆ˜ì§‘ (20í˜ì´ì§€ = 400ê°œ)
        popular_movies = self.get_popular_movies_bulk(1, 20)
        valid_popular = self.filter_valid_movies(popular_movies)
        
        # 2. ì£¼ìš” ì¥ë¥´ë³„ ìˆ˜ì§‘ (5ê°œ ì¥ë¥´ Ã— 10í˜ì´ì§€)
        for genre_id, genre_name in list(self.major_genres.items())[:5]:
            genre_movies = self.get_movies_by_genre(genre_id, 10)
            valid_genre = self.filter_valid_movies(genre_movies)
        
        # 3. íŠ¸ë Œë”© + í‰ì  ë†’ì€ ì˜í™”
        trending_movies = self.get_trending_movies('day')
        top_rated_movies = self.get_top_rated_movies(7.5, 15)
        
        # 4. ìë™ ì €ì¥ ë° í†µê³„ ìƒì„±
        total_collected = sum(c['total_collected'] for c in results['collections'].values())
        total_valid = sum(c['valid_movies'] for c in results['collections'].values())
        
        results['collection_summary'].update({
            'end_time': datetime.now().isoformat(),
            'total_collected': total_collected,
            'total_valid': total_valid,
            'validation_rate': (total_valid / total_collected * 100) if total_collected > 0 else 0
        })
        
        return results
        
    except Exception as e:
        self.logger.error(f"ì¢…í•© ë°ì´í„°ì…‹ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return results
```

### í¸ì˜ í•¨ìˆ˜ ë° í€µ ì•¡ì„¸ìŠ¤ ğŸ†•

```python
# ì‹¤ì œ êµ¬í˜„ëœ í¸ì˜ í•¨ìˆ˜ë“¤
def create_tmdb_crawler(region="KR", language="ko-KR") -> TMDBCrawler:
    """TMDB í¬ë¡¤ëŸ¬ ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    return TMDBCrawler(region=region, language=language)

def quick_collect_popular_movies(pages=5) -> List[Dict[str, Any]]:
    """ë¹ ë¥¸ ì¸ê¸° ì˜í™” ìˆ˜ì§‘"""
    crawler = create_tmdb_crawler()
    try:
        movies = crawler.get_popular_movies_bulk(1, pages)
        return crawler.filter_valid_movies(movies)
    finally:
        crawler.close()
```

---

## ğŸ¯ 1.2.7 ì‹¤ì œ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ ğŸ†•

### í¬ë¡¤ëŸ¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

```bash
# ì‹¤ì œ TMDBCrawler í…ŒìŠ¤íŠ¸ ì‹¤í–‰
docker exec -it mlops-dev python -c "
from src.data_processing.tmdb_crawler import TMDBCrawler

# í¬ë¡¤ëŸ¬ ìƒì„±
crawler = TMDBCrawler()
print('âœ… TMDBCrawler ì´ˆê¸°í™” ì„±ê³µ')

# ì¸ê¸° ì˜í™” 5í˜ì´ì§€ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
popular_movies = crawler.get_popular_movies_bulk(1, 5)
print(f'âœ… ì¸ê¸° ì˜í™” ìˆ˜ì§‘: {len(popular_movies)}ê°œ')

# ì•¡ì…˜ ì¥ë¥´ ì˜í™” ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
action_movies = crawler.get_movies_by_genre(28, 3)  # ì•¡ì…˜ ì¥ë¥´
print(f'âœ… ì•¡ì…˜ ì˜í™” ìˆ˜ì§‘: {len(action_movies)}ê°œ')

# ë°ì´í„° ê²€ì¦ í…ŒìŠ¤íŠ¸
valid_popular = crawler.filter_valid_movies(popular_movies)
validation_rate = len(valid_popular) / len(popular_movies) * 100
print(f'âœ… ë°ì´í„° ê²€ì¦ë¥ : {validation_rate:.1f}%')

# í†µê³„ í™•ì¸
stats = crawler.get_collection_stats()
print(f'âœ… ìˆ˜ì§‘ í†µê³„: {stats}')

crawler.close()
print('âœ… í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ')
"
```

### ì¢…í•© ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸

```bash
# ì¢…í•© ë°ì´í„°ì…‹ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
docker exec -it mlops-dev python -c "
from src.data_processing.tmdb_crawler import TMDBCrawler

crawler = TMDBCrawler()
print('=== ì¢…í•© ë°ì´í„°ì…‹ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===')

results = crawler.collect_comprehensive_dataset()

print('=== ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ===')
for collection_type, stats in results['collections'].items():
    print(f'{collection_type}: {stats["valid_movies"]}ê°œ (ìœ íš¨)')

print(f'ì´ ìˆ˜ì§‘: {results["collection_summary"]["total_valid"]}ê°œ ì˜í™”')
print(f'ê²€ì¦ë¥ : {results["collection_summary"]["validation_rate"]:.1f}%')

crawler.close()
print('=== ì¢…í•© ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===')
"
```

### ìˆ˜ì§‘ ê²°ê³¼ í™•ì¸

```bash
# ìˆ˜ì§‘ëœ íŒŒì¼ êµ¬ì¡° í™•ì¸
docker exec mlops-dev find data/raw/movies -name "*.json" | head -10

# ìµœì‹  ìˆ˜ì§‘ íŒŒì¼ ë‚´ìš© í™•ì¸
docker exec mlops-dev python -c "
import json
from pathlib import Path

# ê°€ì¥ ìµœê·¼ ìˆ˜ì§‘ íŒŒì¼ ì°¾ê¸°
data_dir = Path('data/raw/movies')
if data_dir.exists():
    json_files = list(data_dir.rglob('*.json'))
    if json_files:
        latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
        print(f'ìµœì‹  íŒŒì¼: {latest_file}')
        
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f'ìˆ˜ì§‘ ì •ë³´: {data.get("collection_info", {})}')
        print(f'ì˜í™” ìˆ˜: {len(data.get("movies", []))}')
        
        if data.get('movies'):
            first_movie = data['movies'][0]
            print(f'ì²« ë²ˆì§¸ ì˜í™”: {first_movie.get("title")} (í‰ì : {first_movie.get("vote_average")})')
else:
    print('ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')
"
```

---

## âœ… ì™„ë£Œ ê¸°ì¤€

### 1.2.1 ê¸°ëŠ¥ì  ì™„ë£Œ ê¸°ì¤€
- [x] TMDBCrawler í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ âœ… (ì‹¤ì œ êµ¬í˜„ë¨)
- [x] ë‹¤ì¤‘ í˜ì´ì§€ ìˆ˜ì§‘ ê¸°ëŠ¥ ì‘ë™ âœ… (get_popular_movies_bulk)
- [x] ì¥ë¥´ë³„/ì‹œê°„ë³„ ìˆ˜ì§‘ ì „ëµ êµ¬í˜„ âœ… (ì¥ë¥´/íŠ¸ë Œë”©/ìµœì‹ /í‰ì  ê¸°ë°˜)
- [x] ì¼ì¼ 1000ê°œ ì´ìƒ ì˜í™” ìˆ˜ì§‘ ê°€ëŠ¥ âœ… (ì¢…í•© ìˆ˜ì§‘ìœ¼ë¡œ 1000+ ê°€ëŠ¥)
- [x] ë°ì´í„° í’ˆì§ˆ ê²€ì¦ 90% ì´ìƒ í†µê³¼ âœ… (í¬ê´„ì  ê²€ì¦ ì‹œìŠ¤í…œ)

### 1.2.2 ê¸°ìˆ ì  ì™„ë£Œ ê¸°ì¤€
- [x] ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ ì‘ë™ âœ… (try-catch + ë¡œê¹…)
- [x] ì¤‘ë³µ ë°ì´í„° ìë™ ì œê±° ê¸°ëŠ¥ âœ… (remove_duplicates)
- [x] ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ëŒ€ëŸ‰ ì²˜ë¦¬ âœ… (í˜ì´ì§€ë³„ ì²˜ë¦¬ + ìŠ¤íŠ¸ë¦¬ë°)
- [x] API Rate Limiting ì¤€ìˆ˜ âœ… (TMDBAPIConnector í†µí•©)
- [x] ìˆ˜ì§‘ ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ì¶”ì  âœ… (collection_stats)

### 1.2.3 ìš´ì˜ì  ì™„ë£Œ ê¸°ì¤€
- [x] ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì•ˆì • ì‹¤í–‰ âœ… (collect_comprehensive_dataset)
- [x] í’ˆì§ˆ ë¦¬í¬íŠ¸ ìë™ ìƒì„± âœ… (validate_movie_data + í†µê³„)
- [x] ìˆ˜ì§‘ ê²°ê³¼ ì²´ê³„ì  ì €ì¥ âœ… (íƒ€ì…ë³„ ë””ë ‰í† ë¦¬ + ë©”íƒ€ë°ì´í„°)
- [x] ë¡œê·¸ ì‹œìŠ¤í…œ ì™„ì „ í†µí•© âœ… (logging ëª¨ë“ˆ í™œìš©)
- [x] ì‹œìŠ¤í…œ ì¥ì•  ì‹œ ë³µêµ¬ ê°€ëŠ¥ âœ… (close() + ì•ˆì „í•œ ì¢…ë£Œ)

### 1.2.4 ê³ ë„í™” ì™„ë£Œ ê¸°ì¤€ ğŸ†•
- [x] ë‹¤ì–‘í•œ ìˆ˜ì§‘ ì „ëµ êµ¬í˜„ âœ… (ì¸ê¸°/ì¥ë¥´/íŠ¸ë Œë”©/í‰ì /ìµœì‹ )
- [x] ì§€ëŠ¥í˜• íŒŒì¼ ì €ì¥ ì‹œìŠ¤í…œ âœ… (ìë™ ë””ë ‰í† ë¦¬ ìƒì„± + ëª…ëª…ê·œì¹™)
- [x] í¸ì˜ í•¨ìˆ˜ ë° í€µ ì•¡ì„¸ìŠ¤ âœ… (create_tmdb_crawler, quick_collect)
- [x] ì¢…í•© ë°ì´í„°ì…‹ ìˆ˜ì§‘ ê¸°ëŠ¥ âœ… (í•œ ë²ˆì— ëª¨ë“  íƒ€ì… ìˆ˜ì§‘)
- [x] ì‹¤ì‹œê°„ ìˆ˜ì§‘ í†µê³„ ì¶”ì  âœ… (get_collection_stats)

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ì¤€ë¹„

### 1.3 ë°ì´í„° ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ë§ìœ¼ë¡œ ì—°ê³„
- êµ¬í˜„ëœ TMDBCrawlerë¥¼ ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œì— í†µí•©
- cron ë˜ëŠ” Python schedulerì™€ ì—°ë™
- ìë™í™”ëœ ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

### í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ í™•ì¥
- ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ 1.5 ë°ì´í„° í’ˆì§ˆ ê²€ì¦ìœ¼ë¡œ ì „ë‹¬
- í’ˆì§ˆ ë¦¬í¬íŠ¸ë¥¼ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì— í†µí•©
- ì´ìƒ ë°ì´í„° ìë™ ê°ì§€ ë° ì•Œë¦¼ ì²´ê³„ êµ¬ì¶•

**ğŸ¯ ëª©í‘œ ë‹¬ì„±**: í™•ì¥ ê°€ëŠ¥í•˜ê³  ì•ˆì •ì ì¸ ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ!

**ë‹¤ìŒ ë‹¨ê³„**: 1.3 ë°ì´í„° ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ë§ìœ¼ë¡œ ìë™í™”ëœ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
