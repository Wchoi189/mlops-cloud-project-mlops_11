---
title: "1.5 ë°ì´í„° í’ˆì§ˆ ê²€ì¦ - WSL Ubuntu 24.04 êµ¬í˜„ ê°€ì´ë“œ"
description: "ìˆ˜ì§‘ëœ ë°ì´í„°ì˜ í’ˆì§ˆì„ ë³´ì¥í•˜ê³  ì´ìƒ ë°ì´í„°ë¥¼ ì¡°ê¸°ì— ê°ì§€"
stage: "01-data-processing"
phase: "implementation"
step: "1.5"
category: "quality-validation"
difficulty: "intermediate"
estimated_time: "10-14 hours"
tags:
  - data-quality
  - validation
  - anomaly-detection
  - data-cleaning
  - quality-metrics
  - statistical-analysis
authors:
  - mlops-team
last_updated: "2025-06-06"
version: "1.0"
status: "active"
prerequisites:
  - "1.2 ë°ì´í„° í¬ë¡¤ëŸ¬ ê°œë°œ ì™„ë£Œ"
  - "1.4 ë°ì´í„° ì €ì¥ì†Œ ì„¤ì • ì™„ë£Œ"
outcomes:
  - "ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ"
  - "í•„ë“œë³„ ê²€ì¦ ê·œì¹™ ì •ìƒ ì‘ë™"
  - "ë°°ì¹˜ í’ˆì§ˆ ë¶„ì„ ìë™ ì‹¤í–‰"
  - "í†µê³„ì  ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ ë™ì‘"
  - "ì¼ê°„ í’ˆì§ˆ ë¦¬í¬íŠ¸ ìë™ ìƒì„±"
related_docs:
  - "1.2-data-crawler-development-guide.md"
  - "1.3-data-collection-scheduling-guide.md"
  - "1.7-logging-system-setup-guide.md"
---

# 1.5 ë°ì´í„° í’ˆì§ˆ ê²€ì¦ - WSL Ubuntu 24.04 êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“‹ ë‹¨ê³„ ê°œìš”

**ëª©í‘œ**: ìˆ˜ì§‘ëœ ë°ì´í„°ì˜ í’ˆì§ˆì„ ë³´ì¥í•˜ê³  ì´ìƒ ë°ì´í„°ë¥¼ ì¡°ê¸°ì— ê°ì§€

**í™˜ê²½**: WSL Ubuntu 24.04 + Docker + Python 3.11

**í•µì‹¬ ê°€ì¹˜**: ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°ì´í„° í’ˆì§ˆì„ í†µí•œ ML ëª¨ë¸ì˜ ì„±ëŠ¥ ë³´ì¥

---

## ğŸ¯ 1.5.1 ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ

### ëª©í‘œ
ë°ì´í„° ìˆ˜ì§‘ ì‹œì ì— ì¦‰ì‹œ í’ˆì§ˆì„ ê²€ì¦í•˜ì—¬ ë¬¸ì œ ë°ì´í„° ìœ ì… ì°¨ë‹¨

### í•„ë“œë³„ ê²€ì¦ ê·œì¹™ êµ¬í˜„

```bash
# í’ˆì§ˆ ê²€ì¦ ëª¨ë“ˆ ìƒì„±
docker exec mlops-dev touch src/data_processing/quality_validator.py
```

**QualityValidator í´ë˜ìŠ¤ êµ¬ì¡°**:
```python
import logging
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any
import json

class DataQualityValidator:
    """ë°ì´í„° í’ˆì§ˆ ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.validation_rules = self._setup_validation_rules()
        self.quality_stats = {
            'total_validated': 0,
            'passed': 0,
            'failed': 0,
            'error_details': {}
        }
    
    def _setup_validation_rules(self):
        """ê²€ì¦ ê·œì¹™ ì„¤ì •"""
        return {
            'required_fields': [
                'id', 'title', 'release_date', 
                'vote_average', 'popularity', 'overview'
            ],
            'field_types': {
                'id': int,
                'title': str,
                'vote_average': (int, float),
                'popularity': (int, float),
                'adult': bool
            },
            'field_ranges': {
                'vote_average': (0, 10),
                'popularity': (0, float('inf')),
                'vote_count': (0, float('inf'))
            },
            'field_patterns': {
                'release_date': r'^\d{4}-\d{2}-\d{2}$',
                'imdb_id': r'^tt\d+$'
            }
        }
    
    def validate_single_movie(self, movie: Dict) -> Tuple[bool, str, Dict]:
        """ë‹¨ì¼ ì˜í™” ë°ì´í„° ê²€ì¦"""
        self.quality_stats['total_validated'] += 1
        validation_result = {
            'movie_id': movie.get('id', 'unknown'),
            'checks': {},
            'overall_score': 0,
            'issues': []
        }
        
        try:
            # í•„ìˆ˜ í•„ë“œ ì¡´ì¬ í™•ì¸
            required_check = self._check_required_fields(movie)
            validation_result['checks']['required_fields'] = required_check
            
            # ë°ì´í„° íƒ€ì… ê²€ì¦
            type_check = self._check_field_types(movie)
            validation_result['checks']['field_types'] = type_check
            
            # ê°’ ë²”ìœ„ ê²€ì¦
            range_check = self._check_field_ranges(movie)
            validation_result['checks']['field_ranges'] = range_check
            
            # íŒ¨í„´ ê²€ì¦
            pattern_check = self._check_field_patterns(movie)
            validation_result['checks']['field_patterns'] = pattern_check
            
            # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê²€ì¦
            business_check = self._check_business_logic(movie)
            validation_result['checks']['business_logic'] = business_check
            
            # ì „ì²´ ì ìˆ˜ ê³„ì‚°
            validation_result['overall_score'] = self._calculate_quality_score(validation_result['checks'])
            
            # í†µê³¼/ì‹¤íŒ¨ íŒì • (70ì  ì´ìƒ í†µê³¼)
            is_valid = validation_result['overall_score'] >= 70
            
            if is_valid:
                self.quality_stats['passed'] += 1
                return True, "Valid", validation_result
            else:
                self.quality_stats['failed'] += 1
                return False, f"Quality score too low: {validation_result['overall_score']}", validation_result
                
        except Exception as e:
            self.quality_stats['failed'] += 1
            self.logger.error(f"Validation error for movie {movie.get('id', 'unknown')}: {e}")
            return False, f"Validation error: {str(e)}", validation_result
    
    def _check_required_fields(self, movie: Dict) -> Dict:
        """í•„ìˆ˜ í•„ë“œ ì¡´ì¬ í™•ì¸"""
        missing_fields = []
        for field in self.validation_rules['required_fields']:
            if field not in movie or movie[field] is None or movie[field] == '':
                missing_fields.append(field)
        
        return {
            'passed': len(missing_fields) == 0,
            'score': max(0, 100 - len(missing_fields) * 20),
            'missing_fields': missing_fields
        }
    
    def _check_field_types(self, movie: Dict) -> Dict:
        """ë°ì´í„° íƒ€ì… ê²€ì¦"""
        type_errors = []
        for field, expected_type in self.validation_rules['field_types'].items():
            if field in movie and movie[field] is not None:
                if not isinstance(movie[field], expected_type):
                    type_errors.append(f"{field}: expected {expected_type}, got {type(movie[field])}")
        
        return {
            'passed': len(type_errors) == 0,
            'score': max(0, 100 - len(type_errors) * 25),
            'type_errors': type_errors
        }
    
    def _check_field_ranges(self, movie: Dict) -> Dict:
        """ê°’ ë²”ìœ„ ê²€ì¦"""
        range_errors = []
        for field, (min_val, max_val) in self.validation_rules['field_ranges'].items():
            if field in movie and movie[field] is not None:
                value = movie[field]
                if not (min_val <= value <= max_val):
                    range_errors.append(f"{field}: {value} not in range [{min_val}, {max_val}]")
        
        return {
            'passed': len(range_errors) == 0,
            'score': max(0, 100 - len(range_errors) * 20),
            'range_errors': range_errors
        }
    
    def _check_field_patterns(self, movie: Dict) -> Dict:
        """íŒ¨í„´ ê²€ì¦"""
        import re
        pattern_errors = []
        for field, pattern in self.validation_rules['field_patterns'].items():
            if field in movie and movie[field] is not None:
                if not re.match(pattern, str(movie[field])):
                    pattern_errors.append(f"{field}: {movie[field]} doesn't match pattern {pattern}")
        
        return {
            'passed': len(pattern_errors) == 0,
            'score': max(0, 100 - len(pattern_errors) * 15),
            'pattern_errors': pattern_errors
        }
    
    def _check_business_logic(self, movie: Dict) -> Dict:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê²€ì¦"""
        business_errors = []
        
        # ì„±ì¸ ì˜í™” í•„í„°ë§
        if movie.get('adult', False):
            business_errors.append("Adult content not allowed")
        
        # ê°œë´‰ ì „ ì˜í™” ì œì™¸
        release_date = movie.get('release_date')
        if release_date:
            try:
                release_dt = datetime.strptime(release_date, '%Y-%m-%d')
                if release_dt > datetime.now():
                    business_errors.append("Unreleased movie")
            except ValueError:
                business_errors.append("Invalid release date format")
        
        # í‰ì  0ì¸ ì˜í™” ì œì™¸
        if movie.get('vote_average', 0) == 0:
            business_errors.append("Zero rating")
        
        # íˆ¬í‘œ ìˆ˜ ë„ˆë¬´ ì ì€ ì˜í™” ì œì™¸
        if movie.get('vote_count', 0) < 10:
            business_errors.append("Insufficient votes")
        
        return {
            'passed': len(business_errors) == 0,
            'score': max(0, 100 - len(business_errors) * 25),
            'business_errors': business_errors
        }
    
    def _calculate_quality_score(self, checks: Dict) -> float:
        """ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        total_score = 0
        weights = {
            'required_fields': 0.3,
            'field_types': 0.25,
            'field_ranges': 0.2,
            'field_patterns': 0.1,
            'business_logic': 0.15
        }
        
        for check_name, weight in weights.items():
            if check_name in checks:
                total_score += checks[check_name]['score'] * weight
        
        return round(total_score, 2)
```

### ë°°ì¹˜ í’ˆì§ˆ ë¶„ì„ ì‹œìŠ¤í…œ

```python
def validate_batch_data(self, movies: List[Dict]) -> Dict:
    """ë°°ì¹˜ ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
    batch_results = {
        'total_movies': len(movies),
        'valid_movies': 0,
        'invalid_movies': 0,
        'quality_distribution': {},
        'common_issues': {},
        'recommendations': []
    }
    
    valid_movies = []
    invalid_movies = []
    quality_scores = []
    all_issues = []
    
    for movie in movies:
        is_valid, message, details = self.validate_single_movie(movie)
        quality_scores.append(details['overall_score'])
        
        if is_valid:
            valid_movies.append(movie)
            batch_results['valid_movies'] += 1
        else:
            invalid_movies.append(movie)
            batch_results['invalid_movies'] += 1
            all_issues.extend(details['issues'])
    
    # í’ˆì§ˆ ë¶„í¬ ë¶„ì„
    batch_results['quality_distribution'] = {
        'excellent': len([s for s in quality_scores if s >= 90]),
        'good': len([s for s in quality_scores if 80 <= s < 90]),
        'fair': len([s for s in quality_scores if 70 <= s < 80]),
        'poor': len([s for s in quality_scores if s < 70])
    }
    
    # ê³µí†µ ì´ìŠˆ ë¶„ì„
    from collections import Counter
    issue_counts = Counter(all_issues)
    batch_results['common_issues'] = dict(issue_counts.most_common(10))
    
    # ê°œì„  ê¶Œì¥ì‚¬í•­
    batch_results['recommendations'] = self._generate_recommendations(batch_results)
    
    return batch_results

def _generate_recommendations(self, batch_results: Dict) -> List[str]:
    """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
    recommendations = []
    
    total = batch_results['total_movies']
    invalid_rate = batch_results['invalid_movies'] / total * 100
    
    if invalid_rate > 10:
        recommendations.append(f"ë°ì´í„° í’ˆì§ˆ ë¶ˆëŸ‰ë¥ ì´ {invalid_rate:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤. ìˆ˜ì§‘ ë¡œì§ ì ê²€ í•„ìš”")
    
    common_issues = batch_results['common_issues']
    if 'Zero rating' in common_issues:
        recommendations.append("í‰ì  0ì¸ ì˜í™”ê°€ ë§ìŠµë‹ˆë‹¤. í•„í„°ë§ ê°•í™” í•„ìš”")
    
    if 'Insufficient votes' in common_issues:
        recommendations.append("íˆ¬í‘œ ìˆ˜ ë¶€ì¡± ì˜í™”ê°€ ë§ìŠµë‹ˆë‹¤. ìµœì†Œ íˆ¬í‘œ ìˆ˜ ê¸°ì¤€ ìƒí–¥ ê²€í† ")
    
    return recommendations
```

---

## ğŸ¯ 1.5.2 í†µê³„ì  ì´ìƒ íƒì§€

### ëª©í‘œ
í†µê³„ì  ë°©ë²•ì„ í†µí•œ ì´ìƒ íŒ¨í„´ ìë™ ê°ì§€

### ì´ìƒ íƒì§€ êµ¬í˜„

```python
class AnomalyDetector:
    """í†µê³„ì  ì´ìƒ íƒì§€"""
    
    def __init__(self):
        self.baseline_stats = {}
        self.alert_thresholds = {
            'rating_mean_change': 0.5,
            'popularity_variance_change': 2.0,
            'collection_volume_change': 0.3
        }
    
    def detect_rating_anomalies(self, movies: List[Dict]) -> Dict:
        """í‰ì  ë¶„í¬ ì´ìƒ íƒì§€"""
        ratings = [m.get('vote_average', 0) for m in movies if m.get('vote_average')]
        
        if not ratings:
            return {'status': 'no_data', 'anomalies': []}
        
        current_stats = {
            'mean': np.mean(ratings),
            'std': np.std(ratings),
            'median': np.median(ratings),
            'q1': np.percentile(ratings, 25),
            'q3': np.percentile(ratings, 75)
        }
        
        anomalies = []
        
        # ê¸°ì¤€ í†µê³„ì™€ ë¹„êµ
        if 'ratings' in self.baseline_stats:
            baseline = self.baseline_stats['ratings']
            
            # í‰ê·  ë³€í™” í™•ì¸
            mean_change = abs(current_stats['mean'] - baseline['mean'])
            if mean_change > self.alert_thresholds['rating_mean_change']:
                anomalies.append({
                    'type': 'rating_mean_shift',
                    'current': current_stats['mean'],
                    'baseline': baseline['mean'],
                    'change': mean_change
                })
        
        # ê·¹ê°’ íƒì§€
        iqr = current_stats['q3'] - current_stats['q1']
        lower_bound = current_stats['q1'] - 1.5 * iqr
        upper_bound = current_stats['q3'] + 1.5 * iqr
        
        outliers = [r for r in ratings if r < lower_bound or r > upper_bound]
        if len(outliers) > len(ratings) * 0.1:  # 10% ì´ìƒì´ ê·¹ê°’
            anomalies.append({
                'type': 'excessive_outliers',
                'outlier_count': len(outliers),
                'outlier_rate': len(outliers) / len(ratings)
            })
        
        return {
            'status': 'analyzed',
            'current_stats': current_stats,
            'anomalies': anomalies
        }
    
    def detect_collection_anomalies(self, collection_stats: Dict) -> Dict:
        """ìˆ˜ì§‘ëŸ‰ ì´ìƒ íƒì§€"""
        anomalies = []
        
        current_count = collection_stats.get('total_collected', 0)
        
        if 'collection' in self.baseline_stats:
            baseline_count = self.baseline_stats['collection']['average_count']
            change_rate = abs(current_count - baseline_count) / baseline_count
            
            if change_rate > self.alert_thresholds['collection_volume_change']:
                anomalies.append({
                    'type': 'collection_volume_change',
                    'current': current_count,
                    'baseline': baseline_count,
                    'change_rate': change_rate
                })
        
        return {
            'status': 'analyzed',
            'anomalies': anomalies
        }
    
    def update_baseline(self, movies: List[Dict], collection_stats: Dict):
        """ê¸°ì¤€ì„  ì—…ë°ì´íŠ¸"""
        # í‰ì  í†µê³„ ì—…ë°ì´íŠ¸
        ratings = [m.get('vote_average', 0) for m in movies if m.get('vote_average')]
        if ratings:
            self.baseline_stats['ratings'] = {
                'mean': np.mean(ratings),
                'std': np.std(ratings),
                'median': np.median(ratings)
            }
        
        # ìˆ˜ì§‘ëŸ‰ í†µê³„ ì—…ë°ì´íŠ¸
        if 'collection' not in self.baseline_stats:
            self.baseline_stats['collection'] = {'average_count': collection_stats.get('total_collected', 0)}
        else:
            # ì§€ìˆ˜ ì´ë™ í‰ê·  ì ìš©
            alpha = 0.1
            current_avg = self.baseline_stats['collection']['average_count']
            new_count = collection_stats.get('total_collected', 0)
            self.baseline_stats['collection']['average_count'] = alpha * new_count + (1 - alpha) * current_avg
```

---

## ğŸ¯ 1.5.3 ì¼ê°„ í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±

### ëª©í‘œ
ìë™í™”ëœ í’ˆì§ˆ ë¦¬í¬íŠ¸ë¥¼ í†µí•œ ë°ì´í„° ìƒíƒœ ê°€ì‹œí™”

### í’ˆì§ˆ ë¦¬í¬íŠ¸ ì‹œìŠ¤í…œ

```bash
# í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±ê¸° êµ¬í˜„
docker exec mlops-dev touch src/data_processing/quality_reporter.py
```

```python
class QualityReporter:
    """ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±"""
    
    def __init__(self):
        self.validator = DataQualityValidator()
        self.anomaly_detector = AnomalyDetector()
    
    def generate_daily_report(self, date_str: str = None) -> Dict:
        """ì¼ê°„ í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±"""
        if date_str is None:
            date_str = datetime.now().strftime('%Y%m%d')
        
        # í•´ë‹¹ ë‚ ì§œ ë°ì´í„° ë¡œë“œ
        daily_files = self._find_daily_files(date_str)
        if not daily_files:
            return {'status': 'no_data', 'date': date_str}
        
        all_movies = []
        collection_stats = {}
        
        for file_path in daily_files:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if 'movies' in data:
                    all_movies.extend(data['movies'])
                if 'collection_info' in data:
                    collection_stats.update(data['collection_info'])
        
        # í’ˆì§ˆ ë¶„ì„ ì‹¤í–‰
        batch_results = self.validator.validate_batch_data(all_movies)
        anomaly_results = self.anomaly_detector.detect_rating_anomalies(all_movies)
        collection_anomalies = self.anomaly_detector.detect_collection_anomalies(collection_stats)
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = {
            'report_date': date_str,
            'generation_time': datetime.now().isoformat(),
            'data_summary': {
                'total_files_processed': len(daily_files),
                'total_movies_analyzed': len(all_movies),
                'unique_movies': len(set(m.get('id') for m in all_movies if m.get('id')))
            },
            'quality_summary': {
                'overall_quality_score': self._calculate_overall_quality(batch_results),
                'valid_rate': batch_results['valid_movies'] / batch_results['total_movies'] * 100,
                'quality_distribution': batch_results['quality_distribution'],
                'common_issues': batch_results['common_issues'],
                'recommendations': batch_results['recommendations']
            },
            'anomaly_analysis': {
                'rating_anomalies': anomaly_results['anomalies'],
                'collection_anomalies': collection_anomalies['anomalies'],
                'anomaly_count': len(anomaly_results['anomalies']) + len(collection_anomalies['anomalies'])
            },
            'data_health': self._assess_data_health(batch_results, anomaly_results, collection_anomalies)
        }
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        self._save_report(report, date_str)
        
        return report
    
    def _calculate_overall_quality(self, batch_results: Dict) -> float:
        """ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        quality_dist = batch_results['quality_distribution']
        total = batch_results['total_movies']
        
        if total == 0:
            return 0
        
        weighted_score = (
            quality_dist['excellent'] * 95 +
            quality_dist['good'] * 85 +
            quality_dist['fair'] * 75 +
            quality_dist['poor'] * 50
        ) / total
        
        return round(weighted_score, 2)
    
    def _assess_data_health(self, batch_results: Dict, anomaly_results: Dict, collection_anomalies: Dict) -> Dict:
        """ë°ì´í„° ê±´ê°•ë„ í‰ê°€"""
        health_score = 100
        issues = []
        
        # í’ˆì§ˆ ë¶ˆëŸ‰ë¥  ì²´í¬
        if batch_results['total_movies'] > 0:
            invalid_rate = batch_results['invalid_movies'] / batch_results['total_movies']
            if invalid_rate > 0.2:  # 20% ì´ìƒ
                health_score -= 30
                issues.append("high_invalid_rate")
            elif invalid_rate > 0.1:  # 10% ì´ìƒ
                health_score -= 15
                issues.append("moderate_invalid_rate")
        
        # ì´ìƒ íƒì§€ ê²°ê³¼ ì²´í¬
        anomaly_count = len(anomaly_results.get('anomalies', [])) + len(collection_anomalies.get('anomalies', []))
        if anomaly_count > 2:
            health_score -= 25
            issues.append("multiple_anomalies")
        elif anomaly_count > 0:
            health_score -= 10
            issues.append("minor_anomalies")
        
        # ê±´ê°•ë„ ë“±ê¸‰ ê²°ì •
        if health_score >= 90:
            grade = "ğŸŸ¢ Excellent"
        elif health_score >= 80:
            grade = "ğŸŸ¡ Good"
        elif health_score >= 70:
            grade = "ğŸŸ  Fair"
        else:
            grade = "ğŸ”´ Poor"
        
        return {
            'health_score': max(0, health_score),
            'grade': grade,
            'issues': issues
        }
    
    def _save_report(self, report: Dict, date_str: str):
        """ë¦¬í¬íŠ¸ ì €ì¥"""
        report_dir = Path('data/raw/metadata/quality_reports')
        report_dir.mkdir(parents=True, exist_ok=True)
        
        report_file = report_dir / f"daily_quality_report_{date_str}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        # ìµœì‹  ë¦¬í¬íŠ¸ ë§í¬ ìƒì„±
        latest_link = report_dir / "latest_quality_report.json"
        if latest_link.exists():
            latest_link.unlink()
        latest_link.symlink_to(report_file.name)
    
    def _find_daily_files(self, date_str: str) -> List[Path]:
        """í•´ë‹¹ ë‚ ì§œ ë°ì´í„° íŒŒì¼ ì°¾ê¸°"""
        data_dir = Path('data/raw/movies')
        pattern = f"*{date_str}*.json"
        
        files = []
        for subdir in ['daily', 'trending']:
            subdir_path = data_dir / subdir
            if subdir_path.exists():
                files.extend(subdir_path.glob(pattern))
        
        return files
```

### í’ˆì§ˆ ë¦¬í¬íŠ¸ ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

```bash
# ì¼ê°„ í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
docker exec mlops-dev bash -c "
cat > scripts/generate_daily_quality_report.py << 'EOF'
#!/usr/bin/env python3
\"\"\"ì¼ê°„ ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸\"\"\"

import sys
from pathlib import Path
from datetime import datetime, timedelta

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / 'src'))

from data_processing.quality_reporter import QualityReporter

def main():
    reporter = QualityReporter()
    
    # ì–´ì œ ë‚ ì§œ ë¦¬í¬íŠ¸ ìƒì„± (ë³´í†µ ìƒˆë²½ì— ì‹¤í–‰)
    yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
    
    print(f\"ì¼ê°„ í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘... (ë‚ ì§œ: {yesterday})\")
    
    try:
        report = reporter.generate_daily_report(yesterday)
        
        if report.get('status') == 'no_data':
            print(f\"ê²½ê³ : {yesterday} ë‚ ì§œì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")
            return
        
        # ë¦¬í¬íŠ¸ ìš”ì•½ ì¶œë ¥
        print(\"\\n=== ì¼ê°„ í’ˆì§ˆ ë¦¬í¬íŠ¸ ìš”ì•½ ===\")
        print(f\"ë¶„ì„ëœ ì˜í™” ìˆ˜: {report['data_summary']['total_movies_analyzed']}\")
        print(f\"ì „ì²´ í’ˆì§ˆ ì ìˆ˜: {report['quality_summary']['overall_quality_score']}/100\")
        print(f\"ìœ íš¨ ë°ì´í„° ë¹„ìœ¨: {report['quality_summary']['valid_rate']:.1f}%\")
        print(f\"ë°ì´í„° ê±´ê°•ë„: {report['data_health']['grade']}\")
        print(f\"ê°ì§€ëœ ì´ìƒ: {report['anomaly_analysis']['anomaly_count']}ê°œ\")
        
        if report['quality_summary']['recommendations']:
            print(\"\\n=== ê°œì„  ê¶Œì¥ì‚¬í•­ ===\")
            for i, rec in enumerate(report['quality_summary']['recommendations'], 1):
                print(f\"{i}. {rec}\")
        
        print(f\"\\nâœ… ë¦¬í¬íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: data/raw/metadata/quality_reports/daily_quality_report_{yesterday}.json\")
        
    except Exception as e:
        print(f\"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}\")
        sys.exit(1)

if __name__ == \"__main__\":
    main()
EOF

chmod +x scripts/generate_daily_quality_report.py
"
```

---

## ğŸ¯ 1.5.4 í’ˆì§ˆ ê°œì„  ì•¡ì…˜ ì‹œìŠ¤í…œ

### ìë™ ë°ì´í„° ì •ì œ

```python
class DataCleaner:
    """ìë™ ë°ì´í„° ì •ì œ"""
    
    def __init__(self):
        self.cleaning_stats = {
            'processed': 0,
            'cleaned': 0,
            'removed': 0,
            'actions': []
        }
    
    def clean_movie_data(self, movie: Dict) -> Tuple[Dict, str]:
        """ê°œë³„ ì˜í™” ë°ì´í„° ì •ì œ"""
        self.cleaning_stats['processed'] += 1
        original_movie = movie.copy()
        actions = []
        
        # 1. ë¹ˆ ë¬¸ìì—´ì„ Noneìœ¼ë¡œ ë³€í™˜
        for key, value in movie.items():
            if value == "":
                movie[key] = None
                actions.append(f"empty_to_none_{key}")
        
        # 2. ì œëª© ì •ì œ
        if movie.get('title'):
            cleaned_title = self._clean_title(movie['title'])
            if cleaned_title != movie['title']:
                movie['title'] = cleaned_title
                actions.append("title_cleaned")
        
        # 3. ê°œìš” ì •ì œ
        if movie.get('overview'):
            cleaned_overview = self._clean_overview(movie['overview'])
            if cleaned_overview != movie['overview']:
                movie['overview'] = cleaned_overview
                actions.append("overview_cleaned")
        
        # 4. ì¥ë¥´ ì •ê·œí™”
        if movie.get('genre_ids'):
            movie['genre_ids'] = self._normalize_genres(movie['genre_ids'])
            actions.append("genres_normalized")
        
        # 5. ë‚ ì§œ í˜•ì‹ í‘œì¤€í™”
        if movie.get('release_date'):
            standardized_date = self._standardize_date(movie['release_date'])
            if standardized_date != movie['release_date']:
                movie['release_date'] = standardized_date
                actions.append("date_standardized")
        
        if actions:
            self.cleaning_stats['cleaned'] += 1
            self.cleaning_stats['actions'].extend(actions)
        
        return movie, '; '.join(actions) if actions else 'no_cleaning_needed'
    
    def _clean_title(self, title: str) -> str:
        """ì œëª© ì •ì œ"""
        import re
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        title = re.sub(r'\s+', ' ', title.strip())
        # íŠ¹ìˆ˜ ë¬¸ì ì •ì œ
        title = re.sub(r'[^\w\s\-\.\,\!\?\:\(\)]', '', title)
        return title
    
    def _clean_overview(self, overview: str) -> str:
        """ê°œìš” ì •ì œ"""
        import re
        # HTML íƒœê·¸ ì œê±°
        overview = re.sub(r'<[^>]+>', '', overview)
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        overview = re.sub(r'\s+', ' ', overview.strip())
        return overview
    
    def _normalize_genres(self, genre_ids: List) -> List:
        """ì¥ë¥´ ì •ê·œí™”"""
        if not isinstance(genre_ids, list):
            return []
        return [int(g) for g in genre_ids if isinstance(g, (int, str)) and str(g).isdigit()]
    
    def _standardize_date(self, date_str: str) -> str:
        """ë‚ ì§œ í˜•ì‹ í‘œì¤€í™”"""
        import re
        from datetime import datetime
        
        # ì´ë¯¸ YYYY-MM-DD í˜•ì‹ì¸ì§€ í™•ì¸
        if re.match(r'^\d{4}-\d{2}-\d{2}$', date_str):
            return date_str
        
        # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
        date_patterns = [
            '%Y/%m/%d', '%Y.%m.%d', '%Y%m%d',
            '%m/%d/%Y', '%m-%d-%Y', '%d/%m/%Y'
        ]
        
        for pattern in date_patterns:
            try:
                dt = datetime.strptime(date_str, pattern)
                return dt.strftime('%Y-%m-%d')
            except ValueError:
                continue
        
        return date_str  # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜

def apply_batch_cleaning(self, movies: List[Dict]) -> Tuple[List[Dict], Dict]:
    """ë°°ì¹˜ ë°ì´í„° ì •ì œ"""
    cleaned_movies = []
    cleaning_report = {
        'total_processed': len(movies),
        'successfully_cleaned': 0,
        'removed_count': 0,
        'cleaning_actions': {},
        'removed_reasons': {}
    }
    
    for movie in movies:
        try:
            cleaned_movie, actions = self.clean_movie_data(movie)
            
            # ì •ì œ í›„ ì¬ê²€ì¦
            validator = DataQualityValidator()
            is_valid, reason, details = validator.validate_single_movie(cleaned_movie)
            
            if is_valid:
                cleaned_movies.append(cleaned_movie)
                cleaning_report['successfully_cleaned'] += 1
                
                # ì •ì œ ì•¡ì…˜ í†µê³„
                if actions != 'no_cleaning_needed':
                    for action in actions.split('; '):
                        cleaning_report['cleaning_actions'][action] = cleaning_report['cleaning_actions'].get(action, 0) + 1
            else:
                # ì •ì œ í›„ì—ë„ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ì œê±°
                cleaning_report['removed_count'] += 1
                cleaning_report['removed_reasons'][reason] = cleaning_report['removed_reasons'].get(reason, 0) + 1
                
        except Exception as e:
            cleaning_report['removed_count'] += 1
            cleaning_report['removed_reasons'][f'cleaning_error: {str(e)}'] = cleaning_report['removed_reasons'].get(f'cleaning_error: {str(e)}', 0) + 1
    
    return cleaned_movies, cleaning_report
```

---

## ğŸ¯ 1.5.5 ì‹¤ì œ êµ¬í˜„ëœ í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ ğŸ†•

### ëª©í‘œ
ì‹¤ì œ êµ¬í˜„ëœ DataQualityValidator, AnomalyDetector, DataCleaner í´ë˜ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¢…í•©ì  ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ ê²€ì¦

### ì‹¤ì œ êµ¬í˜„ëœ DataQualityValidator ì£¼ìš” ê¸°ëŠ¥

#### **í¬ê´„ì  í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ**
```python
# ì‹¤ì œ êµ¬í˜„ëœ í’ˆì§ˆ ê²€ì¦ ë¡œì§
class DataQualityValidator:
    def validate_single_movie(self, movie: Dict[str, Any]) -> Tuple[bool, str, Dict[str, Any]]:
        """ì‹¤ì œ êµ¬í˜„ëœ ë‹¨ì¼ ì˜í™” ë°ì´í„° ê²€ì¦"""
        
        validation_result = {
            'movie_id': movie.get('id', 'unknown'),
            'checks': {},
            'overall_score': 0,
            'issues': []
        }
        
        # 1. í•„ìˆ˜ í•„ë“œ ì¡´ì¬ í™•ì¸ (30% ê°€ì¤‘ì¹˜)
        required_check = self._check_required_fields(movie)
        validation_result['checks']['required_fields'] = required_check
        
        # 2. ë°ì´í„° íƒ€ì… ê²€ì¦ (25% ê°€ì¤‘ì¹˜)
        type_check = self._check_field_types(movie)
        validation_result['checks']['field_types'] = type_check
        
        # 3. ê°’ ë²”ìœ„ ê²€ì¦ (20% ê°€ì¤‘ì¹˜)
        range_check = self._check_field_ranges(movie)
        validation_result['checks']['field_ranges'] = range_check
        
        # 4. íŒ¨í„´ ê²€ì¦ (10% ê°€ì¤‘ì¹˜)
        pattern_check = self._check_field_patterns(movie)
        validation_result['checks']['field_patterns'] = pattern_check
        
        # 5. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê²€ì¦ (15% ê°€ì¤‘ì¹˜)
        business_check = self._check_business_logic(movie)
        validation_result['checks']['business_logic'] = business_check
        
        # 6. ì „ì²´ ì ìˆ˜ ê³„ì‚° (70ì  ì´ìƒ í†µê³¼)
        validation_result['overall_score'] = self._calculate_quality_score(validation_result['checks'])
        
        # 7. í†µê³¼/ì‹¤íŒ¨ íŒì •
        is_valid = validation_result['overall_score'] >= 70
        
        return is_valid, "Valid" if is_valid else f"Quality score too low: {validation_result['overall_score']}", validation_result
```

### ì‹¤ì œ êµ¬í˜„ëœ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ ğŸ†•

#### **ë‹¨ì¼ ì˜í™” ê²€ì¦ í…ŒìŠ¤íŠ¸**
```bash
# ì‹¤ì œ êµ¬í˜„ëœ í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸
docker exec -it mlops-dev python -c "
from src.data_processing.quality_validator import DataQualityValidator

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
test_movie_good = {
    'id': 12345,
    'title': 'í…ŒìŠ¤íŠ¸ ì˜í™”',
    'release_date': '2023-05-15',
    'vote_average': 8.5,
    'popularity': 1500.0,
    'overview': 'ì¢‹ì€ ì˜í™”ì…ë‹ˆë‹¤.',
    'adult': False,
    'vote_count': 1000
}

validator = DataQualityValidator()
is_valid, message, details = validator.validate_single_movie(test_movie_good)
print(f'ê²°ê³¼: {"\u2705 í†µê³¼" if is_valid else "\u274c ì‹¤íŒ¨"}')
print(f'ì ìˆ˜: {details["overall_score"]}/100')
"
```

---

## âœ… ì™„ë£Œ ê¸°ì¤€

### 1.5.1 ê¸°ëŠ¥ì  ì™„ë£Œ ê¸°ì¤€
- [ ] ì‹¤ì‹œê°„ í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ
- [ ] í•„ë“œë³„ ê²€ì¦ ê·œì¹™ ì •ìƒ ì‘ë™
- [ ] ë°°ì¹˜ í’ˆì§ˆ ë¶„ì„ ìë™ ì‹¤í–‰
- [ ] í†µê³„ì  ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ ë™ì‘
- [ ] ì¼ê°„ í’ˆì§ˆ ë¦¬í¬íŠ¸ ìë™ ìƒì„±

### 1.5.2 ê¸°ìˆ ì  ì™„ë£Œ ê¸°ì¤€
- [ ] í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì•Œê³ ë¦¬ì¦˜ ê²€ì¦
- [ ] ì´ìƒ íƒì§€ ì•Œê³ ë¦¬ì¦˜ ì •í™•ë„ í™•ì¸
- [ ] ìë™ ë°ì´í„° ì •ì œ ê¸°ëŠ¥ ì‘ë™
- [ ] í’ˆì§ˆ ê°œì„  ì•¡ì…˜ ì‹œìŠ¤í…œ êµ¬í˜„
- [ ] ë©”íƒ€ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œ í†µí•©

### 1.5.3 ìš´ì˜ì  ì™„ë£Œ ê¸°ì¤€
- [ ] í’ˆì§ˆ ì„ê³„ê°’ ê¸°ë°˜ ì•Œë¦¼ ì‹œìŠ¤í…œ
- [ ] í’ˆì§ˆ ì¶”ì„¸ ë¶„ì„ ë° ì‹œê°í™”
- [ ] í’ˆì§ˆ ë¦¬í¬íŠ¸ ìë™ ë°°í¬
- [ ] ë°ì´í„° í’ˆì§ˆ SLA ëª¨ë‹ˆí„°ë§
- [ ] í’ˆì§ˆ ê°œì„  ê¶Œì¥ì‚¬í•­ ìë™ ìƒì„±

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ì¤€ë¹„

### 1.7 ë¡œê¹… ì‹œìŠ¤í…œê³¼ í†µí•©
- í’ˆì§ˆ ê²€ì¦ ê²°ê³¼ë¥¼ ë¡œê¹… ì‹œìŠ¤í…œì— í†µí•©
- í’ˆì§ˆ ì´ë²¤íŠ¸ ê¸°ë°˜ ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•
- í’ˆì§ˆ ì§€í‘œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

### 2ë‹¨ê³„ í”¼ì²˜ ìŠ¤í† ì–´ ì—°ê³„
- ê²€ì¦ëœ ê³ í’ˆì§ˆ ë°ì´í„°ë§Œ í”¼ì²˜ ìŠ¤í† ì–´ë¡œ ì „ë‹¬
- í’ˆì§ˆ ë©”íƒ€ë°ì´í„°ë¥¼ í”¼ì²˜ì™€ í•¨ê»˜ ì €ì¥
- í’ˆì§ˆ ê¸°ë°˜ í”¼ì²˜ ì„ íƒ ì „ëµ ìˆ˜ë¦½

**ğŸ¯ ëª©í‘œ ë‹¬ì„±**: ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°ì´í„° í’ˆì§ˆ ë³´ì¥ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ!

**ë‹¤ìŒ ë‹¨ê³„**: 1.7 ë¡œê¹… ì‹œìŠ¤í…œ êµ¬ì¶•ìœ¼ë¡œ ì¢…í•©ì ì¸ ìš´ì˜ ê°€ì‹œì„± í™•ë³´
