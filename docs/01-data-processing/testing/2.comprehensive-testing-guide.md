---
title: "1ë‹¨ê³„ ë°ì´í„° ì²˜ë¦¬ ì¢…í•© í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ - Docker ê¸°ë°˜"
description: "1ë‹¨ê³„ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ Docker í™˜ê²½ì—ì„œ ì¢…í•©ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸"
stage: "01-data-processing"
phase: "testing"
category: "comprehensive-testing"
difficulty: "intermediate"
estimated_time: "8-12 hours"
tags:
  - comprehensive-testing
  - docker-testing
  - integration-testing
  - system-validation
  - end-to-end-testing
  - troubleshooting
authors:
  - mlops-team
last_updated: "2025-06-06"
version: "1.0"
status: "active"
prerequisites:
  - "1.1-1.8 ë‹¨ê³„ êµ¬í˜„ ì™„ë£„"
  - "Docker ë° Docker Compose"
  - "TMDB API í‚¤"
outcomes:
  - "ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ"
  - "ëª¨ë“  êµ¬ì„± ìš”ì†Œ ì •ìƒ ì‘ë™ í™•ì¸"
  - "ì„±ëŠ¥ ë° ì•ˆì •ì„± ê²€ì¦"
  - "ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ì œê³µ"
related_docs:
  - "../1.data-processing-implementation-guide.md"
  - "../implementation/"
  - "../../02-feature-store/"
testing_scope:
  - "1.1 ë°ì´í„° ì†ŒìŠ¤ ì—°ê²°"
  - "1.2 ë°ì´í„° í¬ë¡¤ëŸ¬"
  - "1.3 ìŠ¤ì¼€ì¤„ë§"
  - "1.4 ë°ì´í„° ì €ì¥ì†Œ"
  - "1.5 í’ˆì§ˆ ê²€ì¦"
  - "1.7 ë¡œê¹… ì‹œìŠ¤í…œ"
  - "1.8 Apache Airflow"
---

# 1ë‹¨ê³„ ë°ì´í„° ì²˜ë¦¬ ì¢…í•© í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ - Docker ê¸°ë°˜

## ğŸ“‹ ê°œìš”

ì´ ê°€ì´ë“œëŠ” 1ë‹¨ê³„ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ Docker í™˜ê²½ì—ì„œ ì¢…í•©ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

**í…ŒìŠ¤íŠ¸ ë²”ìœ„**: 1.1 ~ 1.8 ëª¨ë“  í•˜ìœ„ ë‹¨ê³„
**í™˜ê²½**: WSL Ubuntu 24.04 + Docker + Python 3.11
**ì „ì œ ì¡°ê±´**: TMDB API í‚¤ í•„ìš”

---

## ğŸ¯ í…ŒìŠ¤íŠ¸ ì¤€ë¹„

### 1. Docker í™˜ê²½ í™•ì¸

```

#### ğŸš¨ ìŠ¤ì¼€ì¤„ëŸ¬ ì˜¤ë¥˜ í•´ê²° ê°€ì´ë“œ

**ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë° í•´ê²°ì±…**:

##### **1. AttributeError: 'Job' object has no attribute 'month'**
##### **5. ì„±ê³µì ì¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ì˜ˆìƒ ê²°ê³¼**
```
âœ… TMDBDataScheduler ì´ˆê¸°í™” ì„±ê³µ
[2025-06-05 02:31:05,186] INFO tmdb_scheduler | ìŠ¤ì¼€ì¤„ ì‘ì—… ì„¤ì • ì¤‘...
[2025-06-05 02:31:05,187] INFO tmdb_scheduler | ì´ 5ê°œ ì‘ì—…ì´ ìŠ¤ì¼€ì¤„ë˜ì—ˆìŠµë‹ˆë‹¤.
âœ… ìŠ¤ì¼€ì¤„ ì‘ì—… ì„¤ì • ì™„ë£Œ: 0ê°œ ì‘ì—…
ë“±ë¡ëœ ì‘ì—… ìˆ˜: 5ê°œ
1. Every 1 day at 02:00:00 do _safe_job_wrapper() (last run: [never], next run: 2025-06-06 02:00:00)
2. Every 1 week do _safe_job_wrapper() (last run: [never], next run: 2025-06-08 03:00:00)
3. Every 1 hour do _safe_job_wrapper() (last run: [never], next run: 2025-06-05 12:00:00)
4. Every 1 day at 04:00:00 do _safe_job_wrapper() (last run: [never], next run: 2025-06-06 04:00:00)
5. Every 10 minutes do _safe_job_wrapper() (last run: [never], next run: 2025-06-05 02:41:05)
```

**ìŠ¤ì¼€ì¤„ëœ ì‘ì—… ì„¤ëª…**:
- **ì‘ì—… 1**: ì¼ì¼ ìˆ˜ì§‘ (ë§¤ì¼ ìƒˆë²½ 2ì‹œ)
- **ì‘ì—… 2**: ì£¼ê°„ ìˆ˜ì§‘ (ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 3ì‹œ)
- **ì‘ì—… 3**: ì‹œê°„ë³„ íŠ¸ë Œë”© (ë§¤ì‹œê°„ ì •ê°, ìš´ì˜ì‹œê°„ 8-22ì‹œ)
- **ì‘ì—… 4**: ì›”ê°„ ì²´í¬ (ë§¤ì¼ ìƒˆë²½ 4ì‹œ, ë§¤ì›” 1ì¼ì—ë§Œ ì‹¤í–‰)
- **ì‘ì—… 5**: í—¬ìŠ¤ì²´í¬ (ë§¤ 10ë¶„ë§ˆë‹¤)

---
# ì¦ìƒ
AttributeError: 'Job' object has no attribute 'month'

# ì›ì¸: schedule ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì›”ê°„ ìŠ¤ì¼€ì¤„ë§ì„ ì§ì ‘ ì§€ì›í•˜ì§€ ì•ŠìŒ
# í•´ê²°: ì´ë¯¸ ìˆ˜ì •ë¨ (ë§¤ì¼ ì²´í¬ í›„ ì›” 1ì¼ì—ë§Œ ì‹¤í–‰í•˜ëŠ” ë°©ì‹)
```

##### **2. ModuleNotFoundError ì˜¤ë¥˜**
```bash
# schedule ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í™•ì¸
docker exec mlops-dev pip list | grep schedule

# ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš°
docker exec mlops-dev pip install schedule
```

##### **3. ìŠ¤ì¼€ì¤„ ì‘ì—…ì´ ë“±ë¡ë˜ì§€ ì•ŠëŠ” ê²½ìš°**
```bash
# ìŠ¤ì¼€ì¤„ ìƒíƒœ ì´ˆê¸°í™” í›„ ì¬ì‹œë„
docker exec mlops-dev python -c "
import schedule
schedule.clear()  # ê¸°ì¡´ ì‘ì—… ëª¨ë‘ ì œê±°
from src.data_processing.scheduler import TMDBDataScheduler
scheduler = TMDBDataScheduler()
scheduler.setup_jobs()
print(f'ì¬ì„¤ì • ì™„ë£Œ: {len(schedule.jobs)}ê°œ ì‘ì—…')
"
```

##### **4. ì›”ê°„ ìŠ¤ì¼€ì¤„ë§ ì´í•´**
**ìˆ˜ì • ì „** (ì˜¤ë¥˜ ë°œìƒ):
```python
schedule.every().month.do(...)  # ì§€ì›ë˜ì§€ ì•ŠëŠ” ë©”ì„œë“œ
```

**ìˆ˜ì • í›„** (ì •ìƒ ì‘ë™):
```python
# ë§¤ì¼ ìƒˆë²½ 4ì‹œì— ì²´í¬
schedule.every().day.at("04:00").do(self._safe_job_wrapper, self._monthly_check, "monthly_check")

# _monthly_check() ë©”ì„œë“œì—ì„œ ë§¤ì›” 1ì¼ì—ë§Œ ì‹¤ì œ ì‹¤í–‰
def _monthly_check(self):
    if datetime.now().day == 1:  # ë§¤ì›” 1ì¼ì—ë§Œ
        return self.monthly_full_refresh()
    return None
```

##### **5. ì„±ê³µì ì¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ì˜ˆìƒ ê²°ê³¼**
```
âœ… TMDBDataScheduler ì´ˆê¸°í™” ì„±ê³µ
[2025-06-05 11:31:05,186] INFO tmdb_scheduler | ìŠ¤ì¼€ì¤„ ì‘ì—… ì„¤ì • ì¤‘...
[2025-06-05 11:31:05,187] INFO tmdb_scheduler | ì´ 5ê°œ ì‘ì—…ì´ ìŠ¤ì¼€ì¤„ë˜ì—ˆìŠµë‹ˆë‹¤.
âœ… ìŠ¤ì¼€ì¤„ ì‘ì—… ì„¤ì • ì™„ë£Œ: 0ê°œ ì‘ì—…
ë“±ë¡ëœ ì‘ì—… ìˆ˜: 5ê°œ
1. Every 1 day at 02:00:00 do _safe_job_wrapper() (last run: [never], next run: 2025-06-06 02:00:00)
2. Every 1 week do _safe_job_wrapper() (last run: [never], next run: 2025-06-08 03:00:00)
3. Every 1 hour do _safe_job_wrapper() (last run: [never], next run: 2025-06-05 12:00:00)
4. Every 1 day at 04:00:00 do _safe_job_wrapper() (last run: [never], next run: 2025-06-06 04:00:00)
5. Every 10 minutes do _safe_job_wrapper() (last run: [never], next run: 2025-06-05 11:41:05)
```

**ìŠ¤ì¼€ì¤„ëœ ì‘ì—… ì„¤ëª…**:
- **ì‘ì—… 1**: ì¼ì¼ ìˆ˜ì§‘ (ë§¤ì¼ ìƒˆë²½ 2ì‹œ)
- **ì‘ì—… 2**: ì£¼ê°„ ìˆ˜ì§‘ (ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 3ì‹œ)
- **ì‘ì—… 3**: ì‹œê°„ë³„ íŠ¸ë Œë”© (ë§¤ì‹œê°„ ì •ê°, ìš´ì˜ì‹œê°„ 8-22ì‹œ)
- **ì‘ì—… 4**: ì›”ê°„ ì²´í¬ (ë§¤ì¼ ìƒˆë²½ 4ì‹œ, ë§¤ì›” 1ì¼ì—ë§Œ ì‹¤í–‰)
- **ì‘ì—… 5**: í—¬ìŠ¤ì²´í¬ (ë§¤ 10ë¶„ë§ˆë‹¤)

---

### 1. Docker í™˜ê²½ í™•ì¸

```bash
# Docker ìƒíƒœ í™•ì¸
docker --version
docker compose --version

# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd /mnt/c/dev/movie-mlops

# Docker ì»¨í…Œì´ë„ˆ ì¬ë¹Œë“œ (jqì™€ treeëŠ” Dockerfileì— ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìŒ)
docker compose down
docker compose build dev
docker compose up -d dev

# ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker compose ps

# jq ë° tree ì„¤ì¹˜ í™•ì¸ (ì´ë¯¸ Dockerfileì— í¬í•¨ë˜ì–´ ìˆìŒ)
docker exec mlops-dev jq --version
docker exec mlops-dev tree --version
```

**ì°¸ê³ **: `jq`ì™€ `tree`ëŠ” ì´ë¯¸ Dockerfile.devì— í¬í•¨ë˜ì–´ ìë™ìœ¼ë¡œ ì„¤ì¹˜ë©ë‹ˆë‹¤. ë§Œì•½ `command not found` ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì»¨í…Œì´ë„ˆë¥¼ ì¬ë¹Œë“œí•˜ì„¸ìš”:
```bash
docker compose down
docker compose build dev --no-cache
docker compose up -d dev
```

### 2. í™˜ê²½ë³€ìˆ˜ ì„¤ì • í™•ì¸ ë° ë¬¸ì œ í•´ê²°

```bash
# .env íŒŒì¼ ì¡´ì¬ í™•ì¸
docker exec mlops-dev ls -la .env

# .env íŒŒì¼ ë‚´ìš© í™•ì¸ (API í‚¤ í¬í•¨)
docker exec mlops-dev bash -c "cat .env | grep TMDB_API_KEY"

# Docker ì»¨í…Œì´ë„ˆ í™˜ê²½ë³€ìˆ˜ í™•ì¸
docker exec mlops-dev bash -c "echo \$TMDB_API_KEY"

# í™˜ê²½ë³€ìˆ˜ ë¡œë”© í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
import os
from dotenv import load_dotenv
print('ë¡œë“œ ì „ API í‚¤:', os.getenv('TMDB_API_KEY'))
load_dotenv(override=True)  # ê°•ì œ ë®ì–´ì“°ê¸°
print('ë¡œë“œ í›„ API í‚¤:', os.getenv('TMDB_API_KEY'))
"
```

**ì¤‘ìš” ë¬¸ì œ í•´ê²° ê°€ì´ë“œ**:

#### ğŸš¨ API í‚¤ í™˜ê²½ë³€ìˆ˜ ë¡œë”© ë¬¸ì œ

**ì¦ìƒ**: .env íŒŒì¼ì—ëŠ” ì‹¤ì œ API í‚¤ê°€ ìˆì§€ë§Œ, Docker ì»¨í…Œì´ë„ˆì—ì„œëŠ” `your_tmdb_api_key_here`ê°€ ì‚¬ìš©ë¨

```bash
# ë¬¸ì œ ì¦ìƒ í™•ì¸
docker exec mlops-dev bash -c "cat .env | grep TMDB_API_KEY"    # ì‹¤ì œ API í‚¤
docker exec mlops-dev bash -c "echo \$TMDB_API_KEY"             # your_tmdb_api_key_here

# ì¦ì‹œ í•´ê²°: ìë™ í•´ê²° ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
chmod +x scripts/fix-env-vars.sh
./scripts/fix-env-vars.sh
```

**ìˆ˜ë™ í•´ê²° ë°©ë²•**:

```bash
# í•´ê²° ë°©ë²• 1: Docker ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘ (ê°€ì¥ ê°„ë‹¨)
docker compose down
docker compose up -d dev

# í•´ê²° ë°©ë²• 2: í™˜ê²½ë³€ìˆ˜ ì œê±° í›„ í…ŒìŠ¤íŠ¸
docker exec mlops-dev bash -c "
unset TMDB_API_KEY
cd /app
python src/data_processing/test_integration.py
"

# í•´ê²° ë°©ë²• 3: ê°•ì œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
API_KEY=$(docker exec mlops-dev bash -c "cat .env | grep TMDB_API_KEY | cut -d'=' -f2")
docker exec -e TMDB_API_KEY="$API_KEY" mlops-dev python src/data_processing/test_integration.py
```

#### ğŸ“ .env íŒŒì¼ ì„¤ì • ë°©ë²•

```bash
# 1. .env íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° í…œí”Œë¦¿ì—ì„œ ë³µì‚¬
docker exec mlops-dev bash -c "
if [ ! -f .env ]; then
    cp .env.template .env
    echo '.env íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. TMDB_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.'
fi
"

# 2. API í‚¤ ì„¤ì • (ì‹¤ì œ í‚¤ë¡œ êµì²´ í•„ìš”)
docker exec mlops-dev bash -c "
sed -i 's/your_tmdb_api_key_here/ì‹¤ì œ_TMDB_API_í‚¤/' .env
echo 'API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.'
"

# 3. ì„¤ì • í™•ì¸
docker exec mlops-dev bash -c "cat .env | grep TMDB_API_KEY"
```

#### ğŸ”¥ ê°•ë ¥í•œ ë¬¸ì œ í•´ê²° (ìƒê¸‰)

**ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í•œ ê²½ìš° ì‚¬ìš©:**

```bash
# ë°©ë²• 1: ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ í™˜ê²½ë³€ìˆ˜ ì§ì ‘ ìˆ˜ì •
docker exec mlops-dev bash -c "
# ê¸°ì¡´ í™˜ê²½ë³€ìˆ˜ ì œê±°
unset TMDB_API_KEY
unset DB_PASSWORD

# .env íŒŒì¼ì—ì„œ API í‚¤ ì¶”ì¶œ ë° ì„¤ì •
API_KEY=\$(grep '^TMDB_API_KEY=' .env | cut -d'=' -f2 | tr -d ' ')

if [ -n '\$API_KEY' ] && [ '\$API_KEY' != 'your_tmdb_api_key_here' ]; then
    export TMDB_API_KEY=\$API_KEY
    echo 'âœ… API í‚¤ ì„¤ì • ì™„ë£Œ:' \$TMDB_API_KEY
else
    echo 'âŒ .env íŒŒì¼ì— ì˜¬ë°”ë¥¸ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.'
fi

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
cd /app
python src/data_processing/test_integration.py
"

# ë°©ë²• 2: Docker Compose í™˜ê²½ë³€ìˆ˜ ê°•ì œ ì„¤ì •
API_KEY=$(grep '^TMDB_API_KEY=' .env | cut -d'=' -f2 | tr -d ' ')
docker exec -e TMDB_API_KEY="$API_KEY" mlops-dev python src/data_processing/test_integration.py

# ë°©ë²• 3: Python ë‚´ë¶€ì—ì„œ í™˜ê²½ë³€ìˆ˜ ê°•ì œ ì„¤ì •
docker exec mlops-dev python -c "
import os
from dotenv import load_dotenv

# í”Œë ˆì´ìŠ¤í™€ë” ê°’ ì œê±°
if 'your_' in os.getenv('TMDB_API_KEY', '').lower():
    os.environ.pop('TMDB_API_KEY', None)

# .env íŒŒì¼ì—ì„œ ê°•ì œ ë¡œë“œ
load_dotenv(override=True)

api_key = os.getenv('TMDB_API_KEY')
print(f'API í‚¤ ë¡œë“œ ê²°ê³¼: {api_key[:8] if api_key else "None"}...')

# API í…ŒìŠ¤íŠ¸
from src.data_processing.tmdb_api_connector import test_tmdb_connection
result = test_tmdb_connection()
print(f'í…ŒìŠ¤íŠ¸ ê²°ê³¼: {"âœ… ì„±ê³µ" if result else "âŒ ì‹¤íŒ¨"}')
"
```

### 3. ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸

```bash
# í•„ìˆ˜ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
docker exec mlops-dev bash -c "
mkdir -p data/{raw,processed,backup,test,staging}
mkdir -p data/raw/movies/{daily,weekly,monthly,genre,trending}
mkdir -p logs/{app,data,error,performance,health}
mkdir -p reports
echo 'ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ'
"
```

---

## ğŸ§ª 1.1 ë°ì´í„° ì†ŒìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸

### í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# 1.1 ë‹¨ê³„ í†µí•© í…ŒìŠ¤íŠ¸ (ë°©ë²• 2: bashë¡œ ë“¤ì–´ê°€ì„œ ì‹¤í–‰)
docker exec -it mlops-dev bash
# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ:
cd /app
python src/data_processing/test_integration.py
```

**ì°¸ê³ **: Python ëŒ€í™”í˜• ëª¨ë“œ(`docker exec -it mlops-dev python`)ë¡œ ë“¤ì–´ê°„ í›„ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ëª…ì„ ì…ë ¥í•˜ëŠ” ê²ƒì€ ì˜¬ë°”ë¥¸ ë°©ë²•ì´ ì•„ë‹™ë‹ˆë‹¤. ë°˜ë“œì‹œ ìœ„ì˜ ë°©ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.

**ì˜ˆìƒ ê²°ê³¼**:
```
============================================================
TMDB API ì—°ë™ 1.1 ë‹¨ê³„ í†µí•© í…ŒìŠ¤íŠ¸
============================================================

1. í™˜ê²½ë³€ìˆ˜ ì„¤ì • í…ŒìŠ¤íŠ¸...
   ê²°ê³¼: âœ… ì„±ê³µ

2. Rate Limiter í…ŒìŠ¤íŠ¸...
   ê²°ê³¼: âœ… ì„±ê³µ

3. ì‘ë‹µ íŒŒì‹± í…ŒìŠ¤íŠ¸...
   ê²°ê³¼: âœ… ì„±ê³µ

4. API ì—°ê²° í…ŒìŠ¤íŠ¸...
   ê²°ê³¼: âœ… ì„±ê³µ

5. í†µí•© í…ŒìŠ¤íŠ¸...
   ê²°ê³¼: âœ… ì„±ê³µ

ì „ì²´ ê²°ê³¼: 5/5 í†µê³¼ (100.0%)
í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ì €ì¥ë¨: /app/reports/tmdb_test_report_20250605_020746.json

ê¶Œì¥ì‚¬í•­:
1. ëª¨ë“  ê¸°ë³¸ í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í–ˆìŠµë‹ˆë‹¤. ì´ì œ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

í…ŒìŠ¤íŠ¸ ì™„ë£Œ!
```

**ğŸ‰ ì„±ê³µ ì‹œ ë‹¤ìŒ ë‹¨ê³„**:
```bash
# ì»¨í…Œì´ë„ˆì—ì„œ ë‚˜ê°€ê¸° (ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì— ìˆëŠ” ê²½ìš°)
exit

# í˜¸ìŠ¤íŠ¸ì—ì„œ jqë¡œ ê²°ê³¼ í™•ì¸
docker exec mlops-dev bash -c "
latest_report=\$(ls -t reports/tmdb_test_report_*.json 2>/dev/null | head -1)
if [ -f \"\$latest_report\" ]; then
    echo '=== ìµœì‹  í…ŒìŠ¤íŠ¸ ê²°ê³¼ ==='
    cat \"\$latest_report\" | jq '.summary'
    
    echo -e '\n=== ê¶Œì¥ì‚¬í•­ ==='
    cat \"\$latest_report\" | jq '.recommendations[]?'
fi
"

# 1.2ë‹¨ê³„ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ë¡œ ì§„í–‰
docker exec -it mlops-dev python src/data_processing/test_crawler.py
```

### ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸

```bash
# API ì—°ê²° ë‹¨ë… í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from src.data_processing.tmdb_api_connector import test_tmdb_connection
if test_tmdb_connection():
    print('âœ… API ì—°ê²° ì„±ê³µ')
else:
    print('âŒ API ì—°ê²° ì‹¤íŒ¨')
"

# Rate Limiter í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from src.data_processing.rate_limiter import RateLimiter, RateLimitConfig
limiter = RateLimiter(RateLimitConfig())
print('âœ… Rate Limiter ë¡œë“œ ì„±ê³µ')
"

# ì‘ë‹µ íŒŒì„œ í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from src.data_processing.response_parser import TMDBResponseParser
parser = TMDBResponseParser()
print('âœ… Response Parser ë¡œë“œ ì„±ê³µ')
"
```

### 1.1 í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸

```bash
# í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ íŒŒì¼ ëª©ë¡ í™•ì¸
docker exec mlops-dev ls -la reports/tmdb_test_report_*.json

# ìµœì‹  ë³´ê³ ì„œ ë‚´ìš© í™•ì¸ (jq ì‚¬ìš©)
docker exec mlops-dev bash -c "
latest_report=\$(ls -t reports/tmdb_test_report_*.json 2>/dev/null | head -1)
if [ -f \"\$latest_report\" ]; then
    echo '=== ìµœì‹  í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ==='
    cat \"\$latest_report\" | jq '.summary'
else
    echo 'ë³´ê³ ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
fi
"

# ë˜ëŠ” ì „ì²´ ë³´ê³ ì„œ ë‚´ìš© í™•ì¸
docker exec mlops-dev bash -c "
latest_report=\$(ls -t reports/tmdb_test_report_*.json 2>/dev/null | head -1)
if [ -f \"\$latest_report\" ]; then
    echo '=== ì „ì²´ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ==='
    cat \"\$latest_report\" | jq '.'
fi
"

# íŠ¹ì • í•„ë“œë§Œ ì¶”ì¶œ (ì˜ˆ: ì¶”ì²œì‚¬í•­)
docker exec mlops-dev bash -c "
latest_report=\$(ls -t reports/tmdb_test_report_*.json 2>/dev/null | head -1)
if [ -f \"\$latest_report\" ]; then
    echo '=== ì¶”ì²œì‚¬í•­ ==='
    cat \"\$latest_report\" | jq '.recommendations[]?'
fi
"

# ë¡œê·¸ íŒŒì¼ í™•ì¸
docker exec mlops-dev tail -20 logs/test_tmdb_integration.log
```

**âš ï¸ ì£¼ì˜ì‚¬í•­**: Docker ì»¨í…Œì´ë„ˆ **ë‚´ë¶€**ì—ì„œ `docker` ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ `docker: command not found` ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤. ì´ëŠ” ì •ìƒì ì¸ ë™ì‘ì…ë‹ˆë‹¤.

**í•´ê²° ë°©ë²•**:
```bash
# ì»¨í…Œì´ë„ˆì—ì„œ ë‚˜ê°€ê¸°
exit

# í˜¸ìŠ¤íŠ¸ì—ì„œ jq ì‹¤í–‰
docker exec mlops-dev bash -c "..."
```

**jq ëª…ë ¹ì–´ ì„¤ëª…**:
- `jq '.'`: ì „ì²´ JSONì„ ì˜ˆì˜ê²Œ í¬ë§§íŒ…
- `jq '.summary'`: summary í•„ë“œë§Œ ì¶”ì¶œ
- `jq '.recommendations[]?'`: recommendations ë°°ì—´ì˜ ê° ìš”ì†Œë¥¼ ê°œë³„ ì¶œë ¥
- `jq '.summary.success_rate'`: ì¤‘ì²©ëœ í•„ë“œ ì ‘ê·¼

---

## ğŸ•·ï¸ 1.2 ë°ì´í„° í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸

### í¬ë¡¤ëŸ¬ í†µí•© í…ŒìŠ¤íŠ¸

```bash
# 1.2 ë‹¨ê³„ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸
docker exec -it mlops-dev python src/data_processing/test_crawler.py
```

**ì˜ˆìƒ ê²°ê³¼**:
```
============================================================
TMDB í¬ë¡¤ëŸ¬ 1.2 ë‹¨ê³„ í†µí•© í…ŒìŠ¤íŠ¸
============================================================

1. ê¸°ë³¸ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸...
   ê²°ê³¼: âœ… ì„±ê³µ

2. ëŒ€ëŸ‰ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸...
   ê²°ê³¼: âœ… ì„±ê³µ

3. ì¥ë¥´ë³„ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸...
   ê²°ê³¼: âœ… ì„±ê³µ

4. íŠ¸ë Œë”© ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸...
   ê²°ê³¼: âœ… ì„±ê³µ

5. í‰ì  ë†’ì€ ì˜í™” í…ŒìŠ¤íŠ¸...
   ê²°ê³¼: âœ… ì„±ê³µ

6. ì¢…í•© ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸...
   ê²°ê³¼: âœ… ì„±ê³µ

7. ë¹ ë¥¸ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸...
   ê²°ê³¼: âœ… ì„±ê³µ

ì „ì²´ ê²°ê³¼: 7/7 í†µê³¼ (100.0%)
```

### ê°œë³„ í¬ë¡¤ëŸ¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

```bash
# TMDBCrawler ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from src.data_processing.tmdb_crawler import TMDBCrawler
crawler = TMDBCrawler()
print('âœ… TMDBCrawler ì´ˆê¸°í™” ì„±ê³µ')

# ì¸ê¸° ì˜í™” 3í˜ì´ì§€ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
movies = crawler.get_popular_movies_bulk(1, 3)
print(f'âœ… ì¸ê¸° ì˜í™” ìˆ˜ì§‘: {len(movies)}ê°œ')

# ë°ì´í„° ê²€ì¦ í…ŒìŠ¤íŠ¸
valid_movies = crawler.filter_valid_movies(movies)
print(f'âœ… ê²€ì¦ í†µê³¼: {len(valid_movies)}ê°œ')

crawler.close()
"

# ì¥ë¥´ë³„ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from src.data_processing.tmdb_crawler import TMDBCrawler
crawler = TMDBCrawler()

# ì•¡ì…˜ ì¥ë¥´ ì˜í™” ìˆ˜ì§‘ (ì¥ë¥´ ID: 28)
action_movies = crawler.get_movies_by_genre(28, 2)
print(f'âœ… ì•¡ì…˜ ì˜í™” ìˆ˜ì§‘: {len(action_movies)}ê°œ')

crawler.close()
"

# íŠ¸ë Œë”© ì˜í™” ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from src.data_processing.tmdb_crawler import TMDBCrawler
crawler = TMDBCrawler()

# ì¼ê°„ íŠ¸ë Œë”© ìˆ˜ì§‘
trending = crawler.get_trending_movies('day')
print(f'âœ… ì¼ê°„ íŠ¸ë Œë”©: {len(trending)}ê°œ')

crawler.close()
"
```

### ëŒ€ëŸ‰ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸

```bash
# ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (ì†Œê·œëª¨)
docker exec -it mlops-dev python src/data_processing/bulk_collection_test.py
```

**í…ŒìŠ¤íŠ¸ ì˜µì…˜ ì„ íƒ**:
```
í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:
1. ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸ (100ê°œ ì˜í™”, 5í˜ì´ì§€)
2. ì¤‘ê°„ ê·œëª¨ í…ŒìŠ¤íŠ¸ (500ê°œ ì˜í™”, 25í˜ì´ì§€)
3. ëŒ€ëŸ‰ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (1000ê°œ ì˜í™”, 50í˜ì´ì§€)

ì„ íƒ (1-3, ê¸°ë³¸ê°’ 1): 1
```

### 1.2 ìˆ˜ì§‘ ê²°ê³¼ í™•ì¸

```bash
# ìˆ˜ì§‘ëœ íŒŒì¼ í™•ì¸
docker exec mlops-dev find data/raw/movies -name "*.json" | head -10

# ìµœì‹  ìˆ˜ì§‘ íŒŒì¼ ë¶„ì„ (ì˜í™” ë°ì´í„°ê°€ ìˆëŠ” íŒŒì¼ ìš°ì„ )
docker exec mlops-dev python -c "
import json
from pathlib import Path
from datetime import datetime

data_dir = Path('data/raw/movies')
if data_dir.exists():
    json_files = list(data_dir.rglob('*.json'))
    
    # ì˜í™” ë°ì´í„°ê°€ ìˆëŠ” íŒŒì¼ë“¤ë§Œ í•„í„°ë§
    movie_files = []
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            movies = data.get('movies', [])
            if len(movies) > 0:
                movie_files.append({
                    'file': json_file,
                    'movie_count': len(movies),
                    'mtime': json_file.stat().st_mtime
                })
        except Exception:
            continue
    
    if movie_files:
        # ì˜í™” ë°ì´í„°ê°€ ìˆëŠ” íŒŒì¼ ì¤‘ ê°€ì¥ ìµœì‹  íŒŒì¼ ì„ íƒ
        latest_movie_file = max(movie_files, key=lambda x: x['mtime'])
        latest_file = latest_movie_file['file']
        
        print(f'ìµœì‹  ì˜í™” ë°ì´í„° íŒŒì¼: {latest_file.name}')
        
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if 'collection_info' in data:
            info = data['collection_info']
            print(f'ìˆ˜ì§‘ ì‹œê°„: {info.get(\"timestamp\")}')
            print(f'ì´ ì˜í™”: {info.get(\"total_movies\")}ê°œ')
        
        movies = data.get('movies', [])
        print(f'ì‹¤ì œ ì˜í™” ë°ì´í„°: {len(movies)}ê°œ')
        
        if movies:
            first_movie = movies[0]
            last_movie = movies[-1]
            print(f'ì²« ë²ˆì§¸ ì˜í™”: {first_movie.get(\"title\")} (í‰ì : {first_movie.get(\"vote_average\")})')
            print(f'ë§ˆì§€ë§‰ ì˜í™”: {last_movie.get(\"title\")} (í‰ì : {last_movie.get(\"vote_average\")})')
        
        # ì „ì²´ ì˜í™” ë°ì´í„° í˜„í™© ìš”ì•½
        print(f'\\n=== ì „ì²´ ìˆ˜ì§‘ í˜„í™© ===')
        total_movies = sum(info['movie_count'] for info in movie_files)
        print(f'ì´ íŒŒì¼ ìˆ˜: {len(movie_files)}ê°œ')
        print(f'ì´ ì˜í™” ìˆ˜: {total_movies}ê°œ')
    else:
        print('âŒ ì˜í™” ë°ì´í„°ê°€ ìˆëŠ” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
else:
    print('âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.')
"
```

---

## ğŸ“… 1.3 ë°ì´í„° ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ë§ í…ŒìŠ¤íŠ¸

### ìŠ¤ì¼€ì¤„ëŸ¬ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

```bash
# ìˆ˜ì •ëœ ìŠ¤ì¼€ì¤„ëŸ¬ í…ŒìŠ¤íŠ¸ (ì›”ê°„ ì˜¤ë¥˜ ìˆ˜ì •ë¨)
docker exec mlops-dev python -c "
from src.data_processing.scheduler import TMDBDataScheduler
scheduler = TMDBDataScheduler()
print('âœ… TMDBDataScheduler ì´ˆê¸°í™” ì„±ê³µ')

# ì‘ì—… ì„¤ì • í…ŒìŠ¤íŠ¸
scheduler.setup_jobs()
print(f'âœ… ìŠ¤ì¼€ì¤„ ì‘ì—… ì„¤ì • ì™„ë£Œ: {len(scheduler.job_history)}ê°œ ì‘ì—…')

# ìŠ¤ì¼€ì¤„ëœ ì‘ì—… ëª©ë¡ í™•ì¸
import schedule
print(f'ë“±ë¡ëœ ì‘ì—… ìˆ˜: {len(schedule.jobs)}ê°œ')
for i, job in enumerate(schedule.jobs):
    print(f'{i+1}. {job}')
"

# ê°œë³„ ìˆ˜ì§‘ ì‘ì—… í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from src.data_processing.scheduler import TMDBDataScheduler
scheduler = TMDBDataScheduler()
print('=== ì¼ì¼ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===')

result = scheduler.daily_collection()
if result:
    print(f'âœ… ì¼ì¼ ìˆ˜ì§‘ ì„±ê³µ: {result.get(\"total_valid\")}ê°œ ì˜í™”')
    print(f'í’ˆì§ˆë¥ : {result.get(\"quality_rate\", 0):.1f}%')
else:
    print('âŒ ì¼ì¼ ìˆ˜ì§‘ ì‹¤íŒ¨')
"
```

### ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ë° í—¬ìŠ¤ì²´í¬

```bash
# í—¬ìŠ¤ì²´í¬ í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from src.data_processing.scheduler import TMDBDataScheduler
scheduler = TMDBDataScheduler()

health = scheduler.health_check()
print('=== ìŠ¤ì¼€ì¤„ëŸ¬ í—¬ìŠ¤ì²´í¬ ===')
print(f'ì‹œìŠ¤í…œ ìƒíƒœ: {health.get(\"system_status\")}')
print(f'ìµœê·¼ ì‹¤íŒ¨: {len(health.get(\"recent_job_failures\", []))}ê±´')
"

# ì‘ì—… í†µê³„ í™•ì¸
docker exec mlops-dev python -c "
from src.data_processing.scheduler import TMDBDataScheduler
scheduler = TMDBDataScheduler()

# ì„ì‹œë¡œ ëª‡ ê°œ ì‘ì—… ì‹¤í–‰ í›„ í†µê³„ í™•ì¸
scheduler.daily_collection()

stats = scheduler.get_job_statistics(days=1)
print('=== ì‘ì—… í†µê³„ (ìµœê·¼ 1ì¼) ===')
print(f'ì´ ì‘ì—…: {stats[\"total_jobs\"]}ê°œ')
print(f'ì„±ê³µë¥ : {stats[\"success_rate\"]:.1f}%')
if stats[\"avg_duration\"] > 0:
    print(f'í‰ê·  ì‹¤í–‰ì‹œê°„: {stats[\"avg_duration\"]:.1f}ì´ˆ')
"
```

### ìŠ¤ì¼€ì¤„ëŸ¬ ë°ëª¬ í…ŒìŠ¤íŠ¸

```bash
# ìŠ¤ì¼€ì¤„ëŸ¬ ì œì–´ ìŠ¤í¬ë¦½íŠ¸ ê¶Œí•œ ì„¤ì •
docker exec mlops-dev chmod +x scripts/scheduler_control.sh

# ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸
docker exec mlops-dev bash scripts/scheduler_control.sh status

# ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ (í…ŒìŠ¤íŠ¸ìš© - ì ê¹ë§Œ ì‹¤í–‰)
docker exec mlops-dev bash -c "
echo 'ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ í…ŒìŠ¤íŠ¸ (5ì´ˆ í›„ ì¢…ë£Œ)'
timeout 5s python src/data_processing/scheduler_daemon.py || true
echo 'ìŠ¤ì¼€ì¤„ëŸ¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ'
"
```

### 1.3 ê²°ê³¼ í™•ì¸

```bash
# ìŠ¤ì¼€ì¤„ë§ëœ ìˆ˜ì§‘ ê²°ê³¼ í™•ì¸
docker exec mlops-dev find data/raw/movies -name "daily_*" -o -name "weekly_*" -o -name "trending_*" | head -5

# í—¬ìŠ¤ì²´í¬ íŒŒì¼ í™•ì¸
docker exec mlops-dev ls -la logs/health/

# ìŠ¤ì¼€ì¤„ëŸ¬ ë¡œê·¸ í™•ì¸
docker exec mlops-dev tail -20 logs/scheduler.log 2>/dev/null || echo "ìŠ¤ì¼€ì¤„ëŸ¬ ë¡œê·¸ ì—†ìŒ"
```

---

## ğŸ’¾ 1.4 ë°ì´í„° ì €ì¥ì†Œ í…ŒìŠ¤íŠ¸

### ì €ì¥ì†Œ êµ¬ì¡° í…ŒìŠ¤íŠ¸

```bash
# ë°ì´í„° ì €ì¥ì†Œ êµ¬ì¡° í™•ì¸
docker exec mlops-dev tree data/ -L 3 2>/dev/null || docker exec mlops-dev find data/ -type d

# íŒŒì¼ ëª…ëª… ê·œì¹™ í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from data.naming_convention import DataFileNamingConvention
from datetime import datetime

naming = DataFileNamingConvention()
print('=== íŒŒì¼ ëª…ëª… ê·œì¹™ í…ŒìŠ¤íŠ¸ ===')
print(f'ì¼ì¼ ìˆ˜ì§‘: {naming.daily_collection()}')
print(f'ì£¼ê°„ ìˆ˜ì§‘: {naming.weekly_collection(2025, 23)}')
print(f'ì¥ë¥´ë³„ ìˆ˜ì§‘: {naming.genre_collection(\"ì•¡ì…˜\")}')
print(f'í’ˆì§ˆ ë¦¬í¬íŠ¸: {naming.quality_report(\"daily\")}')
print('âœ… ëª…ëª… ê·œì¹™ í…ŒìŠ¤íŠ¸ í†µê³¼')
"

# íŒŒì¼ í¬ë§· ê´€ë¦¬ì í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from data.file_formats import DataFileManager
import json

manager = DataFileManager()
print('=== íŒŒì¼ í¬ë§· ê´€ë¦¬ì í…ŒìŠ¤íŠ¸ ===')

# í…ŒìŠ¤íŠ¸ ë°ì´í„°
test_data = {'test': 'data', 'count': 123}

# JSON ì €ì¥ í…ŒìŠ¤íŠ¸
manager.save_json(test_data, 'data/test/test_save.json')
print('âœ… JSON ì €ì¥ ì„±ê³µ')

# íŒŒì¼ ì •ë³´ ì¡°íšŒ í…ŒìŠ¤íŠ¸
info = manager.get_file_info('data/test/test_save.json')
if info:
    print(f'âœ… íŒŒì¼ ì •ë³´: {info[\"size_bytes\"]}bytes')
else:
    print('âŒ íŒŒì¼ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨')
"
```

### ë°±ì—… ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸

```bash
# ë°±ì—… ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from src.data_processing.backup_manager import BackupManager
import os

if os.path.exists('src/data_processing/backup_manager.py'):
    manager = BackupManager()
    print('âœ… BackupManager ë¡œë“œ ì„±ê³µ')
else:
    print('â­ï¸ BackupManager ë¯¸êµ¬í˜„')
"

# ìˆ˜ë™ ë°±ì—… í…ŒìŠ¤íŠ¸
docker exec mlops-dev bash -c "
echo '=== ìˆ˜ë™ ë°±ì—… í…ŒìŠ¤íŠ¸ ==='
mkdir -p data/backup/test
cp -r data/raw/movies/* data/backup/test/ 2>/dev/null || echo 'ë°±ì—…í•  íŒŒì¼ ì—†ìŒ'
echo 'âœ… ìˆ˜ë™ ë°±ì—… ì™„ë£Œ'
ls -la data/backup/test/
"
```

---

## ğŸ” 1.5 ë°ì´í„° í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸

### í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸

```bash
# DataQualityValidator ê¸°ë³¸ í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from src.data_processing.quality_validator import DataQualityValidator

validator = DataQualityValidator()
print('âœ… DataQualityValidator ì´ˆê¸°í™” ì„±ê³µ')

# í…ŒìŠ¤íŠ¸ ì˜í™” ë°ì´í„°
test_movie = {
    'id': 12345,
    'title': 'í…ŒìŠ¤íŠ¸ ì˜í™”',
    'release_date': '2023-05-15',
    'vote_average': 8.5,
    'popularity': 1500.0,
    'overview': 'ì¢‹ì€ ì˜í™”ì…ë‹ˆë‹¤.',
    'adult': False,
    'vote_count': 1000
}

is_valid, message, details = validator.validate_single_movie(test_movie)
print(f'ê²€ì¦ ê²°ê³¼: {\"âœ… í†µê³¼\" if is_valid else \"âŒ ì‹¤íŒ¨\"}')
print(f'í’ˆì§ˆ ì ìˆ˜: {details[\"overall_score\"]}/100')
print(f'ë©”ì‹œì§€: {message}')
"

# ë°°ì¹˜ í’ˆì§ˆ ë¶„ì„ í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from src.data_processing.quality_validator import DataQualityValidator
import json
from pathlib import Path

validator = DataQualityValidator()

# ìµœê·¼ ìˆ˜ì§‘ëœ ì˜í™” ë°ì´í„°ë¡œ ë°°ì¹˜ ë¶„ì„
data_dir = Path('data/raw/movies')
json_files = list(data_dir.rglob('*.json'))

if json_files:
    latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
    
    with open(latest_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    movies = data.get('movies', [])
    if movies:
        print(f'=== ë°°ì¹˜ í’ˆì§ˆ ë¶„ì„ ({len(movies)}ê°œ ì˜í™”) ===')
        batch_results = validator.validate_batch_data(movies)
        
        print(f'ì´ ì˜í™”: {batch_results[\"total_movies\"]}ê°œ')
        print(f'ìœ íš¨í•œ ì˜í™”: {batch_results[\"valid_movies\"]}ê°œ')
        print(f'ë¬´íš¨í•œ ì˜í™”: {batch_results[\"invalid_movies\"]}ê°œ')
        
        quality_dist = batch_results['quality_distribution']
        print(f'í’ˆì§ˆ ë¶„í¬:')
        print(f'  ìš°ìˆ˜: {quality_dist[\"excellent\"]}ê°œ')
        print(f'  ì–‘í˜¸: {quality_dist[\"good\"]}ê°œ')
        print(f'  ë³´í†µ: {quality_dist[\"fair\"]}ê°œ')
        print(f'  ë¶ˆëŸ‰: {quality_dist[\"poor\"]}ê°œ')
        
        if batch_results['recommendations']:
            print('ê¶Œì¥ì‚¬í•­:')
            for rec in batch_results['recommendations']:
                print(f'  - {rec}')
    else:
        print('ë¶„ì„í•  ì˜í™” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')
else:
    print('ìˆ˜ì§‘ëœ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.')
"
```

### ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸

```bash
# AnomalyDetector í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from src.data_processing.quality_validator import AnomalyDetector
import json
from pathlib import Path

detector = AnomalyDetector()
print('âœ… AnomalyDetector ì´ˆê¸°í™” ì„±ê³µ')

# ìµœê·¼ ë°ì´í„°ë¡œ ì´ìƒ íƒì§€ í…ŒìŠ¤íŠ¸
data_dir = Path('data/raw/movies')
json_files = list(data_dir.rglob('*.json'))

if json_files:
    latest_file = max(json_files, key=lambda x: x.stat().st_mtime)
    
    with open(latest_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    movies = data.get('movies', [])
    if movies:
        print(f'=== ì´ìƒ íƒì§€ ë¶„ì„ ({len(movies)}ê°œ ì˜í™”) ===')
        
        # í‰ì  ì´ìƒ íƒì§€
        rating_anomalies = detector.detect_rating_anomalies(movies)
        print(f'í‰ì  ì´ìƒ: {len(rating_anomalies.get(\"anomalies\", []))}ê±´')
        
        # ì¸ê¸°ë„ ì´ìƒ íƒì§€
        popularity_anomalies = detector.detect_popularity_anomalies(movies)
        print(f'ì¸ê¸°ë„ ì´ìƒ: {len(popularity_anomalies.get(\"anomalies\", []))}ê±´')
        
        # ê¸°ì¤€ì„  ì—…ë°ì´íŠ¸
        collection_stats = data.get('collection_info', {})
        detector.update_baseline(movies, collection_stats)
        print('âœ… ê¸°ì¤€ì„  ì—…ë°ì´íŠ¸ ì™„ë£Œ')
    else:
        print('ë¶„ì„í•  ì˜í™” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')
else:
    print('ìˆ˜ì§‘ëœ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.')
"
```

### ë°ì´í„° ì •ì œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸

```bash
# DataCleaner í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
from src.data_processing.quality_validator import DataCleaner

cleaner = DataCleaner()
print('âœ… DataCleaner ì´ˆê¸°í™” ì„±ê³µ')

# í…ŒìŠ¤íŠ¸ ë”í‹° ë°ì´í„°
dirty_movie = {
    'id': 12345,
    'title': '  í…ŒìŠ¤íŠ¸  ì˜í™”   ',  # ê³µë°± í¬í•¨
    'release_date': '2023/05/15',    # ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹
    'vote_average': 8.5,
    'popularity': 1500.0,
    'overview': '<p>HTML íƒœê·¸ê°€ í¬í•¨ëœ ê°œìš”</p>',
    'genre_ids': ['28', '35', 'invalid'],  # ë¬¸ìì—´ í¬í•¨
    'adult': False,
    'vote_count': 1000
}

cleaned_movie, actions = cleaner.clean_movie_data(dirty_movie)
print(f'ì •ì œ ì‘ì—…: {actions}')
print(f'ì •ì œ ì „ ì œëª©: \"{dirty_movie[\"title\"]}\"')
print(f'ì •ì œ í›„ ì œëª©: \"{cleaned_movie[\"title\"]}\"')
print(f'ì •ì œ ì „ ë‚ ì§œ: {dirty_movie[\"release_date\"]}')
print(f'ì •ì œ í›„ ë‚ ì§œ: {cleaned_movie[\"release_date\"]}')
print(f'ì •ì œ ì „ ì¥ë¥´: {dirty_movie[\"genre_ids\"]}')
print(f'ì •ì œ í›„ ì¥ë¥´: {cleaned_movie[\"genre_ids\"]}')
"
```

---

## ğŸ“Š 1.6 ì™„ë£Œ ê¸°ì¤€ í™•ì¸

### ì¢…í•© ìƒíƒœ ì ê²€

```bash
# ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€
docker exec mlops-dev python -c "
print('=== 1ë‹¨ê³„ ì¢…í•© ìƒíƒœ ì ê²€ ===')

# 1.1 API ì—°ê²° ìƒíƒœ
try:
    from src.data_processing.tmdb_api_connector import test_tmdb_connection
    api_status = 'âœ…' if test_tmdb_connection() else 'âŒ'
    print(f'1.1 API ì—°ê²°: {api_status}')
except Exception as e:
    print(f'1.1 API ì—°ê²°: âŒ ({e})')

# 1.2 í¬ë¡¤ëŸ¬ ìƒíƒœ
try:
    from src.data_processing.tmdb_crawler import TMDBCrawler
    crawler = TMDBCrawler()
    crawler.close()
    print('1.2 í¬ë¡¤ëŸ¬: âœ…')
except Exception as e:
    print(f'1.2 í¬ë¡¤ëŸ¬: âŒ ({e})')

# 1.3 ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ
try:
    from src.data_processing.scheduler import TMDBDataScheduler
    scheduler = TMDBDataScheduler()
    print('1.3 ìŠ¤ì¼€ì¤„ëŸ¬: âœ…')
except Exception as e:
    print(f'1.3 ìŠ¤ì¼€ì¤„ëŸ¬: âŒ ({e})')

# 1.4 ì €ì¥ì†Œ ìƒíƒœ
import os
data_dirs = ['data/raw', 'data/processed', 'logs']
storage_ok = all(os.path.exists(d) for d in data_dirs)
print(f'1.4 ì €ì¥ì†Œ: {\"âœ…\" if storage_ok else \"âŒ\"}')

# 1.5 í’ˆì§ˆ ê²€ì¦ ìƒíƒœ
try:
    from src.data_processing.quality_validator import DataQualityValidator
    validator = DataQualityValidator()
    print('1.5 í’ˆì§ˆ ê²€ì¦: âœ…')
except Exception as e:
    print(f'1.5 í’ˆì§ˆ ê²€ì¦: âŒ ({e})')
"

# ìˆ˜ì§‘ëœ ë°ì´í„° í†µê³„
docker exec mlops-dev python -c "
from pathlib import Path
import json

print('\\n=== ìˆ˜ì§‘ ë°ì´í„° í†µê³„ ===')

data_dir = Path('data/raw/movies')
if data_dir.exists():
    json_files = list(data_dir.rglob('*.json'))
    total_movies = 0
    
    for file in json_files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            movies = data.get('movies', [])
            total_movies += len(movies)
        except Exception:
            continue
    
    print(f'ì´ ìˆ˜ì§‘ íŒŒì¼: {len(json_files)}ê°œ')
    print(f'ì´ ì˜í™” ë°ì´í„°: {total_movies}ê°œ')
    
    if total_movies >= 1000:
        print('âœ… ì¼ì¼ 1000ê°œ ì´ìƒ ìˆ˜ì§‘ ê¸°ì¤€ ë‹¬ì„±')
    else:
        print(f'âš ï¸ í˜„ì¬ {total_movies}ê°œ ìˆ˜ì§‘ë¨ (ëª©í‘œ: 1000ê°œ ì´ìƒ)')
else:
    print('âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')
"
```

### ì™„ë£Œ ê¸°ì¤€ ì²´í¬ë¦¬ìŠ¤íŠ¸

```bash
# ì™„ë£Œ ê¸°ì¤€ ìë™ ì²´í¬
docker exec mlops-dev python -c "
from pathlib import Path
import json
import os

print('=== 1ë‹¨ê³„ ì™„ë£Œ ê¸°ì¤€ ì²´í¬ë¦¬ìŠ¤íŠ¸ ===')

# ê¸°ëŠ¥ì  ì™„ë£Œ ê¸°ì¤€
criteria = {
    '1.1 API ì—°ê²° ì„±ê³µë¥  95% ì´ìƒ': False,
    '1.2 ì¼ì¼ 1000ê°œ ì´ìƒ ì˜í™” ìˆ˜ì§‘': False,
    '1.3 ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ë™ì‘': False,
    '1.4 ë°ì´í„° ì €ì¥ì†Œ êµ¬ì¡° ì™„ì„±': False,
    '1.5 í’ˆì§ˆ ê²€ì¦ 90% ì´ìƒ í†µê³¼': False,
    'ë¡œê·¸ ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™': False,
    'ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê°€ëŠ¥': False
}

# 1.1 API ì—°ê²° ì²´í¬
try:
    from src.data_processing.tmdb_api_connector import test_tmdb_connection
    if test_tmdb_connection():
        criteria['1.1 API ì—°ê²° ì„±ê³µë¥  95% ì´ìƒ'] = True
except Exception:
    pass

# 1.2 ìˆ˜ì§‘ëŸ‰ ì²´í¬
data_dir = Path('data/raw/movies')
if data_dir.exists():
    json_files = list(data_dir.rglob('*.json'))
    total_movies = 0
    for file in json_files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            total_movies += len(data.get('movies', []))
        except Exception:
            continue
    
    if total_movies >= 1000:
        criteria['1.2 ì¼ì¼ 1000ê°œ ì´ìƒ ì˜í™” ìˆ˜ì§‘'] = True

# 1.3 ìŠ¤ì¼€ì¤„ëŸ¬ ì²´í¬
try:
    from src.data_processing.scheduler import TMDBDataScheduler
    criteria['1.3 ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ ë™ì‘'] = True
except Exception:
    pass

# 1.4 ì €ì¥ì†Œ êµ¬ì¡° ì²´í¬
required_dirs = ['data/raw', 'data/processed', 'logs']
if all(os.path.exists(d) for d in required_dirs):
    criteria['1.4 ë°ì´í„° ì €ì¥ì†Œ êµ¬ì¡° ì™„ì„±'] = True

# 1.5 í’ˆì§ˆ ê²€ì¦ ì²´í¬
try:
    from src.data_processing.quality_validator import DataQualityValidator
    criteria['1.5 í’ˆì§ˆ ê²€ì¦ 90% ì´ìƒ í†µê³¼'] = True
except Exception:
    pass

# ë¡œê·¸ ì‹œìŠ¤í…œ ì²´í¬
if os.path.exists('logs') and any(os.listdir('logs')):
    criteria['ë¡œê·¸ ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™'] = True

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê°€ëŠ¥ì„± ì²´í¬
if os.path.exists('scripts/scheduler_control.sh'):
    criteria['ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê°€ëŠ¥'] = True

# ê²°ê³¼ ì¶œë ¥
passed = sum(criteria.values())
total = len(criteria)

for criterion, status in criteria.items():
    status_icon = 'âœ…' if status else 'âŒ'
    print(f'{status_icon} {criterion}')

print(f'\\nì „ì²´ ì™„ë£Œìœ¨: {passed}/{total} ({passed/total*100:.1f}%)')

if passed >= total * 0.8:  # 80% ì´ìƒ
    print('ğŸ‰ 1ë‹¨ê³„ êµ¬í˜„ì´ ê±°ì˜ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!')
elif passed >= total * 0.6:  # 60% ì´ìƒ
    print('ğŸ‘ 1ë‹¨ê³„ êµ¬í˜„ì´ ì˜ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤.')
else:
    print('âš ï¸ ë” ë§ì€ êµ¬í˜„ì´ í•„ìš”í•©ë‹ˆë‹¤.')
"
```

---

## ğŸ“‹ ë¡œê·¸ ë° ë¬¸ì œ í•´ê²°

### ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜ í™•ì¸

```bash
# ëª¨ë“  ë¡œê·¸ íŒŒì¼ í™•ì¸
docker exec mlops-dev find logs/ -name "*.log" -type f

# ì£¼ìš” ë¡œê·¸ íŒŒì¼ ë‚´ìš© í™•ì¸
echo "=== API ì—°ë™ ë¡œê·¸ ==="
docker exec mlops-dev tail -10 logs/test_tmdb_integration.log 2>/dev/null || echo "ë¡œê·¸ ì—†ìŒ"

echo "=== í¬ë¡¤ëŸ¬ ë¡œê·¸ ==="  
docker exec mlops-dev tail -10 logs/test_crawler.log 2>/dev/null || echo "ë¡œê·¸ ì—†ìŒ"

echo "=== ëŒ€ëŸ‰ ìˆ˜ì§‘ ë¡œê·¸ ==="
docker exec mlops-dev tail -10 logs/data/bulk_collection_test.log 2>/dev/null || echo "ë¡œê·¸ ì—†ìŒ"

echo "=== ìŠ¤ì¼€ì¤„ëŸ¬ ë¡œê·¸ ==="
docker exec mlops-dev tail -10 logs/scheduler.log 2>/dev/null || echo "ë¡œê·¸ ì—†ìŒ"
```

### ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

```bash
# 1. API í‚¤ ë¬¸ì œ ìƒì„¸ ì§„ë‹¨
echo "=== API í‚¤ ë¬¸ì œ ì§„ë‹¨ ==="

# .env íŒŒì¼ì˜ API í‚¤ í™•ì¸
docker exec mlops-dev bash -c "cat .env | grep TMDB_API_KEY"

# Docker ì»¨í…Œì´ë„ˆ í™˜ê²½ë³€ìˆ˜ í™•ì¸
docker exec mlops-dev bash -c "echo \$TMDB_API_KEY"

# Python dotenv ë¡œë”© í…ŒìŠ¤íŠ¸
docker exec mlops-dev python -c "
import os
from dotenv import load_dotenv
print('ë¡œë“œ ì „:', os.getenv('TMDB_API_KEY'))
load_dotenv(override=True)
print('ë¡œë“œ í›„:', os.getenv('TMDB_API_KEY'))
"

# ë¬¸ì œ í•´ê²° ë°©ë²•
if docker exec mlops-dev bash -c "[ '\$TMDB_API_KEY' = 'your_tmdb_api_key_here' ]"; then
    echo 'âŒ Docker ì»¨í…Œì´ë„ˆì— ì˜ëª»ëœ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.'
    echo 'í•´ê²°: docker compose down && docker compose up -d dev'
else
    echo 'âœ… Docker í™˜ê²½ë³€ìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.'
fi

# 2. ë””ë ‰í† ë¦¬ ê¶Œí•œ ë¬¸ì œ
echo "=== ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸ ==="
docker exec mlops-dev bash -c "
dirs=('data' 'logs' 'reports')
for dir in \${dirs[@]}; do
    if [ -w "\$dir" ]; then
        echo "âœ… \$dir ì“°ê¸° ê°€ëŠ¥"
    else
        echo "âŒ \$dir ì“°ê¸° ë¶ˆê°€ - ê¶Œí•œ í™•ì¸ í•„ìš”"
    fi
done
"

# 3. Python ëª¨ë“ˆ ì„í¬íŠ¸ ë¬¸ì œ
echo "=== Python ëª¨ë“ˆ í™•ì¸ ==="
docker exec mlops-dev python -c "
import sys
sys.path.insert(0, 'src')

modules = [
    'data_processing.tmdb_api_connector',
    'data_processing.tmdb_crawler', 
    'data_processing.scheduler',
    'data_processing.quality_validator'
]

for module in modules:
    try:
        __import__(module)
        print(f'âœ… {module}')
    except Exception as e:
        print(f'âŒ {module}: {e}')
"

# 4. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
echo "=== ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸ ==="
docker exec mlops-dev python -c "
import requests
try:
    response = requests.get('https://api.themoviedb.org/3', timeout=10)
    print(f'âœ… TMDB API ì—°ê²° ê°€ëŠ¥ (ìƒíƒœ: {response.status_code})')
except Exception as e:
    print(f'âŒ TMDB API ì—°ê²° ë¶ˆê°€: {e}')
"

# 5. í™˜ê²½ë³€ìˆ˜ ë°°ë¦¬ì–´ ìš°íšŒ í…ŒìŠ¤íŠ¸
echo "=== í™˜ê²½ë³€ìˆ˜ ë°°ë¦¬ì–´ ìš°íšŒ í…ŒìŠ¤íŠ¸ ==="
docker exec mlops-dev bash -c "
# ê¸°ì¡´ í™˜ê²½ë³€ìˆ˜ ì œê±°
unset TMDB_API_KEY

# .env íŒŒì¼ì—ì„œ API í‚¤ ì¶”ì¶œ
API_KEY=\$(grep TMDB_API_KEY .env | cut -d'=' -f2)
export TMDB_API_KEY=\$API_KEY

echo 'í™˜ê²½ë³€ìˆ˜ ì¬ì„¤ì • ì™„ë£Œ:' \$TMDB_API_KEY

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python -c 'from src.data_processing.tmdb_api_connector import test_tmdb_connection; print("âœ… API í…ŒìŠ¤íŠ¸ ì„±ê³µ" if test_tmdb_connection() else "âŒ API í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")'
"
```

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```bash
# Docker ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
echo "=== Docker ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ==="
docker stats mlops-dev --no-stream

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
echo "=== ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ==="
docker exec mlops-dev df -h

# ë°ì´í„° ë””ë ‰í† ë¦¬ í¬ê¸°
echo "=== ë°ì´í„° ë””ë ‰í† ë¦¬ í¬ê¸° ==="
docker exec mlops-dev du -sh data/ logs/ reports/ 2>/dev/null || echo "ë””ë ‰í† ë¦¬ ì—†ìŒ"
```

---

## ğŸ¯ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰

### ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸

```bash
# ì¢…í•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (ìˆœì°¨ ì‹¤í–‰)
docker exec -it mlops-dev bash -c "
echo '============================================================'
echo '1ë‹¨ê³„ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸'
echo '============================================================'

echo ''
echo '1/6 API ì—°ë™ í…ŒìŠ¤íŠ¸...'
python src/data_processing/test_integration.py > /tmp/test1.log 2>&1
if [ \$? -eq 0 ]; then echo 'âœ… 1.1 API ì—°ë™ ì„±ê³µ'; else echo 'âŒ 1.1 API ì—°ë™ ì‹¤íŒ¨'; fi

echo ''
echo '2/6 í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸...'
python src/data_processing/test_crawler.py > /tmp/test2.log 2>&1
if [ \$? -eq 0 ]; then echo 'âœ… 1.2 í¬ë¡¤ëŸ¬ ì„±ê³µ'; else echo 'âŒ 1.2 í¬ë¡¤ëŸ¬ ì‹¤íŒ¨'; fi

echo ''
echo '3/6 ëŒ€ëŸ‰ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸...'
echo '1' | python src/data_processing/bulk_collection_test.py > /tmp/test3.log 2>&1
if [ \$? -eq 0 ]; then echo 'âœ… ëŒ€ëŸ‰ ìˆ˜ì§‘ ì„±ê³µ'; else echo 'âŒ ëŒ€ëŸ‰ ìˆ˜ì§‘ ì‹¤íŒ¨'; fi

echo ''
echo '4/6 ìŠ¤ì¼€ì¤„ëŸ¬ í…ŒìŠ¤íŠ¸...'
timeout 10s python -c \"
from src.data_processing.scheduler import TMDBDataScheduler
scheduler = TMDBDataScheduler()
result = scheduler.daily_collection()
print('ìŠ¤ì¼€ì¤„ëŸ¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ')
\" > /tmp/test4.log 2>&1
if [ \$? -eq 0 ] || [ \$? -eq 124 ]; then echo 'âœ… 1.3 ìŠ¤ì¼€ì¤„ëŸ¬ ì„±ê³µ'; else echo 'âŒ 1.3 ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤íŒ¨'; fi

echo ''
echo '5/6 í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸...'
python -c \"
from src.data_processing.quality_validator import DataQualityValidator
validator = DataQualityValidator()
test_movie = {'id': 1, 'title': 'Test', 'release_date': '2023-01-01', 'vote_average': 8.0, 'popularity': 100, 'overview': 'Test movie', 'adult': False, 'vote_count': 100}
is_valid, msg, details = validator.validate_single_movie(test_movie)
print(f'í’ˆì§ˆ ê²€ì¦: {is_valid}')
\" > /tmp/test5.log 2>&1
if [ \$? -eq 0 ]; then echo 'âœ… 1.5 í’ˆì§ˆ ê²€ì¦ ì„±ê³µ'; else echo 'âŒ 1.5 í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨'; fi

echo ''
echo '6/6 ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€...'
if [ -d 'data' ] && [ -d 'logs' ]; then
    echo 'âœ… 1.4 ì €ì¥ì†Œ êµ¬ì¡° ì„±ê³µ'
else
    echo 'âŒ 1.4 ì €ì¥ì†Œ êµ¬ì¡° ì‹¤íŒ¨'
fi

echo ''
echo '============================================================'
echo 'ì¢…í•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!'
echo '============================================================'

# ë¡œê·¸ íŒŒì¼ ìš”ì•½
echo ''
echo '=== í…ŒìŠ¤íŠ¸ ë¡œê·¸ ìš”ì•½ ==='
for i in {1..5}; do
    if [ -f \"/tmp/test\$i.log\" ]; then
        echo \"í…ŒìŠ¤íŠ¸ \$i ë¡œê·¸:\"
        tail -3 \"/tmp/test\$i.log\" 2>/dev/null || echo 'ë¡œê·¸ ì—†ìŒ'
        echo ''
    fi
done
"
```

### ìµœì¢… ë³´ê³ ì„œ ìƒì„±

```bash
# ìµœì¢… í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±
docker exec mlops-dev python -c "
import json
from datetime import datetime
from pathlib import Path

print('=== 1ë‹¨ê³„ ìµœì¢… í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„± ===')

# ë³´ê³ ì„œ ë°ì´í„° ìˆ˜ì§‘
report = {
    'test_date': datetime.now().isoformat(),
    'stage': '1ë‹¨ê³„ ë°ì´í„° ì²˜ë¦¬',
    'components': {},
    'data_summary': {},
    'recommendations': []
}

# ê° ì»´í¬ë„ŒíŠ¸ ìƒíƒœ í™•ì¸
components = {
    '1.1_api_connection': 'TMDB API ì—°ë™',
    '1.2_crawler': 'ë°ì´í„° í¬ë¡¤ëŸ¬',
    '1.3_scheduler': 'ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ë§', 
    '1.4_storage': 'ë°ì´í„° ì €ì¥ì†Œ',
    '1.5_quality': 'í’ˆì§ˆ ê²€ì¦'
}

for comp_id, comp_name in components.items():
    try:
        if comp_id == '1.1_api_connection':
            from src.data_processing.tmdb_api_connector import test_tmdb_connection
            status = 'PASS' if test_tmdb_connection() else 'FAIL'
        elif comp_id == '1.2_crawler':
            from src.data_processing.tmdb_crawler import TMDBCrawler
            crawler = TMDBCrawler()
            crawler.close()
            status = 'PASS'
        elif comp_id == '1.3_scheduler':
            from src.data_processing.scheduler import TMDBDataScheduler
            scheduler = TMDBDataScheduler()
            status = 'PASS'
        elif comp_id == '1.4_storage':
            import os
            status = 'PASS' if all(os.path.exists(d) for d in ['data', 'logs']) else 'FAIL'
        elif comp_id == '1.5_quality':
            from src.data_processing.quality_validator import DataQualityValidator
            validator = DataQualityValidator()
            status = 'PASS'
        else:
            status = 'UNKNOWN'
            
        report['components'][comp_name] = status
        
    except Exception as e:
        report['components'][comp_name] = f'FAIL: {str(e)}'

# ë°ì´í„° ìˆ˜ì§‘ í†µê³„
data_dir = Path('data/raw/movies')
if data_dir.exists():
    json_files = list(data_dir.rglob('*.json'))
    total_movies = 0
    
    for file in json_files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            total_movies += len(data.get('movies', []))
        except Exception:
            continue
    
    report['data_summary'] = {
        'total_files': len(json_files),
        'total_movies': total_movies,
        'meets_1000_requirement': total_movies >= 1000
    }

# ê¶Œì¥ì‚¬í•­ ìƒì„±
passed_components = sum(1 for status in report['components'].values() if status == 'PASS')
total_components = len(report['components'])

if passed_components == total_components:
    report['recommendations'].append('ğŸ‰ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤. 2ë‹¨ê³„ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
elif passed_components >= total_components * 0.8:
    report['recommendations'].append('ğŸ‘ ëŒ€ë¶€ë¶„ì˜ ì»´í¬ë„ŒíŠ¸ê°€ ì‘ë™í•©ë‹ˆë‹¤. ì‹¤íŒ¨í•œ ë¶€ë¶„ì„ ìˆ˜ì •í•œ í›„ ì§„í–‰í•˜ì„¸ìš”.')
else:
    report['recommendations'].append('âš ï¸ ì—¬ëŸ¬ ì»´í¬ë„ŒíŠ¸ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•˜ê³  ë¬¸ì œë¥¼ í•´ê²°í•˜ì„¸ìš”.')

if report['data_summary'].get('total_movies', 0) < 1000:
    report['recommendations'].append('ğŸ“Š ìˆ˜ì§‘ëœ ì˜í™” ë°ì´í„°ê°€ 1000ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤. ëŒ€ëŸ‰ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.')

# ë³´ê³ ì„œ ì €ì¥
report_dir = Path('reports')
report_dir.mkdir(exist_ok=True)

report_file = report_dir / f'stage1_final_report_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'
with open(report_file, 'w', encoding='utf-8') as f:
    json.dump(report, f, ensure_ascii=False, indent=2, default=str)

print(f'ìµœì¢… ë³´ê³ ì„œ ì €ì¥: {report_file}')

# ê²°ê³¼ ìš”ì•½ ì¶œë ¥
print('\\n=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ===')
for comp_name, status in report['components'].items():
    status_icon = 'âœ…' if status == 'PASS' else 'âŒ'
    print(f'{status_icon} {comp_name}: {status}')

print(f'\\nì „ì²´ ì„±ê³µë¥ : {passed_components}/{total_components} ({passed_components/total_components*100:.1f}%)')

if report['data_summary']:
    summary = report['data_summary']
    print(f'ìˆ˜ì§‘ ë°ì´í„°: {summary[\"total_movies\"]}ê°œ ì˜í™” ({summary[\"total_files\"]}ê°œ íŒŒì¼)')

if report['recommendations']:
    print('\\n=== ê¶Œì¥ì‚¬í•­ ===')
    for rec in report['recommendations']:
        print(f'â€¢ {rec}')
"
```

---

## ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ ë‹¤ìŒ ë‹¨ê³„

### ì„±ê³µì ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„

```bash
echo "âœ… 1ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!"
echo ""
echo "ë‹¤ìŒ ë‹¨ê³„:"
echo "1. 2ë‹¨ê³„ í”¼ì²˜ ìŠ¤í† ì–´ êµ¬í˜„ ì¤€ë¹„"
echo "2. ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ í™œìš©í•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§"
echo "3. MLOps íŒŒì´í”„ë¼ì¸ í™•ì¥"
echo ""
echo "í˜„ì¬ ìƒíƒœ í™•ì¸:"
docker exec mlops-dev find data/raw/movies -name "*.json" | wc -l | xargs echo "ìˆ˜ì§‘ íŒŒì¼ ìˆ˜:"
docker exec mlops-dev find logs -name "*.log" | wc -l | xargs echo "ë¡œê·¸ íŒŒì¼ ìˆ˜:"
```

### ë¬¸ì œ ë°œìƒ ì‹œ ì²´í¬í¬ì¸íŠ¸

```bash
echo "=== ë¬¸ì œ í•´ê²° ì²´í¬í¬ì¸íŠ¸ ==="
echo "1. TMDB API í‚¤ ì„¤ì • í™•ì¸"
echo "2. Docker ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸"  
echo "3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸"
echo "4. ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸"
echo "5. Python ëª¨ë“ˆ ì„í¬íŠ¸ í™•ì¸"
echo ""
echo "ìƒì„¸ ë¡œê·¸ëŠ” ë‹¤ìŒ ìœ„ì¹˜ì—ì„œ í™•ì¸:"
echo "- logs/test_tmdb_integration.log"
echo "- logs/test_crawler.log"  
echo "- logs/data/bulk_collection_test.log"
echo "- logs/scheduler.log"
echo "- reports/ ë””ë ‰í† ë¦¬ì˜ JSON ë³´ê³ ì„œë“¤"
```

---

ì´ ê°€ì´ë“œë¥¼ í†µí•´ 1ë‹¨ê³„ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ì²´ê³„ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì—ì„œ ë¬¸ì œê°€ ë°œìƒí•˜ë©´ í•´ë‹¹ ì„¹ì…˜ì˜ ë¬¸ì œ í•´ê²° ë°©ë²•ì„ ì°¸ì¡°í•˜ì—¬ í•´ê²°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
