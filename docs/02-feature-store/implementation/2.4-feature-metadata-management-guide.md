---
title: "2.4 í”¼ì²˜ ë©”íƒ€ë°ì´í„° ê´€ë¦¬ ê°€ì´ë“œ"
description: "í”¼ì²˜ì˜ ìƒì„± ê³¼ì •, ì˜ë¯¸, í’ˆì§ˆì„ ì²´ê³„ì ìœ¼ë¡œ ë¬¸ì„œí™”"
author: "MLOps Team"
created: "2025-06-05"
updated: "2025-06-05"
version: "1.0"
stage: "2.4"
category: "Feature Metadata"
tags: ["ë©”íƒ€ë°ì´í„°", "ìŠ¤í‚¤ë§ˆì„¤ê³„", "ìë™ë¬¸ì„œí™”", "ë²„ì „ê´€ë¦¬", "ë¦¬ë‹ˆì§€ì¶”ì "]
prerequisites: ["2.3 í”¼ì²˜ ê²€ì¦ ì™„ë£Œ", "JSON/YAML", "ë°ì´í„° ëª¨ë¸ë§"]
difficulty: "intermediate"
estimated_time: "4-5ì‹œê°„"
---

# 2.4 í”¼ì²˜ ë©”íƒ€ë°ì´í„° ê´€ë¦¬ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

**ëª©í‘œ**: í”¼ì²˜ì˜ ìƒì„± ê³¼ì •, ì˜ë¯¸, í’ˆì§ˆì„ ì²´ê³„ì ìœ¼ë¡œ ë¬¸ì„œí™”

**í•µì‹¬ ê°€ì¹˜**: í”¼ì²˜ì˜ íˆ¬ëª…ì„±ê³¼ ì¬ì‚¬ìš©ì„±ì„ ê·¹ëŒ€í™”í•˜ì—¬ íŒ€ í˜‘ì—… íš¨ìœ¨ì„± í–¥ìƒ

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ

### ì´ë¡ ì  ëª©í‘œ
- ë©”íƒ€ë°ì´í„°ì˜ ì—­í• ê³¼ ì¤‘ìš”ì„± ì´í•´
- í”¼ì²˜ ë¦¬ë‹ˆì§€ì™€ ë°ì´í„° ê±°ë²„ë„ŒìŠ¤ ê°œë… í•™ìŠµ
- ìŠ¤í‚¤ë§ˆ ì§„í™”ì™€ í˜¸í™˜ì„± ê´€ë¦¬ ë°©ë²• ìŠµë“

### ì‹¤ë¬´ì  ëª©í‘œ
- í”¼ì²˜ ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì„¤ê³„ ë° êµ¬í˜„
- ìë™ ë¬¸ì„œí™” ì‹œìŠ¤í…œ êµ¬ì¶•
- ë²„ì „ ê´€ë¦¬ ë° ë³€ê²½ ì¶”ì  ì‹œìŠ¤í…œ ê°œë°œ

---

## ğŸ”§ 2.4.1 ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì„¤ê³„

### í•µì‹¬ ë©”íƒ€ë°ì´í„° êµ¬ì¡°

```python
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional
from datetime import datetime
from enum import Enum

class FeatureType(Enum):
    """í”¼ì²˜ íƒ€ì… ì—´ê±°í˜•"""
    NUMERICAL = "numerical"
    CATEGORICAL = "categorical"
    BOOLEAN = "boolean"
    TEXT = "text"
    DATETIME = "datetime"
    EMBEDDING = "embedding"

class FeatureStatus(Enum):
    """í”¼ì²˜ ìƒíƒœ ì—´ê±°í˜•"""
    ACTIVE = "active"
    DEPRECATED = "deprecated"
    EXPERIMENTAL = "experimental"
    ARCHIVED = "archived"

@dataclass
class FeatureMetadata:
    """í”¼ì²˜ ë©”íƒ€ë°ì´í„° í•µì‹¬ êµ¬ì¡°"""
    
    # ê¸°ë³¸ ì •ë³´
    name: str
    display_name: str
    description: str
    feature_type: FeatureType
    data_type: str
    
    # ë²„ì „ ì •ë³´
    version: str
    created_at: datetime
    updated_at: datetime
    created_by: str
    
    # ìƒíƒœ ì •ë³´
    status: FeatureStatus
    tags: List[str] = field(default_factory=list)
    
    # ìƒì„± ì •ë³´
    source_tables: List[str] = field(default_factory=list)
    transformation_logic: str = ""
    dependencies: List[str] = field(default_factory=list)
    
    # í’ˆì§ˆ ì •ë³´
    quality_score: Optional[float] = None
    last_validation: Optional[datetime] = None
    validation_rules: Dict[str, Any] = field(default_factory=dict)
    
    # ì‚¬ìš© ì •ë³´
    usage_count: int = 0
    last_used: Optional[datetime] = None
    models_using: List[str] = field(default_factory=list)
    
    # í†µê³„ ì •ë³´
    statistics: Dict[str, Any] = field(default_factory=dict)
    
    # ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´
    business_owner: str = ""
    business_purpose: str = ""
    domain: str = ""
```

### ë©”íƒ€ë°ì´í„° ì €ì¥ì†Œ

```python
import json
from pathlib import Path

class FeatureMetadataStore:
    """í”¼ì²˜ ë©”íƒ€ë°ì´í„° ì €ì¥ì†Œ"""
    
    def __init__(self, storage_path: str = "metadata/features"):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)
        
        # ì¸ë±ìŠ¤ íŒŒì¼ë“¤
        self.index_file = self.storage_path / "feature_index.json"
        self.feature_index = self._load_index(self.index_file)
    
    def save_feature_metadata(self, metadata: FeatureMetadata) -> str:
        """í”¼ì²˜ ë©”íƒ€ë°ì´í„° ì €ì¥"""
        
        # íŒŒì¼ ê²½ë¡œ ìƒì„±
        file_name = f"{metadata.name}_v{metadata.version}.json"
        file_path = self.storage_path / "features" / file_name
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(metadata.to_dict(), f, indent=2, ensure_ascii=False)
        
        # ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        self.feature_index[metadata.name] = {
            'latest_version': metadata.version,
            'file_path': str(file_path),
            'last_updated': metadata.updated_at.isoformat(),
            'status': metadata.status.value
        }
        
        self._save_index(self.index_file, self.feature_index)
        return str(file_path)
    
    def load_feature_metadata(self, feature_name: str, 
                            version: Optional[str] = None) -> Optional[FeatureMetadata]:
        """í”¼ì²˜ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        
        if feature_name not in self.feature_index:
            return None
        
        # ë²„ì „ ê²°ì •
        if version is None:
            version = self.feature_index[feature_name]['latest_version']
        
        # íŒŒì¼ ê²½ë¡œ ìƒì„±
        file_name = f"{feature_name}_v{version}.json"
        file_path = self.storage_path / "features" / file_name
        
        if not file_path.exists():
            return None
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return FeatureMetadata.from_dict(data)
    
    def search_features(self, query: str) -> List[Dict[str, Any]]:
        """í”¼ì²˜ ê²€ìƒ‰"""
        
        results = []
        query_lower = query.lower()
        
        for feature_name in self.feature_index.keys():
            metadata = self.load_feature_metadata(feature_name)
            if not metadata:
                continue
            
            # ê²€ìƒ‰ ëŒ€ìƒ í…ìŠ¤íŠ¸
            searchable_text = (
                f"{metadata.name} {metadata.display_name} "
                f"{metadata.description} {metadata.business_purpose} "
                f"{' '.join(metadata.tags)}"
            ).lower()
            
            if query_lower in searchable_text:
                results.append({
                    'name': metadata.name,
                    'display_name': metadata.display_name,
                    'description': metadata.description,
                    'feature_type': metadata.feature_type.value,
                    'status': metadata.status.value,
                    'domain': metadata.domain,
                    'tags': metadata.tags
                })
        
        return results
    
    def get_feature_lineage(self, feature_name: str) -> Dict[str, Any]:
        """í”¼ì²˜ ë¦¬ë‹ˆì§€ ì¶”ì """
        
        metadata = self.load_feature_metadata(feature_name)
        if not metadata:
            return {}
        
        lineage = {
            'feature': feature_name,
            'dependencies': [],
            'dependents': []
        }
        
        # ì˜ì¡´ì„± í”¼ì²˜ë“¤
        for dep in metadata.dependencies:
            dep_metadata = self.load_feature_metadata(dep)
            if dep_metadata:
                lineage['dependencies'].append({
                    'name': dep,
                    'type': dep_metadata.feature_type.value,
                    'description': dep_metadata.description
                })
        
        # ì´ í”¼ì²˜ì— ì˜ì¡´í•˜ëŠ” í”¼ì²˜ë“¤ ì°¾ê¸°
        for other_feature in self.feature_index.keys():
            if other_feature == feature_name:
                continue
            
            other_metadata = self.load_feature_metadata(other_feature)
            if other_metadata and feature_name in other_metadata.dependencies:
                lineage['dependents'].append({
                    'name': other_feature,
                    'type': other_metadata.feature_type.value,
                    'description': other_metadata.description
                })
        
        return lineage
```

---

## ğŸ”§ 2.4.2 ìë™ ë¬¸ì„œí™” ì‹œìŠ¤í…œ

### ì½”ë“œ ê¸°ë°˜ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

```python
import inspect
from typing import get_type_hints

def feature_metadata(name: str, description: str, feature_type: str, 
                    domain: str = "", tags: List[str] = None,
                    dependencies: List[str] = None):
    """í”¼ì²˜ ë©”íƒ€ë°ì´í„° ë°ì½”ë ˆì´í„°"""
    
    def decorator(func):
        # í•¨ìˆ˜ì— ë©”íƒ€ë°ì´í„° ì†ì„± ì¶”ê°€
        func._feature_metadata = {
            'name': name,
            'description': description,
            'feature_type': feature_type,
            'domain': domain,
            'tags': tags or [],
            'dependencies': dependencies or [],
            'function': func.__name__,
            'module': func.__module__
        }
        
        return func
    
    return decorator

class AutoDocumentationExtractor:
    """ìë™ ë¬¸ì„œí™” ì¶”ì¶œê¸°"""
    
    def extract_from_function(self, func: callable) -> Dict[str, Any]:
        """í•¨ìˆ˜ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        
        # í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ë¶„ì„
        signature = inspect.signature(func)
        type_hints = get_type_hints(func)
        
        # Docstring íŒŒì‹±
        docstring = inspect.getdoc(func)
        docstring_info = self._parse_docstring(docstring) if docstring else {}
        
        metadata = {
            'function_name': func.__name__,
            'module': func.__module__,
            'signature': str(signature),
            'parameters': {},
            'return_type': type_hints.get('return', 'Any'),
            'docstring_info': docstring_info,
            'file_path': inspect.getfile(func),
            'line_number': inspect.getsourcelines(func)[1]
        }
        
        # íŒŒë¼ë¯¸í„° ì •ë³´
        for param_name, param in signature.parameters.items():
            param_info = {
                'name': param_name,
                'type': type_hints.get(param_name, 'Any'),
                'default': param.default if param.default != param.empty else None
            }
            metadata['parameters'][param_name] = param_info
        
        return metadata
    
    def _parse_docstring(self, docstring: str) -> Dict[str, Any]:
        """Docstring íŒŒì‹±"""
        
        if not docstring:
            return {}
        
        lines = docstring.strip().split('\n')
        
        parsed = {
            'summary': '',
            'description': '',
            'parameters': {},
            'returns': '',
            'examples': []
        }
        
        current_section = 'summary'
        
        for line in lines:
            line = line.strip()
            
            if not line:
                continue
            
            # ì„¹ì…˜ ê°ì§€
            if line.lower().startswith('parameters:'):
                current_section = 'parameters'
                continue
            elif line.lower().startswith('returns:'):
                current_section = 'returns'
                continue
            elif line.lower().startswith('examples:'):
                current_section = 'examples'
                continue
            
            # ë‚´ìš© íŒŒì‹±
            if current_section == 'summary' and not parsed['summary']:
                parsed['summary'] = line
            elif current_section == 'summary':
                parsed['description'] += f" {line}"
            elif current_section == 'parameters':
                if ':' in line:
                    param_name, param_desc = line.split(':', 1)
                    parsed['parameters'][param_name.strip()] = param_desc.strip()
            elif current_section == 'returns':
                parsed['returns'] += f" {line}"
            elif current_section == 'examples':
                parsed['examples'].append(line)
        
        return parsed

# ì‚¬ìš© ì˜ˆì‹œ
@feature_metadata(
    name="user_genre_preference",
    description="ì‚¬ìš©ìë³„ ì¥ë¥´ ì„ í˜¸ë„ ì ìˆ˜ (0-1 ë²”ìœ„)",
    feature_type="numerical",
    domain="recommendation",
    tags=["user", "preference", "genre"],
    dependencies=["user_watch_history", "movie_genres"]
)
def calculate_user_genre_preference(user_interactions: pd.DataFrame, 
                                  movie_metadata: pd.DataFrame) -> pd.Series:
    """
    ì‚¬ìš©ìë³„ ì¥ë¥´ ì„ í˜¸ë„ ê³„ì‚°
    
    Parameters:
        user_interactions: ì‚¬ìš©ì ì‹œì²­ ê¸°ë¡
        movie_metadata: ì˜í™” ë©”íƒ€ë°ì´í„°
    
    Returns:
        ì‚¬ìš©ìë³„ ì¥ë¥´ ì„ í˜¸ë„ ì ìˆ˜
    
    Examples:
        >>> preferences = calculate_user_genre_preference(interactions, movies)
        >>> print(preferences.head())
    """
    # êµ¬í˜„ ë¡œì§...
    pass
```

### ì‹¤í–‰ ì‹œê°„ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘

```python
import time
import psutil
from functools import wraps

class RuntimeMetadataCollector:
    """ì‹¤í–‰ ì‹œê°„ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.execution_history = []
    
    def collect_runtime_metadata(self, func):
        """ì‹¤í–‰ ì‹œê°„ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ë°ì½”ë ˆì´í„°"""
        
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
            
            execution_record = {
                'function_name': func.__name__,
                'start_time': start_time,
                'start_memory_mb': start_memory,
                'arguments': {
                    'args_count': len(args),
                    'kwargs_keys': list(kwargs.keys())
                }
            }
            
            try:
                # í•¨ìˆ˜ ì‹¤í–‰
                result = func(*args, **kwargs)
                
                # ì„±ê³µ ë©”íƒ€ë°ì´í„°
                end_time = time.time()
                end_memory = psutil.Process().memory_info().rss / 1024 / 1024
                
                execution_record.update({
                    'status': 'success',
                    'end_time': end_time,
                    'execution_time_seconds': end_time - start_time,
                    'end_memory_mb': end_memory,
                    'memory_delta_mb': end_memory - start_memory
                })
                
                return result
                
            except Exception as e:
                # ì—ëŸ¬ ë©”íƒ€ë°ì´í„°
                execution_record.update({
                    'status': 'error',
                    'error': {
                        'type': type(e).__name__,
                        'message': str(e)
                    }
                })
                raise
            
            finally:
                # ì‹¤í–‰ ê¸°ë¡ ì €ì¥
                self.execution_history.append(execution_record)
        
        return wrapper
```

---

## ğŸ”§ 2.4.3 ë²„ì „ ê´€ë¦¬ ë° ë³€ê²½ ì¶”ì 

### í”¼ì²˜ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ

```python
class FeatureVersionManager:
    """í”¼ì²˜ ë²„ì „ ê´€ë¦¬ì"""
    
    def __init__(self, metadata_store: FeatureMetadataStore):
        self.metadata_store = metadata_store
        self.version_history = {}
    
    def create_new_version(self, feature_name: str, 
                          changes: Dict[str, Any],
                          change_type: str = "minor") -> str:
        """ìƒˆ ë²„ì „ ìƒì„±"""
        
        # í˜„ì¬ ë²„ì „ ë¡œë“œ
        current_metadata = self.metadata_store.load_feature_metadata(feature_name)
        
        if current_metadata is None:
            # ìƒˆ í”¼ì²˜ì¸ ê²½ìš°
            new_version = "1.0.0"
        else:
            # ê¸°ì¡´ í”¼ì²˜ì˜ ìƒˆ ë²„ì „
            current_version_parts = current_metadata.version.split('.')
            major, minor, patch = map(int, current_version_parts)
            
            if change_type == "major":
                new_version = f"{major + 1}.0.0"
            elif change_type == "minor":
                new_version = f"{major}.{minor + 1}.0"
            else:  # patch
                new_version = f"{major}.{minor}.{patch + 1}"
        
        # ìƒˆ ë©”íƒ€ë°ì´í„° ìƒì„±
        if current_metadata:
            new_metadata = self._create_updated_metadata(current_metadata, changes, new_version)
        else:
            new_metadata = self._create_new_metadata(feature_name, changes, new_version)
        
        # ë³€ê²½ ì‚¬í•­ ê¸°ë¡
        change_record = self._create_change_record(
            feature_name, 
            current_metadata.version if current_metadata else None,
            new_version,
            changes,
            change_type
        )
        
        # ì €ì¥
        self.metadata_store.save_feature_metadata(new_metadata)
        self._save_change_record(feature_name, change_record)
        
        print(f"âœ… {feature_name} ìƒˆ ë²„ì „ ìƒì„±: {new_version}")
        
        return new_version
    
    def compare_versions(self, feature_name: str, 
                        version1: str, version2: str) -> Dict[str, Any]:
        """ë²„ì „ ê°„ ë¹„êµ"""
        
        metadata1 = self.metadata_store.load_feature_metadata(feature_name, version1)
        metadata2 = self.metadata_store.load_feature_metadata(feature_name, version2)
        
        if not metadata1 or not metadata2:
            return {'error': 'ë²„ì „ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ'}
        
        comparison = {
            'feature_name': feature_name,
            'version1': version1,
            'version2': version2,
            'differences': {},
            'compatibility': self._check_compatibility(metadata1, metadata2)
        }
        
        # í•„ë“œë³„ ì°¨ì´ì  ì°¾ê¸°
        dict1 = metadata1.to_dict()
        dict2 = metadata2.to_dict()
        
        for key in set(dict1.keys()) | set(dict2.keys()):
            value1 = dict1.get(key)
            value2 = dict2.get(key)
            
            if value1 != value2:
                comparison['differences'][key] = {
                    'version1_value': value1,
                    'version2_value': value2,
                    'change_type': self._classify_change_type(key, value1, value2)
                }
        
        return comparison
    
    def _check_compatibility(self, metadata1: FeatureMetadata, 
                           metadata2: FeatureMetadata) -> Dict[str, Any]:
        """í˜¸í™˜ì„± ê²€ì‚¬"""
        
        compatibility = {
            'is_compatible': True,
            'breaking_changes': [],
            'warnings': []
        }
        
        # ë°ì´í„° íƒ€ì… ë³€ê²½ ê²€ì‚¬
        if metadata1.data_type != metadata2.data_type:
            compatibility['breaking_changes'].append({
                'type': 'data_type_change',
                'from': metadata1.data_type,
                'to': metadata2.data_type,
                'severity': 'high'
            })
            compatibility['is_compatible'] = False
        
        # í”¼ì²˜ íƒ€ì… ë³€ê²½ ê²€ì‚¬
        if metadata1.feature_type != metadata2.feature_type:
            compatibility['breaking_changes'].append({
                'type': 'feature_type_change',
                'from': metadata1.feature_type.value,
                'to': metadata2.feature_type.value,
                'severity': 'high'
            })
            compatibility['is_compatible'] = False
        
        # ì˜ì¡´ì„± ë³€ê²½ ê²€ì‚¬
        removed_deps = set(metadata1.dependencies) - set(metadata2.dependencies)
        added_deps = set(metadata2.dependencies) - set(metadata1.dependencies)
        
        if removed_deps:
            compatibility['warnings'].append({
                'type': 'dependencies_removed',
                'dependencies': list(removed_deps),
                'severity': 'medium'
            })
        
        if added_deps:
            compatibility['warnings'].append({
                'type': 'dependencies_added',
                'dependencies': list(added_deps),
                'severity': 'low'
            })
        
        return compatibility
    
    def _create_change_record(self, feature_name: str, old_version: str, 
                            new_version: str, changes: Dict[str, Any],
                            change_type: str) -> Dict[str, Any]:
        """ë³€ê²½ ê¸°ë¡ ìƒì„±"""
        
        return {
            'feature_name': feature_name,
            'old_version': old_version,
            'new_version': new_version,
            'change_type': change_type,
            'changes': changes,
            'timestamp': datetime.now().isoformat(),
            'author': changes.get('author', 'system')
        }
    
    def _save_change_record(self, feature_name: str, change_record: Dict[str, Any]):
        """ë³€ê²½ ê¸°ë¡ ì €ì¥"""
        
        changes_file = self.metadata_store.storage_path / "changes" / f"{feature_name}_changes.json"
        changes_file.parent.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ì¡´ ë³€ê²½ ê¸°ë¡ ë¡œë“œ
        if changes_file.exists():
            with open(changes_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
        else:
            history = []
        
        # ìƒˆ ê¸°ë¡ ì¶”ê°€
        history.append(change_record)
        
        # ì €ì¥
        with open(changes_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, indent=2, ensure_ascii=False)
```

### ë¦¬ë‹ˆì§€ ì¶”ì  ì‹œìŠ¤í…œ

```python
class FeatureLineageTracker:
    """í”¼ì²˜ ë¦¬ë‹ˆì§€ ì¶”ì ê¸°"""
    
    def __init__(self, metadata_store: FeatureMetadataStore):
        self.metadata_store = metadata_store
    
    def build_lineage_graph(self) -> Dict[str, Any]:
        """ì „ì²´ í”¼ì²˜ ë¦¬ë‹ˆì§€ ê·¸ë˜í”„ êµ¬ì¶•"""
        
        lineage_graph = {
            'nodes': [],
            'edges': [],
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'total_features': 0,
                'total_dependencies': 0
            }
        }
        
        # ëª¨ë“  í”¼ì²˜ ì •ë³´ ìˆ˜ì§‘
        for feature_name in self.metadata_store.feature_index.keys():
            metadata = self.metadata_store.load_feature_metadata(feature_name)
            if not metadata:
                continue
            
            # ë…¸ë“œ ì¶”ê°€
            node = {
                'id': feature_name,
                'name': metadata.display_name,
                'type': metadata.feature_type.value,
                'status': metadata.status.value,
                'domain': metadata.domain,
                'description': metadata.description,
                'level': 0  # ë‚˜ì¤‘ì— ê³„ì‚°
            }
            lineage_graph['nodes'].append(node)
            
            # ì˜ì¡´ì„± ì—£ì§€ ì¶”ê°€
            for dependency in metadata.dependencies:
                edge = {
                    'source': dependency,
                    'target': feature_name,
                    'type': 'dependency'
                }
                lineage_graph['edges'].append(edge)
        
        # ë ˆë²¨ ê³„ì‚° (ìœ„ìƒ ì •ë ¬)
        self._calculate_levels(lineage_graph)
        
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        lineage_graph['metadata']['total_features'] = len(lineage_graph['nodes'])
        lineage_graph['metadata']['total_dependencies'] = len(lineage_graph['edges'])
        
        return lineage_graph
    
    def get_downstream_features(self, feature_name: str, max_depth: int = 3) -> List[str]:
        """ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ í”¼ì²˜ë“¤ ì¡°íšŒ"""
        
        downstream = []
        visited = set()
        queue = [(feature_name, 0)]
        
        while queue:
            current_feature, depth = queue.pop(0)
            
            if depth >= max_depth or current_feature in visited:
                continue
            
            visited.add(current_feature)
            
            # ì´ í”¼ì²˜ì— ì˜ì¡´í•˜ëŠ” í”¼ì²˜ë“¤ ì°¾ê¸°
            for other_feature in self.metadata_store.feature_index.keys():
                if other_feature == current_feature:
                    continue
                
                other_metadata = self.metadata_store.load_feature_metadata(other_feature)
                if other_metadata and current_feature in other_metadata.dependencies:
                    if other_feature not in visited:
                        downstream.append(other_feature)
                        queue.append((other_feature, depth + 1))
        
        return downstream
    
    def get_upstream_features(self, feature_name: str, max_depth: int = 3) -> List[str]:
        """ì—…ìŠ¤íŠ¸ë¦¼ í”¼ì²˜ë“¤ ì¡°íšŒ"""
        
        upstream = []
        visited = set()
        queue = [(feature_name, 0)]
        
        while queue:
            current_feature, depth = queue.pop(0)
            
            if depth >= max_depth or current_feature in visited:
                continue
            
            visited.add(current_feature)
            
            metadata = self.metadata_store.load_feature_metadata(current_feature)
            if metadata:
                for dependency in metadata.dependencies:
                    if dependency not in visited:
                        upstream.append(dependency)
                        queue.append((dependency, depth + 1))
        
        return upstream
    
    def analyze_impact(self, feature_name: str) -> Dict[str, Any]:
        """í”¼ì²˜ ë³€ê²½ ì˜í–¥ ë¶„ì„"""
        
        downstream_features = self.get_downstream_features(feature_name)
        
        impact_analysis = {
            'feature': feature_name,
            'direct_dependents': 0,
            'total_affected_features': len(downstream_features),
            'affected_domains': set(),
            'affected_models': set(),
            'risk_assessment': 'low'
        }
        
        # ì§ì ‘ ì˜ì¡´í•˜ëŠ” í”¼ì²˜ ìˆ˜ ê³„ì‚°
        for other_feature in self.metadata_store.feature_index.keys():
            other_metadata = self.metadata_store.load_feature_metadata(other_feature)
            if other_metadata and feature_name in other_metadata.dependencies:
                impact_analysis['direct_dependents'] += 1
        
        # ì˜í–¥ë°›ëŠ” ë„ë©”ì¸ ë° ëª¨ë¸ ìˆ˜ì§‘
        for affected_feature in downstream_features:
            affected_metadata = self.metadata_store.load_feature_metadata(affected_feature)
            if affected_metadata:
                if affected_metadata.domain:
                    impact_analysis['affected_domains'].add(affected_metadata.domain)
                impact_analysis['affected_models'].update(affected_metadata.models_using)
        
        # ë¦¬ìŠ¤í¬ í‰ê°€
        if impact_analysis['total_affected_features'] > 10:
            impact_analysis['risk_assessment'] = 'high'
        elif impact_analysis['total_affected_features'] > 3:
            impact_analysis['risk_assessment'] = 'medium'
        
        # setì„ listë¡œ ë³€í™˜
        impact_analysis['affected_domains'] = list(impact_analysis['affected_domains'])
        impact_analysis['affected_models'] = list(impact_analysis['affected_models'])
        
        return impact_analysis
    
    def _calculate_levels(self, lineage_graph: Dict[str, Any]):
        """ë¦¬ë‹ˆì§€ ê·¸ë˜í”„ì˜ ë ˆë²¨ ê³„ì‚°"""
        
        # ë…¸ë“œ ì´ë¦„ìœ¼ë¡œ ì¸ë±ìŠ¤ ìƒì„±
        node_map = {node['id']: i for i, node in enumerate(lineage_graph['nodes'])}
        
        # ì§„ì… ì°¨ìˆ˜ ê³„ì‚°
        in_degree = {node['id']: 0 for node in lineage_graph['nodes']}
        for edge in lineage_graph['edges']:
            if edge['target'] in in_degree:
                in_degree[edge['target']] += 1
        
        # ìœ„ìƒ ì •ë ¬ë¡œ ë ˆë²¨ ê³„ì‚°
        queue = [node_id for node_id, degree in in_degree.items() if degree == 0]
        level = 0
        
        while queue:
            next_queue = []
            
            for node_id in queue:
                if node_id in node_map:
                    lineage_graph['nodes'][node_map[node_id]]['level'] = level
            
            # ë‹¤ìŒ ë ˆë²¨ ë…¸ë“œë“¤ ì°¾ê¸°
            for edge in lineage_graph['edges']:
                if edge['source'] in queue:
                    target = edge['target']
                    in_degree[target] -= 1
                    if in_degree[target] == 0:
                        next_queue.append(target)
            
            queue = list(set(next_queue))
            level += 1
```

---

## âœ… ì™„ë£Œ ê¸°ì¤€

### ê¸°ëŠ¥ì  ì™„ë£Œ ê¸°ì¤€
- [ ] í¬ê´„ì ì¸ ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì„¤ê³„ ì™„ë£Œ
- [ ] ë©”íƒ€ë°ì´í„° ì €ì¥ì†Œ ë° ì¸ë±ì‹± ì‹œìŠ¤í…œ êµ¬í˜„
- [ ] ìë™ ë¬¸ì„œí™” ì¶”ì¶œ ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] ì‹¤í–‰ ì‹œê°„ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ êµ¬í˜„
- [ ] ë²„ì „ ê´€ë¦¬ ë° í˜¸í™˜ì„± ê²€ì‚¬ ì‹œìŠ¤í…œ êµ¬í˜„

### ê¸°ìˆ ì  ì™„ë£Œ ê¸°ì¤€
- [ ] ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì‘ë‹µì‹œê°„ 100ms ì´í•˜
- [ ] í”¼ì²˜ ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„
- [ ] ë¦¬ë‹ˆì§€ ì¶”ì  ì‹œìŠ¤í…œ êµ¬í˜„
- [ ] ë³€ê²½ ì˜í–¥ ë¶„ì„ ê¸°ëŠ¥ êµ¬í˜„
- [ ] ë©”íƒ€ë°ì´í„° ë°±ì—… ë° ë³µêµ¬ ì‹œìŠ¤í…œ

### í’ˆì§ˆ ì™„ë£Œ ê¸°ì¤€
- [ ] ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ ìœ íš¨ì„± ê²€ì¦
- [ ] ìë™ ë¬¸ì„œí™” ì •í™•ë„ 95% ì´ìƒ
- [ ] ë²„ì „ í˜¸í™˜ì„± ê²€ì‚¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
- [ ] ë¦¬ë‹ˆì§€ ì¶”ì  ì •í™•ì„± ê²€ì¦
- [ ] ì‚¬ìš©ì ê°€ì´ë“œ ë° API ë¬¸ì„œ ì‘ì„±

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

ì™„ë£Œ í›„ [2.5 ê°„ë‹¨í•œ í”¼ì²˜ ìŠ¤í† ì–´ êµ¬í˜„](./2.5-simple-feature-store-implementation-guide.md)ë¡œ ì§„í–‰í•˜ì—¬ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë°˜ì˜ ê²½ëŸ‰ í”¼ì²˜ ìŠ¤í† ì–´ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Data Catalog Design Patterns](https://medium.com/@DataEngineering/data-catalog-design-patterns-3c8e2b8a1d7d)
- [Feature Store Concepts](https://www.featurestore.org/)
- [Metadata Management Best Practices](https://towardsdatascience.com/metadata-management-in-ml-systems-9f6bdbb8f4f4)
- [Data Lineage and Governance](https://blog.atlan.com/data-lineage/)
