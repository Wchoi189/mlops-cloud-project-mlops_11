# 2.4 ì„±ëŠ¥ ë° í™•ì¥ì„± í…ŒìŠ¤íŠ¸

## ğŸ“‹ ê°œìš”

í”¼ì²˜ ìŠ¤í† ì–´ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥, í™•ì¥ì„±, ì•ˆì •ì„±ì„ ê²€ì¦í•˜ëŠ” í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œì…ë‹ˆë‹¤.

---

## ğŸƒâ€â™‚ï¸ 1. ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

### 1.1 í”¼ì²˜ ìƒì„± ì²˜ë¦¬ëŸ‰ í…ŒìŠ¤íŠ¸

```bash
# ëŒ€ìš©ëŸ‰ í”¼ì²˜ ìƒì„± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')
import time
import psutil
import gc

from features.engineering.tmdb_processor import AdvancedTMDBPreProcessor

print('ğŸ“Š ëŒ€ìš©ëŸ‰ í”¼ì²˜ ìƒì„± ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...')

# ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ í•¨ìˆ˜
def get_memory_usage():
    process = psutil.Process()
    return process.memory_info().rss / 1024 / 1024  # MB

def get_cpu_usage():
    return psutil.cpu_percent(interval=1)

print(f'ğŸ’» ì´ˆê¸° ì‹œìŠ¤í…œ ìƒíƒœ:')
print(f'  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {get_memory_usage():.1f} MB')

# í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë“¤
test_scenarios = [
    {'name': 'ì†Œê·œëª¨', 'count': 100, 'description': 'ê¸°ë³¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸'},
    {'name': 'ì¤‘ê·œëª¨', 'count': 500, 'description': 'ì¤‘ê°„ ê·œëª¨ ì²˜ë¦¬'},
    {'name': 'ëŒ€ê·œëª¨', 'count': 1000, 'description': 'ëŒ€ìš©ëŸ‰ ì²˜ë¦¬'}
]

results = []

for scenario in test_scenarios:
    print(f'\\nğŸ¯ {scenario[\"name\"]} í…ŒìŠ¤íŠ¸ ({scenario[\"count\"]:,}ê°œ ì˜í™”)...')
    
    # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
    gc.collect()
    initial_memory = get_memory_usage()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    print('  ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì¤‘...')
    test_movies = []
    for i in range(scenario['count']):
        test_movies.append({
            'movie_id': i + 1,
            'title': f'{scenario[\"name\"]} Test Movie {i+1}',
            'release_date': f'202{(i % 4) + 1}-{(i % 12) + 1:02d}-{(i % 28) + 1:02d}',
            'vote_average': 4.0 + (i % 60) * 0.1,
            'vote_count': 100 + i * 10,
            'popularity': 10.0 + (i % 90),
            'genre_ids': [(28 + (i % 5))],  # ë‹¤ì–‘í•œ ì¥ë¥´
            'adult': i % 10 == 0,
            'original_language': ['en', 'ko', 'ja', 'fr', 'es'][i % 5],
            'overview': f'Test movie description for performance testing. Movie {i+1}.'
        })
    
    # í”¼ì²˜ ìƒì„± ì„±ëŠ¥ ì¸¡ì •
    print('  âš™ï¸ í”¼ì²˜ ìƒì„± ì¤‘...')
    feature_start = time.time()
    
    processor = AdvancedTMDBPreProcessor(test_movies)
    features = processor.extract_all_features()
    
    feature_time = time.time() - feature_start
    final_memory = get_memory_usage()
    
    # ê²°ê³¼ ê³„ì‚°
    throughput = scenario['count'] / feature_time if feature_time > 0 else 0
    memory_increase = final_memory - initial_memory
    
    result = {
        'scenario': scenario['name'],
        'count': scenario['count'],
        'feature_time': feature_time,
        'throughput': throughput,
        'memory_increase': memory_increase
    }
    
    results.append(result)
    
    print(f'  ğŸ“ˆ ì„±ëŠ¥ ê²°ê³¼:')
    print(f'    í”¼ì²˜ ìƒì„±: {feature_time:.2f}ì´ˆ')
    print(f'    ì²˜ë¦¬ëŸ‰: {throughput:.1f} movies/second')
    print(f'    ë©”ëª¨ë¦¬ ì¦ê°€: {memory_increase:.1f} MB')
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    del test_movies, features, processor
    gc.collect()

# ì„±ëŠ¥ ìš”ì•½
print('\\nğŸ“Š ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:')
print('=' * 60)
print(f'{\"ì‹œë‚˜ë¦¬ì˜¤\":<10} {\"ì˜í™”ìˆ˜\":<8} {\"ì²˜ë¦¬ì‹œê°„\":<10} {\"ì²˜ë¦¬ëŸ‰\":<15}')
print('-' * 60)

for result in results:
    print(f'{result[\"scenario\"]:<10} {result[\"count\"]:<8,} {result[\"feature_time\"]:<10.1f} {result[\"throughput\"]:<15.1f}')

# ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦
print('\\nğŸ¯ ì„±ëŠ¥ ê¸°ì¤€ ê²€ì¦:')
for result in results:
    if result['throughput'] >= 10:
        status = 'âœ…'
    elif result['throughput'] >= 5:
        status = 'âš ï¸'
    else:
        status = 'âŒ'
    
    print(f'{status} {result[\"scenario\"]}: {result[\"throughput\"]:.1f} movies/sec (ê¸°ì¤€: â‰¥10)')

print('\\nâœ… ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!')
"
```

### 1.2 í”¼ì²˜ ìŠ¤í† ì–´ ì €ì¥ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

```bash
# í”¼ì²˜ ìŠ¤í† ì–´ ì €ì¥ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')
import time
import pandas as pd
import numpy as np

from features.store.feature_store import SimpleFeatureStore, FeatureStoreConfig

print('ğŸ’¾ í”¼ì²˜ ìŠ¤í† ì–´ ì €ì¥ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸...')

# ë‹¤ì–‘í•œ í¬ê¸°ì˜ ë°ì´í„°ì…‹ ìƒì„±
test_datasets = [
    {'name': 'Small', 'rows': 1000, 'cols': 10},
    {'name': 'Medium', 'rows': 5000, 'cols': 20},
    {'name': 'Large', 'rows': 10000, 'cols': 30}
]

config = FeatureStoreConfig(
    base_path='/app/data/performance_test_store',
    cache_enabled=True,
    compression='snappy'
)
store = SimpleFeatureStore(config)

results = []

for dataset in test_datasets:
    print(f'\\nğŸ“Š {dataset[\"name\"]} ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸...')
    print(f'  í¬ê¸°: {dataset[\"rows\"]:,} í–‰ x {dataset[\"cols\"]} ì»¬ëŸ¼')
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_data = pd.DataFrame({
        f'feature_{i}': np.random.random(dataset['rows']) 
        for i in range(dataset['cols'])
    })
    test_data['id'] = range(dataset['rows'])
    
    # ì €ì¥ ì„±ëŠ¥ ì¸¡ì •
    print('  ğŸ’¾ ì €ì¥ ì„±ëŠ¥ ì¸¡ì •...')
    save_start = time.time()
    
    feature_dict = {f'perf_test_{dataset[\"name\"].lower()}': test_data}
    saved_paths = store.save_features(f'perf_test_group_{dataset[\"name\"].lower()}', feature_dict)
    
    save_time = time.time() - save_start
    
    # ì¡°íšŒ ì„±ëŠ¥ ì¸¡ì •
    print('  ğŸ“‹ ì¡°íšŒ ì„±ëŠ¥ ì¸¡ì •...')
    load_start = time.time()
    
    loaded_data = store.get_features([f'perf_test_{dataset[\"name\"].lower()}'], f'perf_test_group_{dataset[\"name\"].lower()}')
    
    load_time = time.time() - load_start
    
    # ê²°ê³¼ ê³„ì‚°
    data_size_mb = test_data.memory_usage(deep=True).sum() / 1024 / 1024
    save_throughput = data_size_mb / save_time
    load_throughput = data_size_mb / load_time
    
    result = {
        'name': dataset['name'],
        'size_mb': data_size_mb,
        'save_time': save_time,
        'load_time': load_time,
        'save_throughput': save_throughput,
        'load_throughput': load_throughput
    }
    
    results.append(result)
    
    print(f'  ğŸ“ˆ ê²°ê³¼:')
    print(f'    ë°ì´í„° í¬ê¸°: {data_size_mb:.2f} MB')
    print(f'    ì €ì¥ ì‹œê°„: {save_time:.2f}ì´ˆ ({save_throughput:.2f} MB/s)')
    print(f'    ì¡°íšŒ ì‹œê°„: {load_time:.2f}ì´ˆ ({load_throughput:.2f} MB/s)')

# ì„±ëŠ¥ ìš”ì•½
print('\\nğŸ“Š í”¼ì²˜ ìŠ¤í† ì–´ ì„±ëŠ¥ ìš”ì•½:')
print('=' * 70)
print(f'{\"ë°ì´í„°ì…‹\":<8} {\"í¬ê¸°(MB)\":<10} {\"ì €ì¥ì‹œê°„\":<10} {\"ì¡°íšŒì‹œê°„\":<10} {\"ì €ì¥ì†ë„\":<12}')
print('-' * 70)

for result in results:
    print(f'{result[\"name\"]:<8} {result[\"size_mb\"]:<10.2f} {result[\"save_time\"]:<10.2f} {result[\"load_time\"]:<10.2f} {result[\"save_throughput\"]:<12.2f}')

print('\\nâœ… í”¼ì²˜ ìŠ¤í† ì–´ ì €ì¥ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!')
"
```

---

## ğŸš€ 2. ë™ì‹œì„± ë° ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸

### 2.1 ë©€í‹°ìŠ¤ë ˆë“œ ë™ì‹œ ì ‘ê·¼ í…ŒìŠ¤íŠ¸

```bash
# ë©€í‹°ìŠ¤ë ˆë“œ ë™ì‹œ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')
import threading
import time
import queue
from concurrent.futures import ThreadPoolExecutor, as_completed

from features.store.feature_store import SimpleFeatureStore, FeatureStoreConfig
import pandas as pd
import numpy as np

print('ğŸš€ ë©€í‹°ìŠ¤ë ˆë“œ ë™ì‹œ ì ‘ê·¼ í…ŒìŠ¤íŠ¸...')

# ê²°ê³¼ ìˆ˜ì§‘ìš© í
results_queue = queue.Queue()

def concurrent_worker(worker_id, iterations=5):
    '''ë™ì‹œ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì›Œì»¤ í•¨ìˆ˜'''
    worker_results = {
        'worker_id': worker_id,
        'success_count': 0,
        'error_count': 0,
        'errors': []
    }
    
    try:
        # ê° ì›Œì»¤ë³„ ë…ë¦½ì ì¸ í”¼ì²˜ ìŠ¤í† ì–´
        config = FeatureStoreConfig(base_path=f'/app/data/concurrent_test_store_{worker_id}')
        store = SimpleFeatureStore(config)
        
        for i in range(iterations):
            try:
                # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
                test_data = pd.DataFrame({
                    'id': range(50),
                    'worker_id': [worker_id] * 50,
                    'iteration': [i] * 50,
                    'value': np.random.random(50)
                })
                
                # ì €ì¥ ë° ì¡°íšŒ
                feature_dict = {f'worker_{worker_id}_data': test_data}
                store.save_features(f'concurrent_group_{worker_id}', feature_dict)
                
                loaded = store.get_features([f'worker_{worker_id}_data'], f'concurrent_group_{worker_id}')
                
                if loaded:
                    worker_results['success_count'] += 1
                else:
                    worker_results['error_count'] += 1
                    
                # ì•½ê°„ì˜ ëœë¤ ì§€ì—°
                time.sleep(np.random.uniform(0.01, 0.05))
                
            except Exception as e:
                worker_results['error_count'] += 1
                worker_results['errors'].append(str(e))
    
    except Exception as e:
        worker_results['errors'].append(f'Worker setup error: {e}')
    
    results_queue.put(worker_results)
    return worker_results

# ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰
print('ğŸ¯ ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ì‹œì‘...')
print('ì„¤ì •: 8ê°œ ì›Œì»¤, ê°ê° 5íšŒ ë°˜ë³µ = ì´ 40íšŒ ì‘ì—…')

test_start_time = time.time()

# ThreadPoolExecutorë¡œ ë™ì‹œ ì‹¤í–‰
with ThreadPoolExecutor(max_workers=8) as executor:
    futures = [executor.submit(concurrent_worker, i, 5) for i in range(8)]
    
    completed_workers = 0
    for future in as_completed(futures):
        try:
            result = future.result()
            completed_workers += 1
            print(f'  ì›Œì»¤ {result[\"worker_id\"]} ì™„ë£Œ: {result[\"success_count\"]}/5 ì„±ê³µ')
        except Exception as e:
            print(f'  ì›Œì»¤ ì‹¤í–‰ ì˜¤ë¥˜: {e}')
            completed_workers += 1

test_total_time = time.time() - test_start_time

# ê²°ê³¼ ì§‘ê³„
print('\\nğŸ“Š ë™ì‹œì„± í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„...')

all_results = []
while not results_queue.empty():
    all_results.append(results_queue.get())

total_operations = sum(r['success_count'] + r['error_count'] for r in all_results)
total_successes = sum(r['success_count'] for r in all_results)
total_errors = sum(r['error_count'] for r in all_results)

success_rate = (total_successes / total_operations * 100) if total_operations > 0 else 0

print(f'ğŸ“ˆ ì „ì²´ ê²°ê³¼:')
print(f'  ì´ ì‘ì—…: {total_operations}ê°œ')
print(f'  ì„±ê³µ: {total_successes}ê°œ')
print(f'  ì‹¤íŒ¨: {total_errors}ê°œ')
print(f'  ì„±ê³µë¥ : {success_rate:.1f}%')
print(f'  ì´ ì†Œìš”ì‹œê°„: {test_total_time:.2f}ì´ˆ')

# ì•ˆì •ì„± ê²€ì¦
if success_rate >= 95:
    print('âœ… ì„±ê³µë¥ : ìš°ìˆ˜ (â‰¥95%)')
elif success_rate >= 90:
    print('âš ï¸ ì„±ê³µë¥ : ì–‘í˜¸ (â‰¥90%)')
else:
    print('âŒ ì„±ê³µë¥ : ê°œì„  í•„ìš” (<90%)')

print('\\nâœ… ë©€í‹°ìŠ¤ë ˆë“œ ë™ì‹œ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!')
"
```

### 2.2 ì—°ì† ì•ˆì •ì„± í…ŒìŠ¤íŠ¸

```bash
# ì—°ì† ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ (3ë¶„ê°„)
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')
import time
import psutil
import gc
from datetime import datetime

from features.store.feature_store import SimpleFeatureStore, FeatureStoreConfig
import pandas as pd
import numpy as np

print('ğŸ’ª ì—°ì† ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ (3ë¶„ê°„ ì—°ì† ë™ì‘)...')

# í…ŒìŠ¤íŠ¸ ì„¤ì •
test_duration = 180  # 3ë¶„
check_interval = 30  # 30ì´ˆë§ˆë‹¤ ì²´í¬
start_time = time.time()
end_time = start_time + test_duration

# í†µê³„ ìˆ˜ì§‘
stats = {
    'operations': 0,
    'errors': 0,
    'memory_samples': [],
    'start_time': datetime.now()
}

config = FeatureStoreConfig(base_path='/app/data/stability_test_store')
store = SimpleFeatureStore(config)

print(f'ì‹œì‘ ì‹œê°„: {stats[\"start_time\"]}')

cycle = 0
last_check = start_time

while time.time() < end_time:
    cycle += 1
    
    try:
        # ëœë¤ í¬ê¸°ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        data_size = np.random.randint(50, 150)
        test_data = pd.DataFrame({
            'cycle': [cycle] * data_size,
            'timestamp': [time.time()] * data_size,
            'feature_1': np.random.random(data_size),
            'feature_2': np.random.normal(0, 1, data_size)
        })
        
        # í”¼ì²˜ ìŠ¤í† ì–´ ì‘ì—…
        feature_dict = {f'stability_test_data_{cycle % 5}': test_data}
        store.save_features('stability_test_group', feature_dict)
        
        # ì¡°íšŒ í…ŒìŠ¤íŠ¸
        loaded = store.get_features([f'stability_test_data_{cycle % 5}'], 'stability_test_group')
        
        if loaded:
            stats['operations'] += 1
        else:
            stats['errors'] += 1
        
    except Exception as e:
        stats['errors'] += 1
        if cycle % 50 == 0:
            print(f'  âŒ ì‚¬ì´í´ {cycle} ì˜¤ë¥˜: {e}')
    
    # 30ì´ˆë§ˆë‹¤ ìƒíƒœ ë¦¬í¬íŠ¸
    current_time = time.time()
    if current_time - last_check >= check_interval:
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìˆ˜ì§‘
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        stats['memory_samples'].append(memory_mb)
        
        # ì§„í–‰ ìƒí™© ì¶œë ¥
        elapsed = current_time - start_time
        remaining = end_time - current_time
        progress = (elapsed / test_duration) * 100
        
        print(f'\\nâ±ï¸ ì§„í–‰ë¥ : {progress:.1f}% ({elapsed/60:.1f}ë¶„ ê²½ê³¼, {remaining/60:.1f}ë¶„ ë‚¨ìŒ)')
        print(f'  ì‘ì—…: {stats[\"operations\"]}ê°œ ì„±ê³µ, {stats[\"errors\"]}ê°œ ì‹¤íŒ¨')
        print(f'  ë©”ëª¨ë¦¬: {memory_mb:.1f} MB')
        
        last_check = current_time
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        if cycle % 50 == 0:
            gc.collect()
    
    # ì ì ˆí•œ ëŒ€ê¸° ì‹œê°„
    time.sleep(0.02)

# ìµœì¢… ê²°ê³¼ ë¶„ì„
final_time = time.time()
total_duration = final_time - start_time

print('\\n' + '='*50)
print('ğŸ“Š ì—°ì† ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ìµœì¢… ê²°ê³¼')
print('='*50)

print(f'í…ŒìŠ¤íŠ¸ ê¸°ê°„: {total_duration/60:.1f}ë¶„')
print(f'ì´ ì‘ì—…: {stats[\"operations\"]}ê°œ')
print(f'ì´ ì˜¤ë¥˜: {stats[\"errors\"]}ê°œ')

if stats['operations'] + stats['errors'] > 0:
    success_rate = (stats[\"operations\"]/(stats[\"operations\"]+stats[\"errors\"])*100)
    print(f'ì„±ê³µë¥ : {success_rate:.2f}%')

if stats['memory_samples']:
    avg_memory = sum(stats['memory_samples']) / len(stats['memory_samples'])
    max_memory = max(stats['memory_samples'])
    min_memory = min(stats['memory_samples'])
    print(f'ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ - í‰ê· : {avg_memory:.1f}MB, ìµœëŒ€: {max_memory:.1f}MB')
    
    memory_growth = max_memory - min_memory
    if memory_growth < 50:
        print('âœ… ë©”ëª¨ë¦¬ ì•ˆì •ì„±: ìš°ìˆ˜ (ì¦ê°€ëŸ‰ <50MB)')
    elif memory_growth < 150:
        print('âš ï¸ ë©”ëª¨ë¦¬ ì•ˆì •ì„±: ì–‘í˜¸ (ì¦ê°€ëŸ‰ <150MB)')
    else:
        print('âŒ ë©”ëª¨ë¦¬ ì•ˆì •ì„±: ê°œì„  í•„ìš”')

print('\\nâœ… ì—°ì† ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ!')
"
```

---

## ğŸ“ˆ 3. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸

### 3.1 ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” í…ŒìŠ¤íŠ¸

```bash
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')
import psutil
import gc
import time

from features.engineering.tmdb_processor import AdvancedTMDBPreProcessor

print('ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” í…ŒìŠ¤íŠ¸...')

def get_memory_usage():
    process = psutil.Process()
    return process.memory_info().rss / 1024 / 1024  # MB

# ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ
initial_memory = get_memory_usage()
print(f'ğŸ“Š ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {initial_memory:.1f} MB')

# ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸
print('\\nğŸ§ª ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í…ŒìŠ¤íŠ¸...')

# ë°˜ë³µ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸
memory_readings = []

for iteration in range(10):
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_movies = [
        {
            'movie_id': i,
            'title': f'Memory Test Movie {i}',
            'release_date': '2023-01-01',
            'vote_average': 7.0 + (i % 3),
            'vote_count': 1000 + i * 100,
            'popularity': 50.0 + i * 5,
            'genre_ids': [28],
            'adult': False,
            'original_language': 'en',
            'overview': f'Memory efficiency test movie {i}'
        }
        for i in range(100)  # 100ê°œì”© ì²˜ë¦¬
    ]
    
    # í”¼ì²˜ ìƒì„±
    processor = AdvancedTMDBPreProcessor(test_movies)
    features = processor.extract_all_features()
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
    current_memory = get_memory_usage()
    memory_readings.append(current_memory)
    
    print(f'  ë°˜ë³µ {iteration + 1}: {current_memory:.1f} MB')
    
    # ëª…ì‹œì  ë©”ëª¨ë¦¬ ì •ë¦¬
    del test_movies, processor, features
    gc.collect()
    
    time.sleep(0.1)  # ì ì‹œ ëŒ€ê¸°

# ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë¶„ì„
if len(memory_readings) >= 2:
    memory_growth = memory_readings[-1] - memory_readings[0]
    avg_per_iteration = memory_growth / len(memory_readings)
    
    print(f'\\nğŸ“ˆ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„:')
    print(f'  ì´ˆê¸°: {memory_readings[0]:.1f} MB')
    print(f'  ìµœì¢…: {memory_readings[-1]:.1f} MB')
    print(f'  ì´ ì¦ê°€: {memory_growth:.1f} MB')
    print(f'  ë°˜ë³µë‹¹ í‰ê·  ì¦ê°€: {avg_per_iteration:.2f} MB')
    
    if memory_growth < 20:
        print('âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: ìš°ìˆ˜ (ì¦ê°€ëŸ‰ <20MB)')
    elif memory_growth < 50:
        print('âš ï¸ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: ì–‘í˜¸ (ì¦ê°€ëŸ‰ <50MB)')
    else:
        print('âŒ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: ê°œì„  í•„ìš” (ì¦ê°€ëŸ‰ â‰¥50MB)')

print('\\nâœ… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” í…ŒìŠ¤íŠ¸ ì™„ë£Œ!')
"
```

---

## â±ï¸ 4. ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

### 4.1 ìºì‹œ íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸

```bash
# ìºì‹œ ì„±ëŠ¥ ë° íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')
import time
import pandas as pd

from features.store.feature_store import SimpleFeatureStore, FeatureStoreConfig

print('ğŸ—„ï¸ ìºì‹œ ì„±ëŠ¥ ë° íš¨ìœ¨ì„± í…ŒìŠ¤íŠ¸...')

# ìºì‹œ í™œì„±í™”ëœ ì„¤ì •
config = FeatureStoreConfig(
    base_path='/app/data/cache_test_store',
    cache_enabled=True,
    cache_max_size=20,
    cache_ttl_seconds=120
)
store = SimpleFeatureStore(config)

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
test_features = {}
for i in range(5):
    test_features[f'cache_test_feature_{i}'] = pd.DataFrame({
        'id': range(1000),
        'value': range(1000 * i, 1000 * (i + 1)),
        'feature': [f'data_{j}' for j in range(1000)]
    })

print(f'ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_features)}ê°œ í”¼ì²˜ ê·¸ë£¹')

# ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
feature_names = list(test_features.keys())

# 1. ì´ˆê¸° ì €ì¥ (ìºì‹œ ì—†ìŒ)
print('\\n1ï¸âƒ£ ì´ˆê¸° ì €ì¥ ë° ì¡°íšŒ (ìºì‹œ ë¯¸ìŠ¤)...')
store.save_features('cache_test_group', test_features)

# ì²« ë²ˆì§¸ ì¡°íšŒ (ë””ìŠ¤í¬ì—ì„œ ë¡œë“œ)
start_time = time.time()
first_load = store.get_features(feature_names, 'cache_test_group')
first_load_time = time.time() - start_time

print(f'  ì²« ë²ˆì§¸ ì¡°íšŒ: {first_load_time*1000:.2f}ms')

# 2. ë‘ ë²ˆì§¸ ì¡°íšŒ (ìºì‹œì—ì„œ ë¡œë“œ)
print('2ï¸âƒ£ ë‘ ë²ˆì§¸ ì¡°íšŒ (ìºì‹œ íˆíŠ¸)...')
start_time = time.time()
second_load = store.get_features(feature_names, 'cache_test_group')
second_load_time = time.time() - start_time

print(f'  ë‘ ë²ˆì§¸ ì¡°íšŒ: {second_load_time*1000:.2f}ms')

# 3. ìºì‹œ ì„±ëŠ¥ ë¶„ì„
if second_load_time < first_load_time:
    speedup = first_load_time / second_load_time
    improvement = ((first_load_time - second_load_time) / first_load_time) * 100
    print(f'\\nğŸ“ˆ ìºì‹œ ì„±ëŠ¥ í–¥ìƒ:')
    print(f'  ì†ë„ í–¥ìƒ: {speedup:.1f}ë°°')
    print(f'  ì„±ëŠ¥ ê°œì„ : {improvement:.1f}%')
    
    if speedup >= 5:
        print('âœ… ìºì‹œ íš¨ìœ¨ì„±: ìš°ìˆ˜ (â‰¥5ë°° í–¥ìƒ)')
    elif speedup >= 2:
        print('âš ï¸ ìºì‹œ íš¨ìœ¨ì„±: ì–‘í˜¸ (â‰¥2ë°° í–¥ìƒ)')
    else:
        print('âŒ ìºì‹œ íš¨ìœ¨ì„±: ê°œì„  í•„ìš” (<2ë°° í–¥ìƒ)')
else:
    print('âŒ ìºì‹œ ì„±ëŠ¥ í–¥ìƒì´ í™•ì¸ë˜ì§€ ì•ŠìŒ')

# 4. ìºì‹œ í†µê³„ í™•ì¸
if store.cache:
    cache_stats = store.cache.get_stats()
    print(f'\\nğŸ“Š ìºì‹œ í†µê³„:')
    print(f'  ìºì‹œ í¬ê¸°: {cache_stats.get(\"size\", 0)}/{cache_stats.get(\"max_size\", 0)}')
    print(f'  TTL: {cache_stats.get(\"ttl_seconds\", 0)}ì´ˆ')

print('\\nâœ… ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!')
"
```

---

## âœ… ì„±ê³µ ê¸°ì¤€

### ì²˜ë¦¬ ì„±ëŠ¥ ê¸°ì¤€
- [ ] **í”¼ì²˜ ìƒì„± ì†ë„**: â‰¥ 10 movies/second (1000ê°œ ì˜í™” ê¸°ì¤€)
- [ ] **ì €ì¥ ì†ë„**: â‰¥ 10 MB/second
- [ ] **ì¡°íšŒ ì†ë„**: â‰¥ 20 MB/second

### í™•ì¥ì„± ê¸°ì¤€
- [ ] **ë™ì‹œì„±**: 8ê°œ ìŠ¤ë ˆë“œ ë™ì‹œ ì ‘ê·¼ ì‹œ â‰¥ 90% ì„±ê³µë¥ 
- [ ] **ëŒ€ìš©ëŸ‰ ì²˜ë¦¬**: 1000ê°œ ì˜í™” ì²˜ë¦¬ ì‹œ < 300MB ë©”ëª¨ë¦¬ ì‚¬ìš©
- [ ] **ì—°ì† ì•ˆì •ì„±**: 3ë¶„ê°„ ì—°ì† ì²˜ë¦¬ ì‹œ ì˜¤ë¥˜ìœ¨ < 5%

### ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê¸°ì¤€
- [ ] **ë©”ëª¨ë¦¬ ì¦ê°€**: ë°˜ë³µ ì²˜ë¦¬ ì‹œ < 20MB ëˆ„ì  ì¦ê°€
- [ ] **ë©”ëª¨ë¦¬ ì •ë¦¬**: ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ í›„ ë©”ëª¨ë¦¬ í•´ì œ í™•ì¸
- [ ] **ë¦¬ì†ŒìŠ¤ ì‚¬ìš©**: CPU ì‚¬ìš©ë¥  í‰ìƒì‹œ < 50%

### ìºì‹œ ì„±ëŠ¥ ê¸°ì¤€
- [ ] **ìºì‹œ íš¨ê³¼**: ë‘ ë²ˆì§¸ ì¡°íšŒê°€ ì²« ë²ˆì§¸ë³´ë‹¤ â‰¥ 2ë°° ë¹ ë¦„
- [ ] **ìºì‹œ ì ì¤‘ë¥ **: ì—°ì† ì¡°íšŒ ì‹œ ì ì¤‘ë¥  > 80%
- [ ] **TTL ê´€ë¦¬**: ìºì‹œ ë§Œë£Œ í›„ ìë™ ê°±ì‹ 

### ì•ˆì •ì„± ê¸°ì¤€
- [ ] **ì˜¤ë¥˜ ë³µêµ¬**: ì¼ì‹œì  ì˜¤ë¥˜ í›„ ìë™ ë³µêµ¬
- [ ] **ë°ì´í„° ë¬´ê²°ì„±**: ë™ì‹œ ì ‘ê·¼ ì‹œì—ë„ ë°ì´í„° ì†ì‹¤ ì—†ìŒ
- [ ] **ì¥ì‹œê°„ ì•ˆì •ì„±**: ì—°ì† ë™ì‘ ì‹œ ì„±ëŠ¥ ì €í•˜ < 10%

**ì„±ëŠ¥ ë° í™•ì¥ì„± í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ë©´ ë‹¤ìŒ ë‹¨ê³„ì¸ [2.5-feast-integration-testing.md](./2.5-feast-integration-testing.md)ë¡œ ì§„í–‰í•˜ì„¸ìš”!** ğŸš€
