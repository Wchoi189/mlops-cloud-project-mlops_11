# 2.2 í•µì‹¬ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸

## ğŸ“‹ ê°œìš”

2ë‹¨ê³„ì—ì„œ êµ¬í˜„ëœ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤ì˜ ê¸°ëŠ¥ì„ ì²´ê³„ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ê°€ì´ë“œì…ë‹ˆë‹¤.

---

## ğŸ”¬ 1. AdvancedTMDBPreProcessor ì „ì²´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

### 1.1 ê¸°ë³¸ í”¼ì²˜ ìƒì„± í…ŒìŠ¤íŠ¸

```bash
# ê¸°ë³¸ í”¼ì²˜ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')

from features.engineering.tmdb_processor import AdvancedTMDBPreProcessor
import pandas as pd

print('ğŸ”¬ AdvancedTMDBPreProcessor ê¸°ë³¸ í”¼ì²˜ í…ŒìŠ¤íŠ¸...')

# ì‹¤ì œ TMDB í˜•ì‹ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°
test_movies = [
    {
        'movie_id': 1,
        'title': 'Test Movie Action',
        'overview': 'An action-packed test movie with heroes and battles.',
        'release_date': '2023-06-15',
        'vote_average': 8.5,
        'vote_count': 1500,
        'popularity': 45.2,
        'genre_ids': [28, 12],  # Action, Adventure
        'adult': False,
        'original_language': 'en',
        'original_title': 'Test Movie Action'
    }
]

print(f'ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_movies)}ê°œ ì˜í™”')

# í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
processor = AdvancedTMDBPreProcessor(test_movies)

# ê¸°ë³¸ í”¼ì²˜ ì¶”ì¶œ
basic_features = processor.extract_basic_features()

print(f'âœ… ê¸°ë³¸ í”¼ì²˜ ìƒì„± ì™„ë£Œ: {len(basic_features)} í–‰, {len(basic_features.columns)} ì»¬ëŸ¼')
print(f'   ì£¼ìš” ì»¬ëŸ¼: {list(basic_features.columns)[:8]}...')

print('âœ… ê¸°ë³¸ í”¼ì²˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ')
"
```

### 1.2 ì‹œê°„ ê¸°ë°˜ í”¼ì²˜ í…ŒìŠ¤íŠ¸

```bash
# ì‹œê°„ ê¸°ë°˜ í”¼ì²˜ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')

from features.engineering.tmdb_processor import AdvancedTMDBPreProcessor

print('ğŸ•’ ì‹œê°„ ê¸°ë°˜ í”¼ì²˜ í…ŒìŠ¤íŠ¸...')

# ë‹¤ì–‘í•œ ë‚ ì§œì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°
test_movies = [
    {
        'movie_id': 1,
        'title': 'Recent Movie',
        'release_date': '2023-07-15',  # ìµœê·¼ ì˜í™”
        'vote_average': 8.0,
        'vote_count': 1000,
        'popularity': 50.0,
        'genre_ids': [28],
        'adult': False,
        'original_language': 'en'
    },
    {
        'movie_id': 2,
        'title': 'Classic Movie',
        'release_date': '1995-12-25',  # í´ë˜ì‹ ì˜í™”
        'vote_average': 8.5,
        'vote_count': 5000,
        'popularity': 30.0,
        'genre_ids': [18],
        'adult': False,
        'original_language': 'en'
    },
    {
        'movie_id': 3,
        'title': 'Future Release',
        'release_date': '2025-01-01',  # ë¯¸ë˜ ì¶œì‹œ
        'vote_average': 0,
        'vote_count': 0,
        'popularity': 100.0,
        'genre_ids': [878],
        'adult': False,
        'original_language': 'en'
    }
]

processor = AdvancedTMDBPreProcessor(test_movies)
temporal_features = processor.extract_temporal_features()

print(f'âœ… ì‹œê°„ ê¸°ë°˜ í”¼ì²˜ ìƒì„± ì™„ë£Œ: {len(temporal_features)} í–‰, {len(temporal_features.columns)} ì»¬ëŸ¼')

# í•„ìˆ˜ ì‹œê°„ í”¼ì²˜ ê²€ì¦
required_temporal = ['release_year', 'release_quarter', 'is_recent', 'is_classic', 'is_future_release', 'decade']
missing_temporal = [f for f in required_temporal if f not in temporal_features.columns]

if not missing_temporal:
    print('âœ… ëª¨ë“  í•„ìˆ˜ ì‹œê°„ í”¼ì²˜ ìƒì„±ë¨')
    
    # ë°ì´í„° ê²€ì¦
    recent_check = temporal_features[temporal_features['movie_id'] == 1]['is_recent'].iloc[0]
    classic_check = temporal_features[temporal_features['movie_id'] == 2]['is_classic'].iloc[0]
    future_check = temporal_features[temporal_features['movie_id'] == 3]['is_future_release'].iloc[0]
    
    if recent_check == 1 and classic_check == 1 and future_check == 1:
        print('âœ… ì‹œê°„ ê¸°ë°˜ ë¶„ë¥˜ ë¡œì§ ì •í™•')
    else:
        print('âš ï¸ ì‹œê°„ ê¸°ë°˜ ë¶„ë¥˜ ë¡œì§ í™•ì¸ í•„ìš”')
else:
    print(f'âŒ ëˆ„ë½ëœ ì‹œê°„ í”¼ì²˜: {missing_temporal}')

print('âœ… ì‹œê°„ ê¸°ë°˜ í”¼ì²˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ')
"
```

### 1.3 ì „ì²´ í”¼ì²˜ í†µí•© í…ŒìŠ¤íŠ¸

```bash
# ëª¨ë“  í”¼ì²˜ ì¹´í…Œê³ ë¦¬ í†µí•© í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')

from features.engineering.tmdb_processor import AdvancedTMDBPreProcessor
import pandas as pd

print('ğŸ¯ ì „ì²´ í”¼ì²˜ í†µí•© í…ŒìŠ¤íŠ¸...')

# ì¢…í•© í…ŒìŠ¤íŠ¸ ë°ì´í„°
comprehensive_movie = {
    'movie_id': 999,
    'title': 'Comprehensive Test Movie 3: Final Battle',
    'overview': 'An epic action-packed adventure with heroes, battles, love, and scary moments that will test all our feature extraction capabilities.',
    'release_date': '2023-06-15',
    'vote_average': 8.7,
    'vote_count': 2500,
    'popularity': 85.3,
    'genre_ids': [28, 12, 878, 10749],  # Action, Adventure, Sci-Fi, Romance
    'adult': False,
    'original_language': 'en',
    'original_title': 'Comprehensive Test Movie 3: Final Battle'
}

processor = AdvancedTMDBPreProcessor([comprehensive_movie])

# ì „ì²´ í”¼ì²˜ ì¶”ì¶œ
all_features = processor.extract_all_features()

print(f'ğŸŠ ì „ì²´ í”¼ì²˜ ì¶”ì¶œ ì™„ë£Œ: {len(all_features)} ì¹´í…Œê³ ë¦¬')

# ê° ì¹´í…Œê³ ë¦¬ ê²€ì¦
expected_categories = ['basic', 'temporal', 'statistical', 'text', 'interaction', 'augmented', 'metadata']
missing_categories = [cat for cat in expected_categories if cat not in all_features]

if not missing_categories:
    print('âœ… ëª¨ë“  í”¼ì²˜ ì¹´í…Œê³ ë¦¬ ìƒì„±ë¨')
    
    for category, data in all_features.items():
        if isinstance(data, pd.DataFrame):
            print(f'  ğŸ“Š {category}: {len(data)} í–‰, {len(data.columns)} ì»¬ëŸ¼')
        elif isinstance(data, dict):
            print(f'  ğŸ“‹ {category}: {len(data)} í•­ëª©')
        else:
            print(f'  ğŸ“„ {category}: {type(data).__name__}')
    
    # í’ˆì§ˆ ê²€ì¦
    validation_results = processor.validate_features(all_features)
    
    all_valid = True
    for category, results in validation_results.items():
        if isinstance(results, dict) and not results.get('no_missing_values', True):
            all_valid = False
            print(f'âš ï¸ {category}: ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ìˆìŒ')
    
    if all_valid:
        print('âœ… ëª¨ë“  í”¼ì²˜ í’ˆì§ˆ ê²€ì¦ í†µê³¼')
    
else:
    print(f'âŒ ëˆ„ë½ëœ í”¼ì²˜ ì¹´í…Œê³ ë¦¬: {missing_categories}')

print('âœ… ì „ì²´ í”¼ì²˜ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ')
"
```

---

## ğŸª 2. SimpleFeatureStore ì „ì²´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

### 2.1 ê¸°ë³¸ ì €ì¥/ì¡°íšŒ í…ŒìŠ¤íŠ¸

```bash
# ê¸°ë³¸ í”¼ì²˜ ìŠ¤í† ì–´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')

from features.store.feature_store import SimpleFeatureStore, FeatureStoreConfig
import pandas as pd
import numpy as np

print('ğŸª SimpleFeatureStore ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸...')

# í”¼ì²˜ ìŠ¤í† ì–´ ì´ˆê¸°í™”
config = FeatureStoreConfig(
    base_path='/app/data/test_feature_store',
    cache_enabled=True,
    cache_max_size=50,
    cache_ttl_seconds=300
)

store = SimpleFeatureStore(config)
print('âœ… í”¼ì²˜ ìŠ¤í† ì–´ ì´ˆê¸°í™” ì™„ë£Œ')

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
test_features = {
    'movie_features': pd.DataFrame({
        'movie_id': [1, 2, 3, 4, 5],
        'popularity': [100.5, 80.3, 120.7, 95.2, 110.8],
        'vote_average': [7.5, 6.8, 8.1, 7.2, 8.5],
        'genre_action': [1, 0, 1, 0, 1],
        'genre_drama': [0, 1, 0, 1, 0]
    }),
    'user_features': pd.DataFrame({
        'user_id': [101, 102, 103],
        'age_group': ['young', 'adult', 'senior'],
        'preference_score': [0.8, 0.6, 0.9]
    })
}

print(f'ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: {len(test_features)} í”¼ì²˜ ê·¸ë£¹')

# ì €ì¥ í…ŒìŠ¤íŠ¸
saved_paths = store.save_features('test_group', test_features)
print(f'âœ… í”¼ì²˜ ì €ì¥ ì™„ë£Œ: {len(saved_paths)} íŒŒì¼')

# ì¡°íšŒ í…ŒìŠ¤íŠ¸
loaded_features = store.get_features(['movie_features', 'user_features'], 'test_group')
print(f'âœ… í”¼ì²˜ ì¡°íšŒ ì™„ë£Œ: {len(loaded_features)} í”¼ì²˜ ê·¸ë£¹')

# ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
integrity_check = True
for feature_name in test_features.keys():
    original = test_features[feature_name]
    loaded = loaded_features[feature_name]
    
    if len(original) != len(loaded) or len(original.columns) != len(loaded.columns):
        integrity_check = False
        print(f'âŒ {feature_name}: ë°ì´í„° ë¬´ê²°ì„± ì‹¤íŒ¨')
    else:
        print(f'âœ… {feature_name}: ë°ì´í„° ë¬´ê²°ì„± í™•ì¸')

if integrity_check:
    print('âœ… ëª¨ë“  ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ í†µê³¼')

print('âœ… ê¸°ë³¸ ì €ì¥/ì¡°íšŒ í…ŒìŠ¤íŠ¸ ì™„ë£Œ')
"
```

### 2.2 ë©”íƒ€ë°ì´í„° ê´€ë¦¬ í…ŒìŠ¤íŠ¸

```bash
# ë©”íƒ€ë°ì´í„° ê´€ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')

from features.store.feature_store import SimpleFeatureStore, FeatureStoreConfig

print('ğŸ“‹ ë©”íƒ€ë°ì´í„° ê´€ë¦¬ í…ŒìŠ¤íŠ¸...')

config = FeatureStoreConfig(base_path='/app/data/test_feature_store')
store = SimpleFeatureStore(config)

# í”¼ì²˜ ê·¸ë£¹ ëª©ë¡ ì¡°íšŒ
groups = store.list_feature_groups()
print(f'âœ… í”¼ì²˜ ê·¸ë£¹ ëª©ë¡: {groups}')

# í”¼ì²˜ ëª©ë¡ ì¡°íšŒ
features = store.list_features()
print(f'âœ… ì „ì²´ í”¼ì²˜ ëª©ë¡: {features}')

# íŠ¹ì • ê·¸ë£¹ì˜ í”¼ì²˜ ëª©ë¡
if groups:
    group_features = store.list_features(groups[0])
    print(f'âœ… {groups[0]} ê·¸ë£¹ í”¼ì²˜: {group_features}')

# í”¼ì²˜ ì •ë³´ ì¡°íšŒ
if features:
    feature_info = store.get_feature_info(features[0])
    if feature_info:
        print(f'âœ… í”¼ì²˜ ì •ë³´ ì¡°íšŒ ì„±ê³µ: {features[0]}')
        print(f'   ìƒì„±ì¼: {feature_info[\"created_at\"]}')
        print(f'   í¬ê¸°: {feature_info[\"size_bytes\"]} bytes')
        print(f'   ë ˆì½”ë“œ ìˆ˜: {feature_info[\"record_count\"]}')
    else:
        print(f'âš ï¸ í”¼ì²˜ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {features[0]}')

# ìŠ¤í† ì–´ í†µê³„
stats = store.get_store_stats()
print(f'âœ… ìŠ¤í† ì–´ í†µê³„ ì¡°íšŒ ì„±ê³µ:')
print(f'   ì´ í”¼ì²˜: {stats[\"total_features\"]}ê°œ')
print(f'   ì´ ê·¸ë£¹: {stats[\"total_groups\"]}ê°œ')
print(f'   ì €ì¥ í¬ê¸°: {stats[\"total_size_mb\"]:.2f} MB')
print(f'   ì´ ë ˆì½”ë“œ: {stats[\"total_records\"]:,}ê°œ')

print('âœ… ë©”íƒ€ë°ì´í„° ê´€ë¦¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ')
"
```

### 2.3 ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

```bash
# ìºì‹œ ê¸°ëŠ¥ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')

from features.store.feature_store import SimpleFeatureStore, FeatureStoreConfig
import pandas as pd
import time

print('ğŸ—„ï¸ ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸...')

config = FeatureStoreConfig(
    base_path='/app/data/test_feature_store',
    cache_enabled=True,
    cache_max_size=10,
    cache_ttl_seconds=60
)
store = SimpleFeatureStore(config)

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
large_data = pd.DataFrame({
    'id': range(1000),
    'value': range(1000, 2000),
    'random_data': [f'data_{i}' for i in range(1000)]
})

test_features = {'large_test_data': large_data}

# ì²« ë²ˆì§¸ ì €ì¥ ë° ì¡°íšŒ (ìºì‹œ ë¯¸ìŠ¤)
print('ğŸ’¾ ì²« ë²ˆì§¸ ì €ì¥ ë° ì¡°íšŒ (ìºì‹œ ë¯¸ìŠ¤)...')
store.save_features('cache_test_group', test_features)

start_time = time.time()
loaded_data_1 = store.get_features(['large_test_data'], 'cache_test_group')
first_load_time = time.time() - start_time

# ë‘ ë²ˆì§¸ ì¡°íšŒ (ìºì‹œ íˆíŠ¸)
print('ğŸš€ ë‘ ë²ˆì§¸ ì¡°íšŒ (ìºì‹œ íˆíŠ¸)...')
start_time = time.time()
loaded_data_2 = store.get_features(['large_test_data'], 'cache_test_group')
second_load_time = time.time() - start_time

print(f'â±ï¸ ì„±ëŠ¥ ë¹„êµ:')
print(f'   ì²« ë²ˆì§¸ ì¡°íšŒ: {first_load_time*1000:.2f}ms')
print(f'   ë‘ ë²ˆì§¸ ì¡°íšŒ: {second_load_time*1000:.2f}ms')

if second_load_time < first_load_time:
    speedup = first_load_time / second_load_time
    print(f'âœ… ìºì‹œ ì„±ëŠ¥ í–¥ìƒ: {speedup:.1f}ë°° ë¹ ë¦„')
else:
    print('âš ï¸ ìºì‹œ ì„±ëŠ¥ í–¥ìƒ í™•ì¸ë˜ì§€ ì•ŠìŒ')

# ìºì‹œ í†µê³„ í™•ì¸
if store.cache:
    cache_stats = store.cache.get_stats()
    print(f'ğŸ“Š ìºì‹œ í†µê³„: {cache_stats}')

print('âœ… ìºì‹œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ')
"
```

---

## ğŸ”„ 3. FeaturePipeline ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸

### 3.1 ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸

```bash
# ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')

from features.pipeline.feature_pipeline import FeaturePipeline, PipelineConfig, create_default_config

print('ğŸ”„ FeaturePipeline ê¸°ë³¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸...')

# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ ìƒì„±
config_dict = create_default_config()
config = PipelineConfig(**config_dict)

print(f'âœ… íŒŒì´í”„ë¼ì¸ ì„¤ì • ë¡œë“œ: {len(config.stages)} ë‹¨ê³„')

# í…ŒìŠ¤íŠ¸ ë°ì´í„°
sample_data = [
    {
        'movie_id': 1,
        'title': 'Pipeline Test Movie',
        'overview': 'Testing the feature pipeline with this movie.',
        'release_date': '2023-01-01',
        'vote_average': 8.0,
        'vote_count': 1000,
        'popularity': 40.0,
        'genre_ids': [28],
        'adult': False,
        'original_language': 'en'
    },
    {
        'movie_id': 2,
        'title': 'Another Test Movie',
        'overview': 'Second movie for pipeline testing.',
        'release_date': '2023-06-15',
        'vote_average': 7.5,
        'vote_count': 800,
        'popularity': 35.0,
        'genre_ids': [18, 10749],
        'adult': False,
        'original_language': 'en'
    }
]

print(f'ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(sample_data)} ì˜í™”')

# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
pipeline = FeaturePipeline(config)

def progress_callback(progress, stage_name):
    print(f'  ì§„í–‰ë¥ : {progress:.1f}% - {stage_name}')

pipeline.set_progress_callback(progress_callback)

try:
    result = pipeline.run(sample_data)
    print(f'âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì„±ê³µ')
    
    if isinstance(result, dict):
        print(f'   ê²°ê³¼ ì¹´í…Œê³ ë¦¬: {list(result.keys())}')
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ ì •ë³´ ì¶œë ¥
        for category, data in result.items():
            if hasattr(data, 'shape'):
                print(f'   {category}: {data.shape[0]}í–‰ x {data.shape[1]}ì»¬ëŸ¼')
            elif isinstance(data, dict):
                print(f'   {category}: {len(data)}ê°œ í•­ëª©')
        
        # ê²€ì¦ ê²°ê³¼ í™•ì¸
        if 'validation_results' in result:
            validation_results = result['validation_results']
            all_passed = all(r.get('passed', False) for r in validation_results.values() if isinstance(r, dict))
            if all_passed:
                print('âœ… ëª¨ë“  íŒŒì´í”„ë¼ì¸ ê²€ì¦ í†µê³¼')
            else:
                print('âš ï¸ ì¼ë¶€ íŒŒì´í”„ë¼ì¸ ê²€ì¦ ì‹¤íŒ¨')
        
        print('ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!')
    
except Exception as e:
    print(f'âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}')

print('âœ… ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ')
"
```

### 3.2 íŒŒì´í”„ë¼ì¸ ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì§• í…ŒìŠ¤íŠ¸

```bash
# ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ ì„¤ì • í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')

from features.pipeline.feature_pipeline import FeaturePipeline, PipelineConfig

print('âš™ï¸ ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ ì„¤ì • í…ŒìŠ¤íŠ¸...')

# ë³€í™˜ ë‹¨ê³„ë¥¼ ì œì™¸í•œ ì»¤ìŠ¤í…€ ì„¤ì •
custom_config = PipelineConfig(
    input_source='test_data',
    input_format='json',
    output_destination='/app/data/pipeline_test',
    output_format='parquet',
    parallel_processing=False,
    max_workers=1,
    chunk_size=100,
    enable_caching=True,
    progress_reporting=True,
    stages=[
        {
            'name': 'data_validation',
            'type': 'DataValidationStage',
            'params': {
                'required_fields': ['movie_id', 'title'],
                'min_records': 1
            }
        },
        {
            'name': 'feature_extraction',
            'type': 'FeatureExtractionStage',
            'params': {
                'extraction_type': 'basic'
            }
        },
        {
            'name': 'feature_validation',
            'type': 'FeatureValidationStage',
            'params': {
                'min_records': 1,
                'max_missing_ratio': 0.9,
                'strict_validation': False
            }
        }
    ]
)

print('âœ… ì»¤ìŠ¤í…€ ì„¤ì • ìƒì„± ì™„ë£Œ')

# ìµœì†Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
minimal_data = [
    {
        'movie_id': 1,
        'title': 'Minimal Test Movie',
        'vote_average': 7.0,
        'vote_count': 100,
        'popularity': 20.0,
        'genre_ids': [28],
        'adult': False,
        'original_language': 'en'
    }
]

pipeline = FeaturePipeline(custom_config)

try:
    result = pipeline.run(minimal_data)
    print('âœ… ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì„±ê³µ')
    
    # ê¸°ë³¸ í”¼ì²˜ë§Œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if isinstance(result, dict) and 'basic' in result:
        basic_features = result['basic']
        if hasattr(basic_features, 'shape'):
            print(f'   ê¸°ë³¸ í”¼ì²˜: {basic_features.shape[0]}í–‰ x {basic_features.shape[1]}ì»¬ëŸ¼')
        print('âœ… ì„¤ì •ëŒ€ë¡œ ê¸°ë³¸ í”¼ì²˜ë§Œ ìƒì„±ë¨')
    
    # ê²€ì¦ ê²°ê³¼ í™•ì¸
    if 'validation_results' in result:
        validation_results = result['validation_results']
        all_passed = all(r.get('passed', False) for r in validation_results.values() if isinstance(r, dict))
        if all_passed:
            print('âœ… ëª¨ë“  ê²€ì¦ í†µê³¼')
        else:
            print('âš ï¸ ì¼ë¶€ ê²€ì¦ ì‹¤íŒ¨')
            for category, results in validation_results.items():
                if isinstance(results, dict) and not results.get('passed', True):
                    print(f'   {category}: {results.get(\"issues\", [])}')
    
except Exception as e:
    print(f'âŒ ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}')

print('âœ… ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ ì„¤ì • í…ŒìŠ¤íŠ¸ ì™„ë£Œ')
"
```

---

## ğŸ” 4. FeatureValidator í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸

### 4.1 í”¼ì²˜ í’ˆì§ˆ ì²´í¬ í…ŒìŠ¤íŠ¸

```bash
# í”¼ì²˜ í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')

try:
    from features.validation.feature_validator import FeatureQualityChecker
    
    print('ğŸ” FeatureValidator í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸...')
    
    import pandas as pd
    import numpy as np
    
    # í…ŒìŠ¤íŠ¸ìš© í”¼ì²˜ ë°ì´í„° ìƒì„±
    test_features = pd.DataFrame({
        'movie_id': range(100),
        'popularity': np.random.exponential(50, 100),
        'vote_average': np.random.normal(7.0, 1.5, 100),
        'vote_count': np.random.poisson(500, 100),
        'genre_action': np.random.choice([0, 1], 100),
        'is_english': np.random.choice([0, 1], 100, p=[0.3, 0.7])
    })
    
    print(f'ğŸ“Š í…ŒìŠ¤íŠ¸ í”¼ì²˜ ë°ì´í„°: {test_features.shape[0]}í–‰ x {test_features.shape[1]}ì»¬ëŸ¼')
    
    # í’ˆì§ˆ ê²€ì¦ê¸° ì´ˆê¸°í™”
    validator = FeatureQualityChecker()
    
    # í”¼ì²˜ í’ˆì§ˆ ê²€ì¦
    quality_reports = validator.validate_features(test_features)
    
    print(f'âœ… í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ: {len(quality_reports)} í”¼ì²˜ ê²€ì¦ë¨')
    
    # í‰ê·  í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    if quality_reports:
        avg_score = sum(report.quality_score for report in quality_reports.values()) / len(quality_reports)
        print(f'   í‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_score:.2f}/100')
        
        if avg_score >= 80:
            print('âœ… ë†’ì€ í’ˆì§ˆì˜ í”¼ì²˜ ë°ì´í„°')
        elif avg_score >= 60:
            print('âš ï¸ ë³´í†µ í’ˆì§ˆì˜ í”¼ì²˜ ë°ì´í„°')
        else:
            print('âŒ ë‚®ì€ í’ˆì§ˆì˜ í”¼ì²˜ ë°ì´í„°')
    
    print('âœ… í”¼ì²˜ í’ˆì§ˆ ì²´í¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ')
    
except ImportError:
    print('âš ï¸ FeatureValidator ëª¨ë“ˆì´ êµ¬í˜„ë˜ì§€ ì•ŠìŒ (ì„ íƒì‚¬í•­)')
except Exception as e:
    print(f'âŒ FeatureValidator í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}')
"
```

---

## ğŸ”— 5. í†µí•© ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸

### 5.1 End-to-End í†µí•© í…ŒìŠ¤íŠ¸

```bash
# End-to-End í†µí•© í…ŒìŠ¤íŠ¸
docker compose exec dev python -c "
import sys
sys.path.append('/app/src')

print('ğŸ”— End-to-End í†µí•© ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸...')

try:
    from features.engineering.tmdb_processor import AdvancedTMDBPreProcessor
    from features.store.feature_store import SimpleFeatureStore, FeatureStoreConfig
    from features.pipeline.feature_pipeline import FeaturePipeline, PipelineConfig, create_default_config
    
    # 1. ì›ì‹œ ë°ì´í„° ì¤€ë¹„
    raw_data = [
        {
            'movie_id': 888,
            'title': 'E2E Integration Test Movie',
            'overview': 'A comprehensive test movie for end-to-end workflow validation.',
            'release_date': '2023-12-01',
            'vote_average': 8.8,
            'vote_count': 1800,
            'popularity': 75.5,
            'genre_ids': [28, 878],
            'adult': False,
            'original_language': 'en'
        }
    ]
    print('âœ… 1. ì›ì‹œ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ')
    
    # 2. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    processor = AdvancedTMDBPreProcessor(raw_data)
    features = processor.extract_all_features()
    print(f'âœ… 2. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œ ({len(features)} ì¹´í…Œê³ ë¦¬)')
    
    # 3. í”¼ì²˜ ìŠ¤í† ì–´ ì €ì¥
    config = FeatureStoreConfig(base_path='/app/data/e2e_test_store')
    store = SimpleFeatureStore(config)
    
    # DataFrame í”¼ì²˜ë§Œ ì €ì¥
    storable_features = {}
    for category, data in features.items():
        if hasattr(data, 'to_dict') and category != 'metadata':
            storable_features[f'e2e_{category}'] = data
    
    if storable_features:
        saved_paths = store.save_features('e2e_test_group', storable_features)
        print(f'âœ… 3. í”¼ì²˜ ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ ({len(saved_paths)} íŒŒì¼)')
        
        # 4. í”¼ì²˜ ì¡°íšŒ ê²€ì¦
        loaded_features = store.get_features(list(storable_features.keys()), 'e2e_test_group')
        print(f'âœ… 4. í”¼ì²˜ ì¡°íšŒ ê²€ì¦ ì™„ë£Œ ({len(loaded_features)} í”¼ì²˜ ê·¸ë£¹)')
        
        # 5. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²€ì¦ (ì•ˆì „í•œ ì„¤ì •)
        safe_config = PipelineConfig(
            input_source='test',
            input_format='json', 
            output_destination='/app/data/e2e_pipeline_test',
            output_format='parquet',
            parallel_processing=False,
            max_workers=1,
            chunk_size=100,
            enable_caching=True,
            progress_reporting=True,
            stages=[
                {
                    'name': 'data_validation',
                    'type': 'DataValidationStage',
                    'params': {
                        'required_fields': ['movie_id', 'title'],
                        'min_records': 1
                    }
                },
                {
                    'name': 'feature_extraction',
                    'type': 'FeatureExtractionStage',
                    'params': {
                        'extraction_type': 'basic'
                    }
                }
            ]
        )
        
        pipeline = FeaturePipeline(safe_config)
        pipeline_result = pipeline.run(raw_data)
        print('âœ… 5. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²€ì¦ ì™„ë£Œ')
        
        # 6. ì „ì²´ í†µí•© ê²€ì¦
        total_features_created = len(features)
        total_features_stored = len(saved_paths)
        total_features_loaded = len(loaded_features)
        
        if total_features_created > 0 and total_features_stored > 0 and total_features_loaded > 0:
            print('âœ… 6. ì „ì²´ í†µí•© ê²€ì¦ ì„±ê³µ!')
            print(f'   ìƒì„±ëœ í”¼ì²˜: {total_features_created}ê°œ ì¹´í…Œê³ ë¦¬')
            print(f'   ì €ì¥ëœ í”¼ì²˜: {total_features_stored}ê°œ íŒŒì¼')
            print(f'   ì¡°íšŒëœ í”¼ì²˜: {total_features_loaded}ê°œ ê·¸ë£¹')
            print('')
            print('ğŸ‰ ëª¨ë“  í•µì‹¬ ì»´í¬ë„ŒíŠ¸ê°€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!')
            print('ğŸ“‹ ì™„ë£Œëœ í…ŒìŠ¤íŠ¸:')
            print('   âœ… AdvancedTMDBPreProcessor - í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§')
            print('   âœ… SimpleFeatureStore - í”¼ì²˜ ì €ì¥/ì¡°íšŒ')  
            print('   âœ… FeaturePipeline - ì›Œí¬í”Œë¡œìš° íŒŒì´í”„ë¼ì¸')
            print('   âœ… FeatureValidator - í’ˆì§ˆ ê²€ì¦')
            print('   âœ… End-to-End í†µí•© ì›Œí¬í”Œë¡œìš°')
        else:
            print('âŒ í†µí•© ê²€ì¦ ì‹¤íŒ¨')
            print(f'   ìƒì„±: {total_features_created}, ì €ì¥: {total_features_stored}, ì¡°íšŒ: {total_features_loaded}')
    else:
        print('âŒ ì €ì¥ ê°€ëŠ¥í•œ í”¼ì²˜ê°€ ì—†ìŒ')
    
    print('')
    print('ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: API í†µí•© í…ŒìŠ¤íŠ¸')
    print('   ë¬¸ì„œ: docs/02-feature-store/testing/2.3-api-integration-testing.md')
    
except Exception as e:
    print(f'âŒ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}')
    import traceback
    traceback.print_exc()
"
```

---

## âœ… ì„±ê³µ ê¸°ì¤€

### í•„ìˆ˜ í†µê³¼ í•­ëª©

#### AdvancedTMDBPreProcessor
- [ ] ê¸°ë³¸ í”¼ì²˜ ìƒì„± (ì¥ë¥´ ì›-í•«, ì–¸ì–´, í‰ì  êµ¬ê°„í™”)
- [ ] ì‹œê°„ ê¸°ë°˜ í”¼ì²˜ ìƒì„± (ì—°ë„, ë¶„ê¸°, ê³„ì ˆì„±)
- [ ] í†µê³„ì  í”¼ì²˜ ìƒì„± (Z-score, ë°±ë¶„ìœ„ìˆ˜)
- [ ] í…ìŠ¤íŠ¸ í”¼ì²˜ ìƒì„± (ê¸¸ì´, í‚¤ì›Œë“œ ë¶„ì„)
- [ ] ìƒí˜¸ì‘ìš© í”¼ì²˜ ìƒì„±
- [ ] ì „ì²´ í”¼ì²˜ ì¹´í…Œê³ ë¦¬ ìƒì„± (7ê°œ)

#### SimpleFeatureStore
- [ ] ê¸°ë³¸ ì €ì¥/ì¡°íšŒ ê¸°ëŠ¥
- [ ] ë©”íƒ€ë°ì´í„° ê´€ë¦¬ (SQLite)
- [ ] ìºì‹œ ê¸°ëŠ¥ (ì„±ëŠ¥ í–¥ìƒ í™•ì¸)
- [ ] íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…
- [ ] ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥

#### FeaturePipeline
- [ ] ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
- [ ] ì»¤ìŠ¤í…€ ì„¤ì • ì ìš©
- [ ] ë‹¨ê³„ë³„ ì§„í–‰ë¥  ëª¨ë‹ˆí„°ë§
- [ ] ì˜¤ë¥˜ ì²˜ë¦¬ ë° ê²€ì¦

#### í†µí•© ì›Œí¬í”Œë¡œìš°
- [ ] End-to-End ì²˜ë¦¬ ì„±ê³µ
- [ ] ë°ì´í„° íë¦„ ë¬´ê²°ì„±
- [ ] ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì—°ë™

### ì„±ëŠ¥ ê¸°ì¤€
- [ ] í”¼ì²˜ ìƒì„± ì†ë„: â‰¥ 5 movies/second
- [ ] ìºì‹œ íš¨ê³¼: ë‘ ë²ˆì§¸ ì¡°íšŒê°€ ì²« ë²ˆì§¸ë³´ë‹¤ ë¹ ë¦„
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 1000ê°œ ì˜í™” ì²˜ë¦¬ ì‹œ < 200MB

**í•µì‹¬ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ë©´ ë‹¤ìŒ ë‹¨ê³„ì¸ [2.3-api-integration-testing.md](./2.3-api-integration-testing.md)ë¡œ ì§„í–‰í•˜ì„¸ìš”!** ğŸš€
