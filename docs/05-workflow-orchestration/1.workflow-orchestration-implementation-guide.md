# 5ë‹¨ê³„: ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ - ìƒì„¸ êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“‹ ë‹¨ê³„ ê°œìš”

**ëª©í‘œ**: ë³µì¡í•œ ML ì›Œí¬í”Œë¡œìš°ë¥¼ ìë™í™”í•˜ê³  ì˜ì¡´ì„±ì„ ê´€ë¦¬í•˜ì—¬ ì•ˆì •ì  ì‹¤í–‰ ë³´ì¥

**í•µì‹¬ ê°€ì¹˜**: ë°ì´í„° íŒŒì´í”„ë¼ì¸ë¶€í„° ëª¨ë¸ ë°°í¬ê¹Œì§€ ì „ì²´ ML ìƒëª…ì£¼ê¸°ì˜ ì²´ê³„ì  ê´€ë¦¬

---

## ğŸ¯ 5.1 Apache Airflow ì„¤ì¹˜ ë° ì„¤ì •

### ëª©í‘œ
MLOps íŒŒì´í”„ë¼ì¸ì„ ìœ„í•œ ê²¬ê³ í•œ Airflow í™˜ê²½ êµ¬ì¶•

### ìƒì„¸ êµ¬í˜„ ì‚¬í•­

#### **5.1.1 Airflow ì„¤ì¹˜ ë° ì´ˆê¸° ì„¤ì •**
- **Docker Compose ê¸°ë°˜ ì„¤ì¹˜**
  ```yaml
  # docker-compose.airflow.yml
  version: '3.8'
  
  x-airflow-common:
    &airflow-common
    image: apache/airflow:2.8.1-python3.11
    environment: &airflow-common-env
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
      AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
      _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/dags:/opt/airflow/dags
      - ${AIRFLOW_PROJ_DIR:-.}/logs:/opt/airflow/logs
      - ${AIRFLOW_PROJ_DIR:-.}/config:/opt/airflow/config
      - ${AIRFLOW_PROJ_DIR:-.}/plugins:/opt/airflow/plugins
    user: "${AIRFLOW_UID:-50000}:0"
    depends_on: &airflow-common-depends-on
      postgres:
        condition: service_healthy
  
  services:
    postgres:
      image: postgres:15
      environment:
        POSTGRES_USER: airflow
        POSTGRES_PASSWORD: airflow
        POSTGRES_DB: airflow
      volumes:
        - postgres-db-volume:/var/lib/postgresql/data
      healthcheck:
        test: ["CMD", "pg_isready", "-U", "airflow"]
        interval: 10s
        retries: 5
        start_period: 5s
    
    airflow-webserver:
      <<: *airflow-common
      command: webserver
      ports:
        - "8080:8080"
      healthcheck:
        test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
        interval: 30s
        timeout: 10s
        retries: 5
        start_period: 30s
    
    airflow-scheduler:
      <<: *airflow-common
      command: scheduler
      healthcheck:
        test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
        interval: 30s
        timeout: 10s
        retries: 5
        start_period: 30s
  
  volumes:
    postgres-db-volume:
  ```

#### **5.1.2 Airflow ì„¤ì • ìµœì í™”**
- **airflow.cfg ì£¼ìš” ì„¤ì •**
  ```ini
  # airflow.cfg
  [core]
  dags_folder = /opt/airflow/dags
  base_log_folder = /opt/airflow/logs
  logging_level = INFO
  executor = LocalExecutor
  parallelism = 32
  max_active_tasks_per_dag = 16
  max_active_runs_per_dag = 16
  
  [scheduler]
  dag_dir_list_interval = 300
  child_process_timeout = 600
  catchup_by_default = False
  max_tis_per_query = 512
  
  [webserver]
  web_server_port = 8080
  web_server_host = 0.0.0.0
  secret_key = your-secret-key-here
  authenticate = True
  auth_backend = airflow.contrib.auth.backends.password_auth
  
  [email]
  email_backend = airflow.providers.sendgrid.hooks.sendgrid.SendGridHook
  
  [logging]
  remote_logging = True
  remote_base_log_folder = s3://your-bucket/airflow-logs
  ```

ì´ 5ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ë©´ ë³µì¡í•œ ML ì›Œí¬í”Œë¡œìš°ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ìë™í™”í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” ê²¬ê³ í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œì´ êµ¬ì¶•ë©ë‹ˆë‹¤.
